{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":329006,"sourceType":"datasetVersion","datasetId":139630}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import time\nimport glob\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torchvision import models, transforms\nfrom torch.utils.data import Dataset, DataLoader\nfrom sklearn.model_selection import train_test_split, KFold\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import f1_score\nimport pandas as pd\nimport os\nfrom PIL import Image\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pickle\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau\nfrom torchvision.models import ResNet50_Weights\nfrom sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, confusion_matrix\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T14:00:20.036518Z","iopub.execute_input":"2025-07-20T14:00:20.037114Z","iopub.status.idle":"2025-07-20T14:00:20.041822Z","shell.execute_reply.started":"2025-07-20T14:00:20.037091Z","shell.execute_reply":"2025-07-20T14:00:20.041043Z"}},"outputs":[],"execution_count":26},{"cell_type":"markdown","source":"## FashionDataset Class Definition","metadata":{}},{"cell_type":"markdown","source":"This code defines a custom dataset class called `FashionDataset` for handling fashion image data. It inherits from PyTorch's `Dataset` class and is designed to work with a CSV file containing metadata and a directory of images.\n\nKey features of the `FashionDataset` class include:\n\n- Loading images and their corresponding labels (color, type, season, gender) from the CSV file and image directory.\n- Encoding categorical labels using `LabelEncoder` for efficient processing.\n- Applying different transformations to images based on whether they belong to minority classes, which helps in handling imbalanced datasets.\n- Skipping missing image files and tracking their IDs.\n- Providing utility methods to get the number of unique classes and sample counts for each category.\n\nThis class is essential for preparing the fashion data for training models, ensuring that the data is properly loaded, labeled, and augmented as needed.","metadata":{}},{"cell_type":"code","source":"class FashionDataset(Dataset):\n    # Custom dataset for fashion images, loading images and labels (color, type, season, gender)\n    # from a CSV file and image directory. Supports minority class augmentations and skips missing images.\n    def __init__(self, csv_data, img_dir, transform=None, minority_classes=None):\n        # Initialize the dataset with CSV data, image directory, transformations, and minority classes\n        # Args:\n        #     csv_data (pd.DataFrame): Metadata with labels\n        #     img_dir (str): Path to image files\n        #     transform (dict, optional): Transformations for default and minority classes\n        #     minority_classes (dict, optional): Minority labels for each category\n        self.data = csv_data\n        self.img_dir = img_dir\n        self.transform = transform\n        self.minority_classes = minority_classes or {}  # Default to empty dict if None\n        self.skipped_ids = []  # List to track IDs of skipped images\n\n        # Initialize label encoders and encode labels for each category\n        self.color_encoder = LabelEncoder().fit(self.data['baseColour'])\n        self.type_encoder = LabelEncoder().fit(self.data['articleType'])\n        self.season_encoder = LabelEncoder().fit(self.data['season'])\n        self.gender_encoder = LabelEncoder().fit(self.data['gender'])\n\n        # Transform categorical labels into encoded numerical values\n        self.colors = self.color_encoder.transform(self.data['baseColour'])\n        self.types = self.type_encoder.transform(self.data['articleType'])\n        self.seasons = self.season_encoder.transform(self.data['season'])\n        self.genders = self.gender_encoder.transform(self.data['gender'])\n\n    def __len__(self):\n        # Return the total number of samples in the dataset\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        # Retrieve a sample (image and labels) by index\n        # Returns image and encoded labels (color, type, season, gender)\n        # Skips missing images and applies transformations based on minority class status\n        img_id = self.data.iloc[idx]['id']\n        img_name = os.path.join(self.img_dir, f\"{img_id}.jpg\")\n\n        try:\n            # Load and convert image to RGB format\n            image = Image.open(img_name).convert('RGB')\n        except FileNotFoundError:\n            # Handle missing image files by skipping them\n            print(f\"Skipped ID {img_id}: Image not found\")\n            self.skipped_ids.append(img_id)\n            return None\n\n        # Extract encoded labels for the current sample\n        color = self.colors[idx]\n        type_ = self.types[idx]\n        season = self.seasons[idx]\n        gender = self.genders[idx]\n\n        # Apply transformations if specified\n        if self.transform:\n            # Determine if the sample belongs to a minority class\n            is_minority = any(\n                encoder.inverse_transform([label])[0] in self.minority_classes.get(category, [])\n                for encoder, label, category in [\n                    (self.color_encoder, color, 'color'),\n                    (self.type_encoder, type_, 'articleType'),\n                    (self.season_encoder, season, 'season'),\n                    (self.gender_encoder, gender, 'gender')\n                ]\n            )\n            # Choose transformation based on minority status\n            transform_key = 'minority' if is_minority else 'default'\n            image = self.transform[transform_key](image)\n\n        # Return the processed image and its labels\n        return image, color, type_, season, gender\n\n    def get_num_classes(self):\n        # Return a dictionary with the number of unique classes for each category\n        return {\n            'color': len(self.color_encoder.classes_),\n            'type': len(self.type_encoder.classes_),\n            'season': len(self.season_encoder.classes_),\n            'gender': len(self.gender_encoder.classes_)\n        }\n\n    def get_class_counts(self):\n        # Return a dictionary with sample counts for each class in each category\n        return {\n            'color': np.bincount(self.colors),\n            'type': np.bincount(self.types),\n            'season': np.bincount(self.seasons),\n            'gender': np.bincount(self.genders)\n        }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T07:14:45.471863Z","iopub.execute_input":"2025-07-20T07:14:45.472735Z","iopub.status.idle":"2025-07-20T07:14:45.484734Z","shell.execute_reply.started":"2025-07-20T07:14:45.472700Z","shell.execute_reply":"2025-07-20T07:14:45.484096Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"## MultiTaskModel for Fashion Attribute Classification","metadata":{}},{"cell_type":"markdown","source":"\nThis code defines the `MultiTaskModel` class, a PyTorch neural network for multi-task classification of fashion item attributes (color, type, season, gender).\n\n### Key Features:\n- Uses a pre-trained ResNet50 backbone (frozen) to extract robust image features.\n- Removes the final ResNet50 layer to obtain 2048-dimensional feature vectors.\n- Employs four linear layers (`color_head`, `type_head`, `season_head`, `gender_head`) for attribute-specific predictions.\n- Enables simultaneous classification of all attributes in one forward pass, optimizing computational efficiency.\n\n### Why Use ResNet50?\nResNet50 is chosen for its deep architecture (50 layers) and residual connections, which allow it to learn complex image features effectively without suffering from vanishing gradients. Pre-trained on ImageNet, it provides strong feature extraction for fashion images, reducing training time and the need for large datasets. Other CNN models (e.g., VGG, MobileNet) could be used, but ResNet50 balances performance and computational efficiency, making it a robust choice for transfer learning in multi-task scenarios.\n\n### Why Use 2048 Neurons in All Four Heads?\nThe 2048 neurons in each head correspond to the output dimension of the ResNet50 backbone after removing its final layer. ResNet50's feature extractor produces a 2048-dimensional vector, which is fed directly into each task-specific linear layer. This ensures compatibility with the backbone's output and allows each head to leverage the full feature set for accurate classification, tailored to the number of classes for each attribute (e.g., `num_colors`, `num_types`).","metadata":{}},{"cell_type":"code","source":"class MultiTaskModel(nn.Module):\n    # Custom PyTorch model for multi-task classification of fashion attributes\n    # Predicts color, type, season, and gender using a shared ResNet50 backbone\n    def __init__(self, num_colors, num_types, num_seasons, num_genders):\n        # Initialize the model with number of classes for each attribute\n        super(MultiTaskModel, self).__init__()\n        \n        # Load pre-trained ResNet50 and remove the final classification layer\n        self.base_model = models.resnet50(weights=ResNet50_Weights.DEFAULT)\n        self.base_model = nn.Sequential(*list(self.base_model.children())[:-1])\n        \n        # Freeze backbone parameters to use pre-trained weights without updates\n        for param in self.base_model.parameters():\n            param.requires_grad = False\n            \n        # Define task-specific linear layers for each attribute\n        self.color_head = nn.Linear(2048, num_colors)   # For color classification\n        self.type_head = nn.Linear(2048, num_types)     # For type classification\n        self.season_head = nn.Linear(2048, num_seasons) # For season classification\n        self.gender_head = nn.Linear(2048, num_genders) # For gender classification\n\n    def forward(self, x):\n        # Forward pass to predict all attributes\n        # Input x: Batch of images\n        # Output: Tuple of predictions for color, type, season, and gender\n        features = self.base_model(x)                    # Extract features using ResNet50\n        features = features.view(features.size(0), -1)   # Flatten features to 2048-dim vectors\n        color_output = self.color_head(features)        # Predict color classes\n        type_output = self.type_head(features)          # Predict type classes\n        season_output = self.season_head(features)      # Predict season classes\n        gender_output = self.gender_head(features)      # Predict gender classes\n        return color_output, type_output, season_output, gender_output","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T07:14:51.792340Z","iopub.execute_input":"2025-07-20T07:14:51.792641Z","iopub.status.idle":"2025-07-20T07:14:51.798786Z","shell.execute_reply.started":"2025-07-20T07:14:51.792618Z","shell.execute_reply":"2025-07-20T07:14:51.798097Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"## Data Transformations for Fashion Dataset\n\nThis code defines a dictionary of transformations (`transform`) used by the `FashionDataset` class to preprocess images. It includes two sets of transformations:\n\n- **Default**: Applied to non-minority class samples, it resizes images to 224x224 (required for ResNet50), applies random horizontal flips, converts images to tensors, and normalizes them using ImageNet mean and standard deviation.\n- **Minority**: Applied to minority class samples for data augmentation, it includes the same resizing and normalization as the default, plus random horizontal flips (50% probability) and random rotations (up to 15 degrees) to increase diversity in underrepresented classes.\n\n#### Why Resize to 224x224?\nImages are resized to 224x224 to match the input size expected by the pre-trained ResNet50 model used in `MultiTaskModel`. This size is standard for ResNet50, optimized for ImageNet pre-training, ensuring compatibility with the model's convolutional layers, consistent batch processing, and efficient feature extraction without needing to retrain the backbone.","metadata":{}},{"cell_type":"code","source":"transform = {\n    'default': transforms.Compose([\n        transforms.Resize((224, 224)),\n        transforms.RandomHorizontalFlip(),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n    ]),\n    'minority': transforms.Compose([\n        transforms.Resize((224, 224)),\n        transforms.RandomHorizontalFlip(p=0.5),\n        transforms.RandomRotation(15),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n    ])\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T07:14:56.401372Z","iopub.execute_input":"2025-07-20T07:14:56.401933Z","iopub.status.idle":"2025-07-20T07:14:56.406906Z","shell.execute_reply.started":"2025-07-20T07:14:56.401906Z","shell.execute_reply":"2025-07-20T07:14:56.406183Z"}},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"## Data Loading and Preprocessing\n\nThis code handles the loading and preprocessing of the fashion dataset for training the `MultiTaskModel`.\n\n#### Key Steps:\n- **Data Loading**: Loads metadata from a CSV file (`styles.csv`) and specifies the image directory.\n- **Data Cleaning**: Removes rows with missing values in critical columns (`id`, `baseColour`, `articleType`, `season`, `gender`) to ensure data integrity.\n- **Minority Class Definition**: Identifies minority classes for gender, season, color, and article type based on exploratory data analysis (EDA) to apply targeted augmentations in `FashionDataset`.\n- **Data Splitting**: Splits the dataset into 85% train+validation and 15% test sets using a fixed random seed for reproducibility.\n- **Cross-Validation Setup**: Initializes 5-fold cross-validation to split train+validation data for robust model evaluation.\n\nThese steps prepare the dataset for use with the `FashionDataset` class, ensuring clean data and proper splits for training, validation, and testing.","metadata":{}},{"cell_type":"code","source":"csv_file = '/kaggle/input/fashion-product-images-dataset/fashion-dataset/styles.csv'\nimg_dir = '/kaggle/input/fashion-product-images-dataset/fashion-dataset/images'\ndata = pd.read_csv(csv_file, on_bad_lines='skip')\n# Handle missing values\ndata = data.dropna(subset=['id', 'baseColour', 'articleType', 'season', 'gender'])\n\n# Define minority classes (based on eda_report_final.md)\nminority_classes = {\n    'gender': ['Girls', 'Unisex', 'Boys'],  # Men: 49.8%, Women: 37.3%, others <6%\n    'season': ['Spring'],  # Spring: 3.7%\n    'color': [c for c in data['baseColour'].unique() if data['baseColour'].value_counts()[c] < 1000],  # Colors with <1000 occurrences\n    'articleType': [a for a in data['articleType'].unique() if data['articleType'].value_counts()[a] < 100]  # Article types with <100 occurrences\n}\n\n# Split into train+val (85%) and test (15%)\ntrain_val_data, test_data = train_test_split(data, test_size=0.15, random_state=42)\n\n# Setup K-Fold Cross-Validation (k=5)\nkfold = KFold(n_splits=5, shuffle=True, random_state=42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T07:15:01.371829Z","iopub.execute_input":"2025-07-20T07:15:01.372374Z","iopub.status.idle":"2025-07-20T07:15:01.956810Z","shell.execute_reply.started":"2025-07-20T07:15:01.372350Z","shell.execute_reply":"2025-07-20T07:15:01.956168Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"## DataLoader and Custom Collate Function\n\nThis code defines utilities for creating a PyTorch `DataLoader` and handling batches in the `FashionDataset`.\n\n#### Key Components:\n- **`create_dataloader`**: Creates a `DataLoader` to batch and load data from a dataset (e.g., `FashionDataset`). It supports customizable batch size, shuffling, and multi-threaded loading (`num_workers`). The `pin_memory` option optimizes data transfer for GPU training.\n- **`custom_collate_fn`**: A custom collate function that filters out `None` values in a batch (e.g., caused by missing images in `FashionDataset`) before applying the default collation to create tensors.\n\nThese utilities ensure efficient and robust data loading for training and evaluation, handling issues like missing images gracefully.","metadata":{}},{"cell_type":"code","source":"# Create a DataLoader for the dataset with custom settings\ndef create_dataloader(dataset, batch_size=32, shuffle=True, num_workers=4):\n    # Returns a DataLoader for batching and loading data\n    # Args:\n    #     dataset: PyTorch dataset (e.g., FashionDataset)\n    #     batch_size: Number of samples per batch (default: 32)\n    #     shuffle: Whether to shuffle data (default: True)\n    #     num_workers: Number of subprocesses for data loading (default: 4)\n    return DataLoader(\n        dataset,\n        batch_size=batch_size,\n        shuffle=shuffle,\n        collate_fn=custom_collate_fn,  # Use custom collate function to handle None values\n        num_workers=num_workers,\n        pin_memory=True if torch.cuda.is_available() else False  # Optimize memory for GPU\n    )\n\n# Custom collate function to filter out None values in a batch\ndef custom_collate_fn(batch):\n    # Remove None items (e.g., from missing images in FashionDataset)\n    batch = [item for item in batch if item is not None]\n    # If batch is empty, return None\n    if not batch:\n        return None\n    # Use default collate function to process valid items\n    return torch.utils.data.dataloader.default_collate(batch)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T07:15:15.051665Z","iopub.execute_input":"2025-07-20T07:15:15.052258Z","iopub.status.idle":"2025-07-20T07:15:15.057063Z","shell.execute_reply.started":"2025-07-20T07:15:15.052236Z","shell.execute_reply":"2025-07-20T07:15:15.056234Z"}},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"## Class Weights, Model, and Training Setup\n\nThis code sets up the class weights, model, loss functions, and optimizer for training the `MultiTaskModel`.\n\n#### Key Components:\n- **`compute_class_weights`**: Calculates inverse frequency weights for each class to handle imbalanced data, normalizing them to scale with the number of classes.\n- **Dataset Initialization**: Creates a `FashionDataset` instance to retrieve the number of classes and class counts for each attribute (color, type, season, gender).\n- **Class Weights**: Computes weights for each task to address class imbalance and moves them to the appropriate device (GPU/CPU).\n- **Model Initialization**: Instantiates the `MultiTaskModel` with the number of classes for each attribute and moves it to the device.\n- **Loss Functions**: Defines `CrossEntropyLoss` for each task with corresponding class weights to prioritize minority classes.\n- **Optimizer**: Uses the Adam optimizer with a learning rate of 0.001 to update model parameters.\n\nThis setup ensures the model is ready for training, with weighted losses to handle class imbalance effectively.\n\n#### Why Use CrossEntropyLoss?\n`CrossEntropyLoss` is used because it’s ideal for multi-class classification tasks (color, type, season, gender), combining softmax and negative log-likelihood loss. It supports class weights to handle imbalance.","metadata":{}},{"cell_type":"code","source":"def compute_class_weights(class_counts, num_classes):\n    weights = 1.0 / (np.array(class_counts) + 1e-6)  # Inverse frequency\n    weights = weights / weights.sum() * num_classes  # Normalize\n    return torch.tensor(weights, dtype=torch.float32)\n\n# Initialize dataset to get class counts\nfull_dataset = FashionDataset(data, img_dir, transform=transform)\nnum_classes = full_dataset.get_num_classes()\nclass_counts = full_dataset.get_class_counts()\n\n# Compute class weights for each task\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ncolor_weights = compute_class_weights(class_counts['color'], num_classes['color']).to(device)\ntype_weights = compute_class_weights(class_counts['type'], num_classes['type']).to(device)\nseason_weights = compute_class_weights(class_counts['season'], num_classes['season']).to(device)\ngender_weights = compute_class_weights(class_counts['gender'], num_classes['gender']).to(device)\n\n# Initialize model, loss functions, and optimizer\nmodel = MultiTaskModel(\n    num_classes['color'],\n    num_classes['type'],\n    num_classes['season'],\n    num_classes['gender']\n).to(device)\n\n# Define loss functions with class weights for each task\ncriterion_color = nn.CrossEntropyLoss(weight=color_weights)\ncriterion_type = nn.CrossEntropyLoss(weight=type_weights)\ncriterion_season = nn.CrossEntropyLoss(weight=season_weights)\ncriterion_gender = nn.CrossEntropyLoss(weight=gender_weights)\n\n# Adam optimizer with learning rate 0.001\noptimizer = optim.Adam(model.parameters(), lr=0.001)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T07:15:22.513009Z","iopub.execute_input":"2025-07-20T07:15:22.513750Z","iopub.status.idle":"2025-07-20T07:15:23.272735Z","shell.execute_reply.started":"2025-07-20T07:15:22.513724Z","shell.execute_reply":"2025-07-20T07:15:23.271934Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"num_epochs = 10\nk = 5\nfold_results = []\nfold_metrics = []\nbest_fold = 0\nbest_avg_f1 = 0.0\nbest_model_path = '/kaggle/working/best_model.pth'\ntasks = ['color', 'type', 'season', 'gender']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T07:15:43.740963Z","iopub.execute_input":"2025-07-20T07:15:43.741226Z","iopub.status.idle":"2025-07-20T07:15:44.370131Z","shell.execute_reply.started":"2025-07-20T07:15:43.741207Z","shell.execute_reply":"2025-07-20T07:15:44.369530Z"}},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":"## K-Fold Training and Validation Loop","metadata":{}},{"cell_type":"markdown","source":"This code implements the k-fold cross-validation loop for training and evaluating the `MultiTaskModel` on the fashion dataset.\n\n#### Key Components:\n- **k-fold cross validation**: Uses `KFold` (from Cell 5) to split `train_val_data` into training and validation sets for each fold.\n- **Dataset and DataLoader**: Creates `FashionDataset` and `DataLoader` instances for training and validation using `create_dataloader` (Cell 6).\n- **Model Setup**: Initializes a fresh `MultiTaskModel` and Adam optimizer per fold, with a `ReduceLROnPlateau` scheduler to adjust the learning rate based on validation loss.\n- **Checkpointing**: Resumes training from the latest checkpoint (if available) and saves checkpoints every 10 epochs.\n- **Training Loop**: Trains the model on each batch, computing task-specific losses (color, type, season, gender), performing backpropagation, and updating parameters.\n- **Validation Loop**: Evaluates the model on the validation set, calculating loss and macro-averaged metrics (F1-score, precision, recall) plus accuracy for each task.\n- **Early Stopping**: Stops training if validation loss doesn’t improve for 3 epochs.\n- **Model Saving**: Saves the best model based on the average macro F1-score across tasks.\n- **Metrics Tracking**: Stores training and validation metrics for analysis.\n\n#### Why is Macro-Averaged F1-Score the Most Significant Metric?\nThe macro-averaged F1-score is the most significant metric because the dataset has imbalanced classes (e.g., 'Spring' at 3.7%, 'Girls' <6%). It averages F1-scores per class equally, ensuring minority classes (identified in Cell 5) are not ignored, unlike accuracy, which favors majority classes. It balances precision and recall, is critical for multi-task evaluation (color, type, season, gender), and drives model selection (best model saved based on `avg_f1`), making it ideal for this imbalanced multi-class classification task.\n\nThis loop ensures robust training and evaluation, optimizing model performance across all folds.","metadata":{}},{"cell_type":"code","source":"# Training loop for k-fold cross-validation\nfor fold, (train_idx, val_idx) in enumerate(kfold.split(train_val_data)):\n    # Print current fold number\n    print(f\"Fold {fold+1}/{k}\")\n    \n    # Split train and validation data for the current fold\n    train_data = train_val_data.iloc[train_idx].reset_index(drop=True)\n    val_data = train_val_data.iloc[val_idx].reset_index(drop=True)\n    \n    # Create train and validation datasets\n    train_dataset = FashionDataset(train_data, img_dir, transform=transform, minority_classes=minority_classes)\n    val_dataset = FashionDataset(val_data, img_dir, transform=transform, minority_classes=minority_classes)\n\n    # Create DataLoaders for train and validation\n    train_loader = create_dataloader(train_dataset, batch_size=32, shuffle=True, num_workers=4)\n    val_loader = create_dataloader(val_dataset, batch_size=32, shuffle=False, num_workers=4)\n\n    # Initialize model and optimizer for the current fold\n    model = MultiTaskModel(\n        num_classes['color'],   # Number of color classes\n        num_classes['type'],    # Number of type classes\n        num_classes['season'],  # Number of season classes\n        num_classes['gender']   # Number of gender classes\n    ).to(device)\n    optimizer = optim.Adam(model.parameters(), lr=0.001)  # Adam optimizer with learning rate 0.001\n    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=2, min_lr=1e-6, verbose=True)  # Reduce LR on plateau\n\n    # Load latest checkpoint if available\n    checkpoint_files = glob.glob(f'/kaggle/working/checkpoint_fold_{fold+1}_epoch_*.pth')\n    start_epoch = 0\n    best_val_loss = float('inf')\n    if checkpoint_files:\n        latest_checkpoint = max(checkpoint_files, key=lambda x: int(x.split('_epoch_')[-1].split('.pth')[0]))\n        checkpoint = torch.load(latest_checkpoint)\n        model.load_state_dict(checkpoint['model_state_dict'])\n        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n        start_epoch = checkpoint['epoch'] + 1\n        best_val_loss = checkpoint['best_val_loss']\n        print(f\"Resuming Fold {fold+1} from checkpoint {latest_checkpoint} at Epoch {start_epoch}\")\n\n    # Initialize metrics storage for this fold\n    epoch_metrics = {\n        'train_loss': [],\n        'val_loss': [],\n        'val_f1_color': [], 'val_f1_type': [], 'val_f1_season': [], 'val_f1_gender': [],\n        'val_precision_color': [], 'val_precision_type': [], 'val_precision_season': [], 'val_precision_gender': [],\n        'val_recall_color': [], 'val_recall_type': [], 'val_recall_season': [], 'val_recall_gender': [],\n        'val_accuracy_color': [], 'val_accuracy_type': [], 'val_accuracy_season': [], 'val_accuracy_gender': [],\n        'loss_color': [], 'loss_type': [], 'loss_season': [], 'loss_gender': []\n    }\n\n    # Training loop for each epoch\n    patience = 3\n    counter = 0\n    for epoch in range(start_epoch, num_epochs):\n        epoch_start_time = time.time()\n        model.train()  # Set model to training mode\n        running_loss = 0.0\n        running_loss_color = 0.0\n        running_loss_type = 0.0\n        running_loss_season = 0.0\n        running_loss_gender = 0.0\n        count = 0\n        for batch in train_loader:\n            batch_start_time = time.time()\n            if batch is None:\n                continue\n            # Load batch data and move to device\n            images, colors, types, seasons, genders = batch\n            images, colors, types, seasons, genders = (\n                images.to(device), colors.to(device), types.to(device),\n                seasons.to(device), genders.to(device)\n            )\n            optimizer.zero_grad()  # Clear gradients\n            # Forward pass\n            color_pred, type_pred, season_pred, gender_pred = model(images)\n            # Compute loss for each task\n            loss_color = criterion_color(color_pred, colors)\n            loss_type = criterion_type(type_pred, types)\n            loss_season = criterion_season(season_pred, seasons)\n            loss_gender = criterion_gender(gender_pred, genders)\n            total_loss = loss_color + loss_type + loss_season + loss_gender\n            total_loss.backward()  # Backpropagation\n            optimizer.step()      # Update model parameters\n            # Accumulate losses\n            running_loss += total_loss.item()\n            running_loss_color += loss_color.item()\n            running_loss_type += loss_type.item()\n            running_loss_season += loss_season.item()\n            running_loss_gender += loss_gender.item()\n            count += 1\n            batch_time = time.time() - batch_start_time\n            if count % 10 == 0:\n                print(f\"Fold {fold+1}, Epoch {epoch+1}, Batch {count}, Loss: {total_loss:.4f}, LR: {optimizer.param_groups[0]['lr']:.6f}, Batch Time: {batch_time:.2f}s\")\n        # Compute average training loss\n        avg_train_loss = running_loss / count if count > 0 else float('inf')\n        epoch_metrics['train_loss'].append(avg_train_loss)\n        epoch_metrics['loss_color'].append(running_loss_color / count)\n        epoch_metrics['loss_type'].append(running_loss_type / count)\n        epoch_metrics['loss_season'].append(running_loss_season / count)\n        epoch_metrics['loss_gender'].append(running_loss_gender / count)\n        epoch_time = time.time() - epoch_start_time\n        print(f\"Fold {fold+1}, Epoch {epoch+1}, Train Loss: {avg_train_loss:.4f}, Epoch {epoch+1} Time: {epoch_time:.2f}s\")\n\n        # Validation phase\n        model.eval()  # Set model to evaluation mode\n        val_loss = 0.0\n        val_count = 0\n        val_color_true, val_color_pred = [], []\n        val_type_true, val_type_pred = [], []\n        val_season_true, val_season_pred = [], []\n        val_gender_true, val_gender_pred = [], []\n        with torch.no_grad():  # Disable gradient computation\n            for batch in val_loader:\n                if batch is None:\n                    continue\n                # Load batch data and move to device\n                images, colors, types, seasons, genders = batch\n                images, colors, types, seasons, genders = (\n                    images.to(device), colors.to(device), types.to(device),\n                    seasons.to(device), genders.to(device)\n                )\n                # Forward pass\n                color_pred, type_pred, season_pred, gender_pred = model(images)\n                # Compute validation loss\n                val_loss += (criterion_color(color_pred, colors) + criterion_type(type_pred, types) +\n                             criterion_season(season_pred, seasons) + criterion_gender(gender_pred, genders)).item()\n                val_count += 1\n                # Store predictions and true labels for metrics\n                val_color_true.extend(colors.cpu().numpy())\n                val_color_pred.extend(torch.argmax(color_pred, dim=1).cpu().numpy())\n                val_type_true.extend(types.cpu().numpy())\n                val_type_pred.extend(torch.argmax(type_pred, dim=1).cpu().numpy())\n                val_season_true.extend(seasons.cpu().numpy())\n                val_season_pred.extend(torch.argmax(season_pred, dim=1).cpu().numpy())\n                val_gender_true.extend(genders.cpu().numpy())\n                val_gender_pred.extend(torch.argmax(gender_pred, dim=1).cpu().numpy())\n        # Compute average validation loss\n        avg_val_loss = val_loss / val_count if val_count > 0 else float('inf')\n        # Calculate macro-averaged metrics for each task\n        val_f1_color = f1_score(val_color_true, val_color_pred, average='macro')\n        val_f1_type = f1_score(val_type_true, val_type_pred, average='macro')\n        val_f1_season = f1_score(val_season_true, val_season_pred, average='macro')\n        val_f1_gender = f1_score(val_gender_true, val_gender_pred, average='macro')\n        val_precision_color = precision_score(val_color_true, val_color_pred, average='macro')\n        val_precision_type = precision_score(val_type_true, val_type_pred, average='macro')\n        val_precision_season = precision_score(val_season_true, val_season_pred, average='macro')\n        val_precision_gender = precision_score(val_gender_true, val_gender_pred, average='macro')\n        val_recall_color = recall_score(val_color_true, val_color_pred, average='macro')\n        val_recall_type = recall_score(val_type_true, val_type_pred, average='macro')\n        val_recall_season = recall_score(val_season_true, val_season_pred, average='macro')\n        val_recall_gender = recall_score(val_gender_true, val_gender_pred, average='macro')\n        val_accuracy_color = accuracy_score(val_color_true, val_color_pred)\n        val_accuracy_type = accuracy_score(val_type_true, val_type_pred)\n        val_accuracy_season = accuracy_score(val_season_true, val_season_pred)\n        val_accuracy_gender = accuracy_score(val_gender_true, val_gender_pred)\n        avg_f1 = (val_f1_color + val_f1_type + val_f1_season + val_f1_gender) / 4\n        # Store validation metrics\n        epoch_metrics['val_loss'].append(avg_val_loss)\n        epoch_metrics['val_f1_color'].append(val_f1_color)\n        epoch_metrics['val_f1_type'].append(val_f1_type)\n        epoch_metrics['val_f1_season'].append(val_f1_season)\n        epoch_metrics['val_f1_gender'].append(val_f1_gender)\n        epoch_metrics['val_precision_color'].append(val_precision_color)\n        epoch_metrics['val_precision_type'].append(val_precision_type)\n        epoch_metrics['val_precision_season'].append(val_precision_season)\n        epoch_metrics['val_precision_gender'].append(val_precision_gender)\n        epoch_metrics['val_recall_color'].append(val_recall_color)\n        epoch_metrics['val_recall_type'].append(val_recall_type)\n        epoch_metrics['val_recall_season'].append(val_recall_season)\n        epoch_metrics['val_recall_gender'].append(val_recall_gender)\n        epoch_metrics['val_accuracy_color'].append(val_accuracy_color)\n        epoch_metrics['val_accuracy_type'].append(val_accuracy_type)\n        epoch_metrics['val_accuracy_season'].append(val_accuracy_season)\n        epoch_metrics['val_accuracy_gender'].append(val_accuracy_gender)\n        # Print validation metrics\n        print(f\"Fold {fold+1}, Validation Loss: {avg_val_loss:.4f}\")\n        print(f\"Fold {fold+1}, Validation F1-Scores (Macro) - Color: {val_f1_color:.4f}, Type: {val_f1_type:.4f}, Season: {val_f1_season:.4f}, Gender: {val_f1_gender:.4f}, Avg F1: {avg_f1:.4f}\")\n        print(f\"Fold {fold+1}, Validation Precision (Macro) - Color: {val_precision_color:.4f}, Type: {val_precision_type:.4f}, Season: {val_precision_season:.4f}, Gender: {val_precision_gender:.4f}\")\n        print(f\"Fold {fold+1}, Validation Recall (Macro) - Color: {val_recall_color:.4f}, Type: {val_recall_type:.4f}, Season: {val_recall_season:.4f}, Gender: {val_recall_gender:.4f}\")\n        print(f\"Fold {fold+1}, Validation Accuracy - Color: {val_accuracy_color:.4f}, Type: {val_accuracy_type:.4f}, Season: {val_accuracy_season:.4f}, Gender: {val_accuracy_gender:.4f}\")\n\n        # Update learning rate based on validation loss\n        scheduler.step(avg_val_loss)\n\n        # Save checkpoint every 10th epoch\n        if (epoch + 1) % 10 == 0:\n            checkpoint_path = f'/kaggle/working/checkpoint_fold_{fold+1}_epoch_{epoch+1}.pth'\n            torch.save({\n                'epoch': epoch,\n                'model_state_dict': model.state_dict(),\n                'optimizer_state_dict': optimizer.state_dict(),\n                'best_val_loss': best_val_loss\n            }, checkpoint_path)\n            print(f\"Saved checkpoint for Fold {fold+1} at {checkpoint_path}\")\n\n        # Early stopping and best model saving\n        if avg_val_loss < best_val_loss:\n            best_val_loss = avg_val_loss\n            counter = 0\n            if avg_f1 > best_avg_f1:\n                best_avg_f1 = avg_f1\n                best_fold = fold + 1\n                torch.save(model.state_dict(), best_model_path)\n                print(f\"Saved best model from Fold {fold+1} at {best_model_path} (Avg F1: {avg_f1:.4f})\")\n        else:\n            counter += 1\n            if counter >= patience:\n                print(f\"Early stopping triggered for Fold {fold+1}\")\n                break\n\n    # Store results for this fold\n    fold_results.append({\n        'fold': fold+1,\n        'best_val_loss': best_val_loss,\n        'val_f1_color': val_f1_color,\n        'val_f1_type': val_f1_type,\n        'val_f1_season': val_f1_season,\n        'val_f1_gender': val_f1_gender,\n        'val_precision_color': val_precision_color,\n        'val_precision_type': val_precision_type,\n        'val_precision_season': val_precision_season,\n        'val_precision_gender': val_precision_gender,\n        'val_recall_color': val_recall_color,\n        'val_recall_type': val_recall_type,\n        'val_recall_season': val_recall_season,\n        'val_recall_gender': val_recall_gender,\n        'val_accuracy_color': val_accuracy_color,\n        'val_accuracy_type': val_accuracy_type,\n        'val_accuracy_season': val_accuracy_season,\n        'val_accuracy_gender': val_accuracy_gender,\n        'avg_f1': avg_f1,\n        'skipped_ids_train': train_dataset.skipped_ids,\n        'skipped_ids_val': val_dataset.skipped_ids\n    })\n    fold_metrics.append(epoch_metrics)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T07:39:51.653643Z","iopub.execute_input":"2025-07-20T07:39:51.653909Z","iopub.status.idle":"2025-07-20T11:12:26.796775Z","shell.execute_reply.started":"2025-07-20T07:39:51.653890Z","shell.execute_reply":"2025-07-20T11:12:26.795577Z"}},"outputs":[{"name":"stdout","text":"Fold 1/5\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Fold 1, Epoch 1, Batch 10, Loss: 9.8735, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 1, Batch 20, Loss: 9.8006, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 1, Batch 30, Loss: 8.7932, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 1, Batch 40, Loss: 9.1644, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 1, Batch 50, Loss: 7.4616, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 1, Batch 60, Loss: 7.4593, LR: 0.001000, Batch Time: 0.13s\nFold 1, Epoch 1, Batch 70, Loss: 6.6816, LR: 0.001000, Batch Time: 0.13s\nFold 1, Epoch 1, Batch 80, Loss: 8.2556, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 1, Batch 90, Loss: 6.3210, LR: 0.001000, Batch Time: 0.13s\nFold 1, Epoch 1, Batch 100, Loss: 5.4569, LR: 0.001000, Batch Time: 0.13s\nFold 1, Epoch 1, Batch 110, Loss: 7.2192, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 1, Batch 120, Loss: 5.0299, LR: 0.001000, Batch Time: 0.13s\nFold 1, Epoch 1, Batch 130, Loss: 5.3274, LR: 0.001000, Batch Time: 0.13s\nFold 1, Epoch 1, Batch 140, Loss: 5.6630, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 1, Batch 150, Loss: 5.6970, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 1, Batch 160, Loss: 7.3068, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 1, Batch 170, Loss: 5.7754, LR: 0.001000, Batch Time: 0.13s\nFold 1, Epoch 1, Batch 180, Loss: 5.1333, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 1, Batch 190, Loss: 6.3811, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 1, Batch 200, Loss: 6.0669, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 1, Batch 210, Loss: 5.1448, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 1, Batch 220, Loss: 5.6551, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 1, Batch 230, Loss: 6.1029, LR: 0.001000, Batch Time: 0.12s\nSkipped ID 39425: Image file /kaggle/input/fashion-product-images-dataset/fashion-dataset/images/39425.jpg not found\nFold 1, Epoch 1, Batch 240, Loss: 4.7905, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 1, Batch 250, Loss: 4.7557, LR: 0.001000, Batch Time: 0.13s\nFold 1, Epoch 1, Batch 260, Loss: 4.6643, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 1, Batch 270, Loss: 4.1472, LR: 0.001000, Batch Time: 0.13s\nFold 1, Epoch 1, Batch 280, Loss: 6.6933, LR: 0.001000, Batch Time: 0.13s\nFold 1, Epoch 1, Batch 290, Loss: 7.0067, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 1, Batch 300, Loss: 5.0008, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 1, Batch 310, Loss: 4.7886, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 1, Batch 320, Loss: 4.7397, LR: 0.001000, Batch Time: 0.11s\nFold 1, Epoch 1, Batch 330, Loss: 4.0013, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 1, Batch 340, Loss: 7.6699, LR: 0.001000, Batch Time: 0.11s\nFold 1, Epoch 1, Batch 350, Loss: 4.8190, LR: 0.001000, Batch Time: 0.13s\nFold 1, Epoch 1, Batch 360, Loss: 3.9062, LR: 0.001000, Batch Time: 0.11s\nFold 1, Epoch 1, Batch 370, Loss: 4.9837, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 1, Batch 380, Loss: 3.9188, LR: 0.001000, Batch Time: 0.11s\nFold 1, Epoch 1, Batch 390, Loss: 4.1561, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 1, Batch 400, Loss: 4.3903, LR: 0.001000, Batch Time: 0.11s\nFold 1, Epoch 1, Batch 410, Loss: 3.8893, LR: 0.001000, Batch Time: 0.13s\nFold 1, Epoch 1, Batch 420, Loss: 4.4118, LR: 0.001000, Batch Time: 0.11s\nFold 1, Epoch 1, Batch 430, Loss: 4.0562, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 1, Batch 440, Loss: 3.9681, LR: 0.001000, Batch Time: 0.11s\nFold 1, Epoch 1, Batch 450, Loss: 4.4440, LR: 0.001000, Batch Time: 0.12s\nSkipped ID 39403: Image file /kaggle/input/fashion-product-images-dataset/fashion-dataset/images/39403.jpg not found\nSkipped ID 39401: Image file /kaggle/input/fashion-product-images-dataset/fashion-dataset/images/39401.jpg not found\nFold 1, Epoch 1, Batch 460, Loss: 3.4990, LR: 0.001000, Batch Time: 0.11s\nFold 1, Epoch 1, Batch 470, Loss: 3.6642, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 1, Batch 480, Loss: 4.7017, LR: 0.001000, Batch Time: 0.11s\nFold 1, Epoch 1, Batch 490, Loss: 4.2644, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 1, Batch 500, Loss: 3.8337, LR: 0.001000, Batch Time: 0.11s\nFold 1, Epoch 1, Batch 510, Loss: 4.7455, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 1, Batch 520, Loss: 4.7605, LR: 0.001000, Batch Time: 0.11s\nFold 1, Epoch 1, Batch 530, Loss: 2.9136, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 1, Batch 540, Loss: 3.3182, LR: 0.001000, Batch Time: 0.11s\nFold 1, Epoch 1, Batch 550, Loss: 3.3201, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 1, Batch 560, Loss: 5.7313, LR: 0.001000, Batch Time: 0.11s\nFold 1, Epoch 1, Batch 570, Loss: 4.2056, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 1, Batch 580, Loss: 4.6747, LR: 0.001000, Batch Time: 0.11s\nFold 1, Epoch 1, Batch 590, Loss: 4.8558, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 1, Batch 600, Loss: 3.3206, LR: 0.001000, Batch Time: 0.11s\nFold 1, Epoch 1, Batch 610, Loss: 4.4075, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 1, Batch 620, Loss: 4.5456, LR: 0.001000, Batch Time: 0.11s\nFold 1, Epoch 1, Batch 630, Loss: 5.5814, LR: 0.001000, Batch Time: 0.13s\nFold 1, Epoch 1, Batch 640, Loss: 5.1212, LR: 0.001000, Batch Time: 0.11s\nFold 1, Epoch 1, Batch 650, Loss: 4.5035, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 1, Batch 660, Loss: 3.9964, LR: 0.001000, Batch Time: 0.11s\nFold 1, Epoch 1, Batch 670, Loss: 3.9271, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 1, Batch 680, Loss: 3.5593, LR: 0.001000, Batch Time: 0.11s\nFold 1, Epoch 1, Batch 690, Loss: 4.1833, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 1, Batch 700, Loss: 3.8916, LR: 0.001000, Batch Time: 0.11s\nFold 1, Epoch 1, Batch 710, Loss: 3.9416, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 1, Batch 720, Loss: 3.7118, LR: 0.001000, Batch Time: 0.11s\nFold 1, Epoch 1, Batch 730, Loss: 3.7818, LR: 0.001000, Batch Time: 0.13s\nFold 1, Epoch 1, Batch 740, Loss: 4.0410, LR: 0.001000, Batch Time: 0.11s\nFold 1, Epoch 1, Batch 750, Loss: 3.3968, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 1, Batch 760, Loss: 2.9905, LR: 0.001000, Batch Time: 0.11s\nSkipped ID 12347: Image file /kaggle/input/fashion-product-images-dataset/fashion-dataset/images/12347.jpg not found\nFold 1, Epoch 1, Batch 770, Loss: 5.6426, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 1, Batch 780, Loss: 3.5367, LR: 0.001000, Batch Time: 0.11s\nFold 1, Epoch 1, Batch 790, Loss: 5.3935, LR: 0.001000, Batch Time: 0.13s\nFold 1, Epoch 1, Batch 800, Loss: 3.7736, LR: 0.001000, Batch Time: 0.11s\nFold 1, Epoch 1, Batch 810, Loss: 3.0643, LR: 0.001000, Batch Time: 0.13s\nFold 1, Epoch 1, Batch 820, Loss: 4.5170, LR: 0.001000, Batch Time: 0.11s\nFold 1, Epoch 1, Batch 830, Loss: 3.9472, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 1, Batch 840, Loss: 5.0692, LR: 0.001000, Batch Time: 0.11s\nFold 1, Epoch 1, Batch 850, Loss: 3.5645, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 1, Batch 860, Loss: 3.5165, LR: 0.001000, Batch Time: 0.11s\nFold 1, Epoch 1, Batch 870, Loss: 4.6788, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 1, Batch 880, Loss: 3.2759, LR: 0.001000, Batch Time: 0.11s\nFold 1, Epoch 1, Batch 890, Loss: 3.7824, LR: 0.001000, Batch Time: 0.13s\nFold 1, Epoch 1, Batch 900, Loss: 4.4067, LR: 0.001000, Batch Time: 0.11s\nFold 1, Epoch 1, Batch 910, Loss: 5.2627, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 1, Batch 920, Loss: 5.8081, LR: 0.001000, Batch Time: 0.11s\nFold 1, Epoch 1, Batch 930, Loss: 2.9597, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 1, Batch 940, Loss: 3.1644, LR: 0.001000, Batch Time: 0.11s\nFold 1, Epoch 1, Train Loss: 5.0577, Epoch 1 Time: 440.69s\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"},{"name":"stdout","text":"Fold 1, Validation Loss: 15.0288\nFold 1, Validation F1-Scores (Macro) - Color: 0.0663, Type: 0.0188, Season: 0.6244, Gender: 0.6773, Avg F1: 0.3467\nFold 1, Validation Precision (Macro) - Color: 0.0798, Type: 0.0314, Season: 0.5984, Gender: 0.6297\nFold 1, Validation Recall (Macro) - Color: 0.0751, Type: 0.0158, Season: 0.6919, Gender: 0.7953\nFold 1, Validation Accuracy - Color: 0.2202, Type: 0.0131, Season: 0.6026, Gender: 0.8265\nSaved best model from Fold 1 at /kaggle/working/best_model.pth (Avg F1: 0.3467)\nFold 1, Epoch 2, Batch 10, Loss: 3.1974, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 2, Batch 20, Loss: 3.6017, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 2, Batch 30, Loss: 2.0701, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 2, Batch 40, Loss: 5.2835, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 2, Batch 50, Loss: 4.4174, LR: 0.001000, Batch Time: 0.13s\nFold 1, Epoch 2, Batch 60, Loss: 3.5223, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 2, Batch 70, Loss: 3.3261, LR: 0.001000, Batch Time: 0.11s\nFold 1, Epoch 2, Batch 80, Loss: 4.6243, LR: 0.001000, Batch Time: 0.13s\nFold 1, Epoch 2, Batch 90, Loss: 3.6948, LR: 0.001000, Batch Time: 0.11s\nFold 1, Epoch 2, Batch 100, Loss: 3.3699, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 2, Batch 110, Loss: 4.0541, LR: 0.001000, Batch Time: 0.11s\nFold 1, Epoch 2, Batch 120, Loss: 4.9171, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 2, Batch 130, Loss: 4.6899, LR: 0.001000, Batch Time: 0.11s\nFold 1, Epoch 2, Batch 140, Loss: 1.9816, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 2, Batch 150, Loss: 3.5339, LR: 0.001000, Batch Time: 0.11s\nFold 1, Epoch 2, Batch 160, Loss: 3.1416, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 2, Batch 170, Loss: 3.9482, LR: 0.001000, Batch Time: 0.11s\nFold 1, Epoch 2, Batch 180, Loss: 3.3972, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 2, Batch 190, Loss: 3.8859, LR: 0.001000, Batch Time: 0.10s\nFold 1, Epoch 2, Batch 200, Loss: 3.3078, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 2, Batch 210, Loss: 4.7074, LR: 0.001000, Batch Time: 0.11s\nFold 1, Epoch 2, Batch 220, Loss: 3.9557, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 2, Batch 230, Loss: 2.7779, LR: 0.001000, Batch Time: 0.11s\nFold 1, Epoch 2, Batch 240, Loss: 3.7424, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 2, Batch 250, Loss: 4.3845, LR: 0.001000, Batch Time: 0.11s\nFold 1, Epoch 2, Batch 260, Loss: 3.6159, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 2, Batch 270, Loss: 2.9509, LR: 0.001000, Batch Time: 0.11s\nFold 1, Epoch 2, Batch 280, Loss: 2.4054, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 2, Batch 290, Loss: 3.3837, LR: 0.001000, Batch Time: 0.11s\nFold 1, Epoch 2, Batch 300, Loss: 2.6327, LR: 0.001000, Batch Time: 0.13s\nFold 1, Epoch 2, Batch 310, Loss: 4.4088, LR: 0.001000, Batch Time: 0.11s\nFold 1, Epoch 2, Batch 320, Loss: 2.8818, LR: 0.001000, Batch Time: 0.13s\nFold 1, Epoch 2, Batch 330, Loss: 3.3958, LR: 0.001000, Batch Time: 0.11s\nFold 1, Epoch 2, Batch 340, Loss: 2.7799, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 2, Batch 350, Loss: 3.7365, LR: 0.001000, Batch Time: 0.11s\nFold 1, Epoch 2, Batch 360, Loss: 2.8632, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 2, Batch 370, Loss: 3.5797, LR: 0.001000, Batch Time: 0.11s\nFold 1, Epoch 2, Batch 380, Loss: 3.7509, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 2, Batch 390, Loss: 3.2869, LR: 0.001000, Batch Time: 0.11s\nFold 1, Epoch 2, Batch 400, Loss: 3.8414, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 2, Batch 410, Loss: 4.7925, LR: 0.001000, Batch Time: 0.11s\nFold 1, Epoch 2, Batch 420, Loss: 3.4649, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 2, Batch 430, Loss: 4.8899, LR: 0.001000, Batch Time: 0.11s\nFold 1, Epoch 2, Batch 440, Loss: 3.7338, LR: 0.001000, Batch Time: 0.12s\nSkipped ID 12347: Image file /kaggle/input/fashion-product-images-dataset/fashion-dataset/images/12347.jpg not found\nFold 1, Epoch 2, Batch 450, Loss: 3.5395, LR: 0.001000, Batch Time: 0.11s\nFold 1, Epoch 2, Batch 460, Loss: 3.7892, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 2, Batch 470, Loss: 3.7154, LR: 0.001000, Batch Time: 0.11s\nSkipped ID 39425: Image file /kaggle/input/fashion-product-images-dataset/fashion-dataset/images/39425.jpg not found\nFold 1, Epoch 2, Batch 480, Loss: 4.2318, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 2, Batch 490, Loss: 3.4574, LR: 0.001000, Batch Time: 0.11s\nFold 1, Epoch 2, Batch 500, Loss: 3.2437, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 2, Batch 510, Loss: 3.1997, LR: 0.001000, Batch Time: 0.11s\nFold 1, Epoch 2, Batch 520, Loss: 3.6139, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 2, Batch 530, Loss: 2.7750, LR: 0.001000, Batch Time: 0.13s\nFold 1, Epoch 2, Batch 540, Loss: 3.3969, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 2, Batch 550, Loss: 3.4050, LR: 0.001000, Batch Time: 0.11s\nFold 1, Epoch 2, Batch 560, Loss: 5.1753, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 2, Batch 570, Loss: 3.2341, LR: 0.001000, Batch Time: 0.11s\nFold 1, Epoch 2, Batch 580, Loss: 3.3607, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 2, Batch 590, Loss: 4.2131, LR: 0.001000, Batch Time: 0.11s\nFold 1, Epoch 2, Batch 600, Loss: 4.6802, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 2, Batch 610, Loss: 3.2233, LR: 0.001000, Batch Time: 0.11s\nFold 1, Epoch 2, Batch 620, Loss: 4.9963, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 2, Batch 630, Loss: 3.0906, LR: 0.001000, Batch Time: 0.11s\nFold 1, Epoch 2, Batch 640, Loss: 3.1692, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 2, Batch 650, Loss: 3.2997, LR: 0.001000, Batch Time: 0.11s\nFold 1, Epoch 2, Batch 660, Loss: 2.8513, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 2, Batch 670, Loss: 2.8852, LR: 0.001000, Batch Time: 0.11s\nFold 1, Epoch 2, Batch 680, Loss: 2.3656, LR: 0.001000, Batch Time: 0.13s\nFold 1, Epoch 2, Batch 690, Loss: 2.6563, LR: 0.001000, Batch Time: 0.11s\nFold 1, Epoch 2, Batch 700, Loss: 3.8374, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 2, Batch 710, Loss: 2.8873, LR: 0.001000, Batch Time: 0.11s\nFold 1, Epoch 2, Batch 720, Loss: 3.6651, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 2, Batch 730, Loss: 3.4342, LR: 0.001000, Batch Time: 0.11s\nFold 1, Epoch 2, Batch 740, Loss: 2.6390, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 2, Batch 750, Loss: 3.3320, LR: 0.001000, Batch Time: 0.11s\nFold 1, Epoch 2, Batch 760, Loss: 2.9205, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 2, Batch 770, Loss: 3.2580, LR: 0.001000, Batch Time: 0.11s\nFold 1, Epoch 2, Batch 780, Loss: 3.4650, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 2, Batch 790, Loss: 3.9651, LR: 0.001000, Batch Time: 0.11s\nFold 1, Epoch 2, Batch 800, Loss: 3.9908, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 2, Batch 810, Loss: 4.7643, LR: 0.001000, Batch Time: 0.11s\nSkipped ID 39403: Image file /kaggle/input/fashion-product-images-dataset/fashion-dataset/images/39403.jpg not found\nFold 1, Epoch 2, Batch 820, Loss: 3.2556, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 2, Batch 830, Loss: 2.8700, LR: 0.001000, Batch Time: 0.11s\nFold 1, Epoch 2, Batch 840, Loss: 3.5178, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 2, Batch 850, Loss: 3.0586, LR: 0.001000, Batch Time: 0.11s\nFold 1, Epoch 2, Batch 860, Loss: 4.0965, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 2, Batch 870, Loss: 3.6184, LR: 0.001000, Batch Time: 0.11s\nFold 1, Epoch 2, Batch 880, Loss: 2.9021, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 2, Batch 890, Loss: 4.6257, LR: 0.001000, Batch Time: 0.11s\nFold 1, Epoch 2, Batch 900, Loss: 3.0436, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 2, Batch 910, Loss: 4.3902, LR: 0.001000, Batch Time: 0.11s\nFold 1, Epoch 2, Batch 920, Loss: 3.2306, LR: 0.001000, Batch Time: 0.13s\nSkipped ID 39401: Image file /kaggle/input/fashion-product-images-dataset/fashion-dataset/images/39401.jpg not found\nFold 1, Epoch 2, Batch 930, Loss: 3.4798, LR: 0.001000, Batch Time: 0.11s\nFold 1, Epoch 2, Batch 940, Loss: 2.7102, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 2, Train Loss: 3.5313, Epoch 2 Time: 436.02s\nFold 1, Validation Loss: 17.3720\nFold 1, Validation F1-Scores (Macro) - Color: 0.0734, Type: 0.0244, Season: 0.6497, Gender: 0.7043, Avg F1: 0.3630\nFold 1, Validation Precision (Macro) - Color: 0.0840, Type: 0.0279, Season: 0.6207, Gender: 0.6434\nFold 1, Validation Recall (Macro) - Color: 0.0986, Type: 0.0231, Season: 0.7103, Gender: 0.8213\nFold 1, Validation Accuracy - Color: 0.2340, Type: 0.0144, Season: 0.6254, Gender: 0.8415\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"},{"name":"stdout","text":"Fold 1, Epoch 3, Batch 10, Loss: 2.6097, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 3, Batch 20, Loss: 2.7511, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 3, Batch 30, Loss: 2.6516, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 3, Batch 40, Loss: 2.7273, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 3, Batch 50, Loss: 2.9999, LR: 0.001000, Batch Time: 0.11s\nFold 1, Epoch 3, Batch 60, Loss: 2.1630, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 3, Batch 70, Loss: 3.6720, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 3, Batch 80, Loss: 3.6472, LR: 0.001000, Batch Time: 0.13s\nFold 1, Epoch 3, Batch 90, Loss: 2.3933, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 3, Batch 100, Loss: 2.2442, LR: 0.001000, Batch Time: 0.13s\nFold 1, Epoch 3, Batch 110, Loss: 3.7841, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 3, Batch 120, Loss: 3.1039, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 3, Batch 130, Loss: 2.7479, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 3, Batch 140, Loss: 3.1748, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 3, Batch 150, Loss: 2.0318, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 3, Batch 160, Loss: 2.9101, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 3, Batch 170, Loss: 3.2456, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 3, Batch 180, Loss: 3.2119, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 3, Batch 190, Loss: 3.2264, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 3, Batch 200, Loss: 3.2021, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 3, Batch 210, Loss: 2.7450, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 3, Batch 220, Loss: 3.3944, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 3, Batch 230, Loss: 3.7923, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 3, Batch 240, Loss: 3.0547, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 3, Batch 250, Loss: 3.9787, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 3, Batch 260, Loss: 3.8323, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 3, Batch 270, Loss: 3.6461, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 3, Batch 280, Loss: 3.2312, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 3, Batch 290, Loss: 3.1610, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 3, Batch 300, Loss: 3.0631, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 3, Batch 310, Loss: 2.0767, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 3, Batch 320, Loss: 2.6728, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 3, Batch 330, Loss: 3.3091, LR: 0.001000, Batch Time: 0.13s\nFold 1, Epoch 3, Batch 340, Loss: 3.7673, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 3, Batch 350, Loss: 2.3531, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 3, Batch 360, Loss: 3.2294, LR: 0.001000, Batch Time: 0.12s\nSkipped ID 39401: Image file /kaggle/input/fashion-product-images-dataset/fashion-dataset/images/39401.jpg not found\nFold 1, Epoch 3, Batch 370, Loss: 3.6198, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 3, Batch 380, Loss: 3.7486, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 3, Batch 390, Loss: 4.8505, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 3, Batch 400, Loss: 2.9452, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 3, Batch 410, Loss: 4.0674, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 3, Batch 420, Loss: 4.7694, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 3, Batch 430, Loss: 3.9131, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 3, Batch 440, Loss: 2.5952, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 3, Batch 450, Loss: 3.7586, LR: 0.001000, Batch Time: 0.13s\nFold 1, Epoch 3, Batch 460, Loss: 3.4125, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 3, Batch 470, Loss: 3.2745, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 3, Batch 480, Loss: 4.2025, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 3, Batch 490, Loss: 3.9658, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 3, Batch 500, Loss: 2.5299, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 3, Batch 510, Loss: 3.3347, LR: 0.001000, Batch Time: 0.13s\nFold 1, Epoch 3, Batch 520, Loss: 3.1648, LR: 0.001000, Batch Time: 0.13s\nFold 1, Epoch 3, Batch 530, Loss: 2.2554, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 3, Batch 540, Loss: 2.8292, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 3, Batch 550, Loss: 2.9560, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 3, Batch 560, Loss: 2.6862, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 3, Batch 570, Loss: 2.7324, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 3, Batch 580, Loss: 3.8131, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 3, Batch 590, Loss: 3.9257, LR: 0.001000, Batch Time: 0.13s\nFold 1, Epoch 3, Batch 600, Loss: 2.3508, LR: 0.001000, Batch Time: 0.13s\nFold 1, Epoch 3, Batch 610, Loss: 3.5158, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 3, Batch 620, Loss: 2.7880, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 3, Batch 630, Loss: 2.9141, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 3, Batch 640, Loss: 4.0423, LR: 0.001000, Batch Time: 0.13s\nFold 1, Epoch 3, Batch 650, Loss: 3.7887, LR: 0.001000, Batch Time: 0.12s\nSkipped ID 39425: Image file /kaggle/input/fashion-product-images-dataset/fashion-dataset/images/39425.jpg not found\nFold 1, Epoch 3, Batch 660, Loss: 3.3422, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 3, Batch 670, Loss: 3.1856, LR: 0.001000, Batch Time: 0.13s\nFold 1, Epoch 3, Batch 680, Loss: 4.0878, LR: 0.001000, Batch Time: 0.13s\nFold 1, Epoch 3, Batch 690, Loss: 2.6908, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 3, Batch 700, Loss: 3.4988, LR: 0.001000, Batch Time: 0.11s\nFold 1, Epoch 3, Batch 710, Loss: 2.7922, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 3, Batch 720, Loss: 3.6995, LR: 0.001000, Batch Time: 0.11s\nFold 1, Epoch 3, Batch 730, Loss: 3.4404, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 3, Batch 740, Loss: 5.3868, LR: 0.001000, Batch Time: 0.11s\nFold 1, Epoch 3, Batch 750, Loss: 2.9024, LR: 0.001000, Batch Time: 0.13s\nFold 1, Epoch 3, Batch 760, Loss: 4.1734, LR: 0.001000, Batch Time: 0.11s\nFold 1, Epoch 3, Batch 770, Loss: 5.9763, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 3, Batch 780, Loss: 2.6739, LR: 0.001000, Batch Time: 0.11s\nFold 1, Epoch 3, Batch 790, Loss: 2.9691, LR: 0.001000, Batch Time: 0.12s\nSkipped ID 12347: Image file /kaggle/input/fashion-product-images-dataset/fashion-dataset/images/12347.jpg not found\nFold 1, Epoch 3, Batch 800, Loss: 3.1777, LR: 0.001000, Batch Time: 0.11s\nFold 1, Epoch 3, Batch 810, Loss: 2.6480, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 3, Batch 820, Loss: 2.3069, LR: 0.001000, Batch Time: 0.13s\nFold 1, Epoch 3, Batch 830, Loss: 3.5234, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 3, Batch 840, Loss: 2.3448, LR: 0.001000, Batch Time: 0.11s\nSkipped ID 39403: Image file /kaggle/input/fashion-product-images-dataset/fashion-dataset/images/39403.jpg not found\nFold 1, Epoch 3, Batch 850, Loss: 2.9483, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 3, Batch 860, Loss: 3.3015, LR: 0.001000, Batch Time: 0.11s\nFold 1, Epoch 3, Batch 870, Loss: 3.2421, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 3, Batch 880, Loss: 4.1365, LR: 0.001000, Batch Time: 0.11s\nFold 1, Epoch 3, Batch 890, Loss: 4.2761, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 3, Batch 900, Loss: 2.5887, LR: 0.001000, Batch Time: 0.11s\nFold 1, Epoch 3, Batch 910, Loss: 2.7123, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 3, Batch 920, Loss: 2.2094, LR: 0.001000, Batch Time: 0.11s\nFold 1, Epoch 3, Batch 930, Loss: 1.9214, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 3, Batch 940, Loss: 2.4673, LR: 0.001000, Batch Time: 0.11s\nFold 1, Epoch 3, Train Loss: 3.1338, Epoch 3 Time: 435.90s\nFold 1, Validation Loss: 18.4651\nFold 1, Validation F1-Scores (Macro) - Color: 0.0734, Type: 0.0311, Season: 0.6148, Gender: 0.7092, Avg F1: 0.3571\nFold 1, Validation Precision (Macro) - Color: 0.0868, Type: 0.0315, Season: 0.6026, Gender: 0.6579\nFold 1, Validation Recall (Macro) - Color: 0.0989, Type: 0.0320, Season: 0.7076, Gender: 0.8103\nFold 1, Validation Accuracy - Color: 0.2302, Type: 0.0162, Season: 0.5856, Gender: 0.8456\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"},{"name":"stdout","text":"Fold 1, Epoch 4, Batch 10, Loss: 2.4068, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 4, Batch 20, Loss: 3.1775, LR: 0.001000, Batch Time: 0.13s\nFold 1, Epoch 4, Batch 30, Loss: 2.8376, LR: 0.001000, Batch Time: 0.11s\nFold 1, Epoch 4, Batch 40, Loss: 3.8021, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 4, Batch 50, Loss: 2.8274, LR: 0.001000, Batch Time: 0.11s\nFold 1, Epoch 4, Batch 60, Loss: 3.2732, LR: 0.001000, Batch Time: 0.12s\nSkipped ID 39403: Image file /kaggle/input/fashion-product-images-dataset/fashion-dataset/images/39403.jpg not found\nFold 1, Epoch 4, Batch 70, Loss: 2.7063, LR: 0.001000, Batch Time: 0.11s\nFold 1, Epoch 4, Batch 80, Loss: 2.9099, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 4, Batch 90, Loss: 2.5356, LR: 0.001000, Batch Time: 0.11s\nFold 1, Epoch 4, Batch 100, Loss: 3.1718, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 4, Batch 110, Loss: 2.0863, LR: 0.001000, Batch Time: 0.11s\nFold 1, Epoch 4, Batch 120, Loss: 2.7202, LR: 0.001000, Batch Time: 0.13s\nFold 1, Epoch 4, Batch 130, Loss: 1.5733, LR: 0.001000, Batch Time: 0.11s\nFold 1, Epoch 4, Batch 140, Loss: 2.4084, LR: 0.001000, Batch Time: 0.13s\nFold 1, Epoch 4, Batch 150, Loss: 2.6594, LR: 0.001000, Batch Time: 0.11s\nSkipped ID 39425: Image file /kaggle/input/fashion-product-images-dataset/fashion-dataset/images/39425.jpg not found\nFold 1, Epoch 4, Batch 160, Loss: 2.2982, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 4, Batch 170, Loss: 2.8843, LR: 0.001000, Batch Time: 0.11s\nFold 1, Epoch 4, Batch 180, Loss: 2.7818, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 4, Batch 190, Loss: 3.4310, LR: 0.001000, Batch Time: 0.11s\nFold 1, Epoch 4, Batch 200, Loss: 3.4410, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 4, Batch 210, Loss: 2.5279, LR: 0.001000, Batch Time: 0.11s\nFold 1, Epoch 4, Batch 220, Loss: 2.2440, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 4, Batch 230, Loss: 2.2133, LR: 0.001000, Batch Time: 0.11s\nFold 1, Epoch 4, Batch 240, Loss: 1.5477, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 4, Batch 250, Loss: 3.2012, LR: 0.001000, Batch Time: 0.11s\nFold 1, Epoch 4, Batch 260, Loss: 3.1585, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 4, Batch 270, Loss: 2.6287, LR: 0.001000, Batch Time: 0.13s\nFold 1, Epoch 4, Batch 280, Loss: 4.0756, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 4, Batch 290, Loss: 3.0104, LR: 0.001000, Batch Time: 0.11s\nFold 1, Epoch 4, Batch 300, Loss: 4.0730, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 4, Batch 310, Loss: 2.8784, LR: 0.001000, Batch Time: 0.11s\nFold 1, Epoch 4, Batch 320, Loss: 2.8372, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 4, Batch 330, Loss: 2.4549, LR: 0.001000, Batch Time: 0.11s\nSkipped ID 12347: Image file /kaggle/input/fashion-product-images-dataset/fashion-dataset/images/12347.jpg not found\nFold 1, Epoch 4, Batch 340, Loss: 1.9580, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 4, Batch 350, Loss: 2.9355, LR: 0.001000, Batch Time: 0.11s\nFold 1, Epoch 4, Batch 360, Loss: 2.6630, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 4, Batch 370, Loss: 3.9794, LR: 0.001000, Batch Time: 0.11s\nFold 1, Epoch 4, Batch 380, Loss: 2.6049, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 4, Batch 390, Loss: 2.9893, LR: 0.001000, Batch Time: 0.11s\nFold 1, Epoch 4, Batch 400, Loss: 2.2998, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 4, Batch 410, Loss: 3.0443, LR: 0.001000, Batch Time: 0.11s\nFold 1, Epoch 4, Batch 420, Loss: 3.6456, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 4, Batch 430, Loss: 3.8245, LR: 0.001000, Batch Time: 0.11s\nFold 1, Epoch 4, Batch 440, Loss: 2.4516, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 4, Batch 450, Loss: 3.0584, LR: 0.001000, Batch Time: 0.11s\nFold 1, Epoch 4, Batch 460, Loss: 3.8696, LR: 0.001000, Batch Time: 0.13s\nFold 1, Epoch 4, Batch 470, Loss: 2.3805, LR: 0.001000, Batch Time: 0.11s\nFold 1, Epoch 4, Batch 480, Loss: 2.0937, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 4, Batch 490, Loss: 3.8006, LR: 0.001000, Batch Time: 0.11s\nFold 1, Epoch 4, Batch 500, Loss: 3.2141, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 4, Batch 510, Loss: 1.8320, LR: 0.001000, Batch Time: 0.11s\nFold 1, Epoch 4, Batch 520, Loss: 2.8376, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 4, Batch 530, Loss: 3.2298, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 4, Batch 540, Loss: 2.6514, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 4, Batch 550, Loss: 2.8528, LR: 0.001000, Batch Time: 0.11s\nFold 1, Epoch 4, Batch 560, Loss: 2.9207, LR: 0.001000, Batch Time: 0.13s\nFold 1, Epoch 4, Batch 570, Loss: 3.1158, LR: 0.001000, Batch Time: 0.11s\nFold 1, Epoch 4, Batch 580, Loss: 2.4564, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 4, Batch 590, Loss: 3.3089, LR: 0.001000, Batch Time: 0.11s\nFold 1, Epoch 4, Batch 600, Loss: 2.3793, LR: 0.001000, Batch Time: 0.13s\nFold 1, Epoch 4, Batch 610, Loss: 2.2714, LR: 0.001000, Batch Time: 0.11s\nFold 1, Epoch 4, Batch 620, Loss: 2.0233, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 4, Batch 630, Loss: 2.7853, LR: 0.001000, Batch Time: 0.11s\nFold 1, Epoch 4, Batch 640, Loss: 2.7016, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 4, Batch 650, Loss: 2.3048, LR: 0.001000, Batch Time: 0.11s\nFold 1, Epoch 4, Batch 660, Loss: 1.7584, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 4, Batch 670, Loss: 2.8983, LR: 0.001000, Batch Time: 0.11s\nFold 1, Epoch 4, Batch 680, Loss: 2.7157, LR: 0.001000, Batch Time: 0.13s\nFold 1, Epoch 4, Batch 690, Loss: 2.3699, LR: 0.001000, Batch Time: 0.11s\nFold 1, Epoch 4, Batch 700, Loss: 2.7339, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 4, Batch 710, Loss: 2.5195, LR: 0.001000, Batch Time: 0.11s\nFold 1, Epoch 4, Batch 720, Loss: 3.4848, LR: 0.001000, Batch Time: 0.12s\nSkipped ID 39401: Image file /kaggle/input/fashion-product-images-dataset/fashion-dataset/images/39401.jpg not found\nFold 1, Epoch 4, Batch 730, Loss: 2.3888, LR: 0.001000, Batch Time: 0.11s\nFold 1, Epoch 4, Batch 740, Loss: 2.5303, LR: 0.001000, Batch Time: 0.13s\nFold 1, Epoch 4, Batch 750, Loss: 2.2384, LR: 0.001000, Batch Time: 0.11s\nFold 1, Epoch 4, Batch 760, Loss: 3.3833, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 4, Batch 770, Loss: 2.3632, LR: 0.001000, Batch Time: 0.11s\nFold 1, Epoch 4, Batch 780, Loss: 2.3301, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 4, Batch 790, Loss: 2.4872, LR: 0.001000, Batch Time: 0.11s\nFold 1, Epoch 4, Batch 800, Loss: 3.1338, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 4, Batch 810, Loss: 3.0992, LR: 0.001000, Batch Time: 0.11s\nFold 1, Epoch 4, Batch 820, Loss: 2.8070, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 4, Batch 830, Loss: 1.8864, LR: 0.001000, Batch Time: 0.11s\nFold 1, Epoch 4, Batch 840, Loss: 2.7140, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 4, Batch 850, Loss: 3.8635, LR: 0.001000, Batch Time: 0.11s\nFold 1, Epoch 4, Batch 860, Loss: 2.7282, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 4, Batch 870, Loss: 2.7123, LR: 0.001000, Batch Time: 0.11s\nFold 1, Epoch 4, Batch 880, Loss: 2.5730, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 4, Batch 890, Loss: 3.3546, LR: 0.001000, Batch Time: 0.11s\nFold 1, Epoch 4, Batch 900, Loss: 2.6379, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 4, Batch 910, Loss: 2.6510, LR: 0.001000, Batch Time: 0.11s\nFold 1, Epoch 4, Batch 920, Loss: 2.5329, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 4, Batch 930, Loss: 3.3094, LR: 0.001000, Batch Time: 0.11s\nFold 1, Epoch 4, Batch 940, Loss: 2.3735, LR: 0.001000, Batch Time: 0.12s\nFold 1, Epoch 4, Train Loss: 2.8612, Epoch 4 Time: 433.55s\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"},{"name":"stdout","text":"Fold 1, Validation Loss: 20.6303\nFold 1, Validation F1-Scores (Macro) - Color: 0.0817, Type: 0.0328, Season: 0.6667, Gender: 0.7146, Avg F1: 0.3739\nFold 1, Validation Precision (Macro) - Color: 0.0922, Type: 0.0377, Season: 0.6377, Gender: 0.6564\nFold 1, Validation Recall (Macro) - Color: 0.1234, Type: 0.0385, Season: 0.7168, Gender: 0.8197\nFold 1, Validation Accuracy - Color: 0.2603, Type: 0.0182, Season: 0.6497, Gender: 0.8586\nEarly stopping triggered for Fold 1\nFold 2/5\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Fold 2, Epoch 1, Batch 10, Loss: 9.6210, LR: 0.001000, Batch Time: 0.12s\nFold 2, Epoch 1, Batch 20, Loss: 7.3753, LR: 0.001000, Batch Time: 0.12s\nFold 2, Epoch 1, Batch 30, Loss: 8.0572, LR: 0.001000, Batch Time: 0.13s\nFold 2, Epoch 1, Batch 40, Loss: 8.0563, LR: 0.001000, Batch Time: 0.11s\nFold 2, Epoch 1, Batch 50, Loss: 7.4747, LR: 0.001000, Batch Time: 0.12s\nFold 2, Epoch 1, Batch 60, Loss: 8.0587, LR: 0.001000, Batch Time: 0.13s\nFold 2, Epoch 1, Batch 70, Loss: 8.3885, LR: 0.001000, Batch Time: 0.12s\nFold 2, Epoch 1, Batch 80, Loss: 5.5247, LR: 0.001000, Batch Time: 0.11s\nFold 2, Epoch 1, Batch 90, Loss: 5.8194, LR: 0.001000, Batch Time: 0.13s\nFold 2, Epoch 1, Batch 100, Loss: 6.0073, LR: 0.001000, Batch Time: 0.11s\nFold 2, Epoch 1, Batch 110, Loss: 5.5881, LR: 0.001000, Batch Time: 0.11s\nFold 2, Epoch 1, Batch 120, Loss: 7.1520, LR: 0.001000, Batch Time: 0.11s\nFold 2, Epoch 1, Batch 130, Loss: 8.1553, LR: 0.001000, Batch Time: 0.12s\nFold 2, Epoch 1, Batch 140, Loss: 5.7137, LR: 0.001000, Batch Time: 0.11s\nFold 2, Epoch 1, Batch 150, Loss: 7.4914, LR: 0.001000, Batch Time: 0.12s\nFold 2, Epoch 1, Batch 160, Loss: 4.8330, LR: 0.001000, Batch Time: 0.11s\nFold 2, Epoch 1, Batch 170, Loss: 4.8270, LR: 0.001000, Batch Time: 0.12s\nFold 2, Epoch 1, Batch 180, Loss: 6.9667, LR: 0.001000, Batch Time: 0.12s\nFold 2, Epoch 1, Batch 190, Loss: 4.9919, LR: 0.001000, Batch Time: 0.12s\nFold 2, Epoch 1, Batch 200, Loss: 6.5092, LR: 0.001000, Batch Time: 0.12s\nFold 2, Epoch 1, Batch 210, Loss: 4.5774, LR: 0.001000, Batch Time: 0.12s\nFold 2, Epoch 1, Batch 220, Loss: 4.7589, LR: 0.001000, Batch Time: 0.11s\nFold 2, Epoch 1, Batch 230, Loss: 4.4001, LR: 0.001000, Batch Time: 0.13s\nSkipped ID 12347: Image file /kaggle/input/fashion-product-images-dataset/fashion-dataset/images/12347.jpg not found\nFold 2, Epoch 1, Batch 240, Loss: 3.5491, LR: 0.001000, Batch Time: 0.11s\nFold 2, Epoch 1, Batch 250, Loss: 9.4648, LR: 0.001000, Batch Time: 0.12s\nFold 2, Epoch 1, Batch 260, Loss: 5.7830, LR: 0.001000, Batch Time: 0.12s\nFold 2, Epoch 1, Batch 270, Loss: 4.4537, LR: 0.001000, Batch Time: 0.13s\nFold 2, Epoch 1, Batch 280, Loss: 4.1962, LR: 0.001000, Batch Time: 0.12s\nFold 2, Epoch 1, Batch 290, Loss: 4.5858, LR: 0.001000, Batch Time: 0.12s\nSkipped ID 39403: Image file /kaggle/input/fashion-product-images-dataset/fashion-dataset/images/39403.jpg not found\nFold 2, Epoch 1, Batch 300, Loss: 4.6212, LR: 0.001000, Batch Time: 0.12s\nFold 2, Epoch 1, Batch 310, Loss: 4.8933, LR: 0.001000, Batch Time: 0.11s\nFold 2, Epoch 1, Batch 320, Loss: 4.3309, LR: 0.001000, Batch Time: 0.12s\nFold 2, Epoch 1, Batch 330, Loss: 5.4245, LR: 0.001000, Batch Time: 0.13s\nFold 2, Epoch 1, Batch 340, Loss: 3.7080, LR: 0.001000, Batch Time: 0.12s\nFold 2, Epoch 1, Batch 350, Loss: 4.3411, LR: 0.001000, Batch Time: 0.12s\nFold 2, Epoch 1, Batch 360, Loss: 4.0501, LR: 0.001000, Batch Time: 0.12s\nFold 2, Epoch 1, Batch 370, Loss: 5.2262, LR: 0.001000, Batch Time: 0.12s\nFold 2, Epoch 1, Batch 380, Loss: 10.2848, LR: 0.001000, Batch Time: 0.13s\nFold 2, Epoch 1, Batch 390, Loss: 3.2983, LR: 0.001000, Batch Time: 0.12s\nFold 2, Epoch 1, Batch 400, Loss: 5.2233, LR: 0.001000, Batch Time: 0.12s\nFold 2, Epoch 1, Batch 410, Loss: 4.2518, LR: 0.001000, Batch Time: 0.13s\nFold 2, Epoch 1, Batch 420, Loss: 2.9257, LR: 0.001000, Batch Time: 0.13s\nFold 2, Epoch 1, Batch 430, Loss: 3.8460, LR: 0.001000, Batch Time: 0.13s\nFold 2, Epoch 1, Batch 440, Loss: 4.7228, LR: 0.001000, Batch Time: 0.13s\nFold 2, Epoch 1, Batch 450, Loss: 4.1566, LR: 0.001000, Batch Time: 0.12s\nFold 2, Epoch 1, Batch 460, Loss: 4.4425, LR: 0.001000, Batch Time: 0.12s\nFold 2, Epoch 1, Batch 470, Loss: 4.1462, LR: 0.001000, Batch Time: 0.12s\nFold 2, Epoch 1, Batch 480, Loss: 4.2221, LR: 0.001000, Batch Time: 0.11s\nFold 2, Epoch 1, Batch 490, Loss: 4.7316, LR: 0.001000, Batch Time: 0.12s\nFold 2, Epoch 1, Batch 500, Loss: 2.9625, LR: 0.001000, Batch Time: 0.11s\nFold 2, Epoch 1, Batch 510, Loss: 3.7466, LR: 0.001000, Batch Time: 0.12s\nFold 2, Epoch 1, Batch 520, Loss: 4.4653, LR: 0.001000, Batch Time: 0.11s\nFold 2, Epoch 1, Batch 530, Loss: 5.6404, LR: 0.001000, Batch Time: 0.12s\nFold 2, Epoch 1, Batch 540, Loss: 4.8102, LR: 0.001000, Batch Time: 0.12s\nFold 2, Epoch 1, Batch 550, Loss: 3.0594, LR: 0.001000, Batch Time: 0.12s\nFold 2, Epoch 1, Batch 560, Loss: 3.7613, LR: 0.001000, Batch Time: 0.11s\nFold 2, Epoch 1, Batch 570, Loss: 3.7622, LR: 0.001000, Batch Time: 0.13s\nFold 2, Epoch 1, Batch 580, Loss: 4.7339, LR: 0.001000, Batch Time: 0.11s\nFold 2, Epoch 1, Batch 590, Loss: 4.8649, LR: 0.001000, Batch Time: 0.12s\nFold 2, Epoch 1, Batch 600, Loss: 4.2109, LR: 0.001000, Batch Time: 0.11s\nFold 2, Epoch 1, Batch 610, Loss: 3.7200, LR: 0.001000, Batch Time: 0.12s\nFold 2, Epoch 1, Batch 620, Loss: 3.7308, LR: 0.001000, Batch Time: 0.11s\nFold 2, Epoch 1, Batch 630, Loss: 3.4763, LR: 0.001000, Batch Time: 0.12s\nFold 2, Epoch 1, Batch 640, Loss: 4.4441, LR: 0.001000, Batch Time: 0.11s\nFold 2, Epoch 1, Batch 650, Loss: 3.5615, LR: 0.001000, Batch Time: 0.12s\nFold 2, Epoch 1, Batch 660, Loss: 2.6895, LR: 0.001000, Batch Time: 0.12s\nFold 2, Epoch 1, Batch 670, Loss: 3.7577, LR: 0.001000, Batch Time: 0.12s\nFold 2, Epoch 1, Batch 680, Loss: 4.1331, LR: 0.001000, Batch Time: 0.11s\nFold 2, Epoch 1, Batch 690, Loss: 3.4629, LR: 0.001000, Batch Time: 0.12s\nFold 2, Epoch 1, Batch 700, Loss: 3.2174, LR: 0.001000, Batch Time: 0.11s\nFold 2, Epoch 1, Batch 710, Loss: 3.4718, LR: 0.001000, Batch Time: 0.12s\nFold 2, Epoch 1, Batch 720, Loss: 3.6314, LR: 0.001000, Batch Time: 0.11s\nFold 2, Epoch 1, Batch 730, Loss: 4.3125, LR: 0.001000, Batch Time: 0.12s\nFold 2, Epoch 1, Batch 740, Loss: 3.8400, LR: 0.001000, Batch Time: 0.11s\nFold 2, Epoch 1, Batch 750, Loss: 4.3273, LR: 0.001000, Batch Time: 0.12s\nFold 2, Epoch 1, Batch 760, Loss: 4.4114, LR: 0.001000, Batch Time: 0.11s\nFold 2, Epoch 1, Batch 770, Loss: 3.8639, LR: 0.001000, Batch Time: 0.12s\nFold 2, Epoch 1, Batch 780, Loss: 4.9630, LR: 0.001000, Batch Time: 0.11s\nFold 2, Epoch 1, Batch 790, Loss: 4.2845, LR: 0.001000, Batch Time: 0.12s\nFold 2, Epoch 1, Batch 800, Loss: 3.4278, LR: 0.001000, Batch Time: 0.11s\nFold 2, Epoch 1, Batch 810, Loss: 5.2724, LR: 0.001000, Batch Time: 0.13s\nFold 2, Epoch 1, Batch 820, Loss: 4.3911, LR: 0.001000, Batch Time: 0.11s\nFold 2, Epoch 1, Batch 830, Loss: 2.9615, LR: 0.001000, Batch Time: 0.12s\nFold 2, Epoch 1, Batch 840, Loss: 3.4875, LR: 0.001000, Batch Time: 0.12s\nFold 2, Epoch 1, Batch 850, Loss: 3.8009, LR: 0.001000, Batch Time: 0.12s\nFold 2, Epoch 1, Batch 860, Loss: 5.1663, LR: 0.001000, Batch Time: 0.11s\nFold 2, Epoch 1, Batch 870, Loss: 2.9788, LR: 0.001000, Batch Time: 0.12s\nFold 2, Epoch 1, Batch 880, Loss: 3.3632, LR: 0.001000, Batch Time: 0.11s\nFold 2, Epoch 1, Batch 890, Loss: 3.7718, LR: 0.001000, Batch Time: 0.12s\nFold 2, Epoch 1, Batch 900, Loss: 2.6594, LR: 0.001000, Batch Time: 0.12s\nFold 2, Epoch 1, Batch 910, Loss: 4.1231, LR: 0.001000, Batch Time: 0.12s\nFold 2, Epoch 1, Batch 920, Loss: 3.6020, LR: 0.001000, Batch Time: 0.12s\nFold 2, Epoch 1, Batch 930, Loss: 3.5956, LR: 0.001000, Batch Time: 0.13s\nFold 2, Epoch 1, Batch 940, Loss: 4.2038, LR: 0.001000, Batch Time: 0.13s\nFold 2, Epoch 1, Train Loss: 4.9794, Epoch 1 Time: 450.20s\nSkipped ID 39401: Image file /kaggle/input/fashion-product-images-dataset/fashion-dataset/images/39401.jpg not found\nSkipped ID 39425: Image file /kaggle/input/fashion-product-images-dataset/fashion-dataset/images/39425.jpg not found\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"},{"name":"stdout","text":"Fold 2, Validation Loss: 18.2874\nFold 2, Validation F1-Scores (Macro) - Color: 0.0663, Type: 0.0198, Season: 0.6328, Gender: 0.6733, Avg F1: 0.3481\nFold 2, Validation Precision (Macro) - Color: 0.0684, Type: 0.0271, Season: 0.6036, Gender: 0.6162\nFold 2, Validation Recall (Macro) - Color: 0.0869, Type: 0.0325, Season: 0.6900, Gender: 0.7864\nFold 2, Validation Accuracy - Color: 0.2426, Type: 0.0146, Season: 0.6267, Gender: 0.8424\nSaved best model from Fold 2 at /kaggle/working/best_model.pth (Avg F1: 0.3481)\nFold 2, Epoch 2, Batch 10, Loss: 3.9077, LR: 0.001000, Batch Time: 0.12s\nFold 2, Epoch 2, Batch 20, Loss: 3.7965, LR: 0.001000, Batch Time: 0.12s\nFold 2, Epoch 2, Batch 30, Loss: 2.6804, LR: 0.001000, Batch Time: 0.13s\nFold 2, Epoch 2, Batch 40, Loss: 3.7320, LR: 0.001000, Batch Time: 0.13s\nFold 2, Epoch 2, Batch 50, Loss: 2.9686, LR: 0.001000, Batch Time: 0.12s\nFold 2, Epoch 2, Batch 60, Loss: 3.9903, LR: 0.001000, Batch Time: 0.11s\nFold 2, Epoch 2, Batch 70, Loss: 3.1025, LR: 0.001000, Batch Time: 0.12s\nFold 2, Epoch 2, Batch 80, Loss: 2.5888, LR: 0.001000, Batch Time: 0.12s\nFold 2, Epoch 2, Batch 90, Loss: 3.8090, LR: 0.001000, Batch Time: 0.13s\nFold 2, Epoch 2, Batch 100, Loss: 5.9453, LR: 0.001000, Batch Time: 0.11s\nFold 2, Epoch 2, Batch 110, Loss: 6.0560, LR: 0.001000, Batch Time: 0.11s\nFold 2, Epoch 2, Batch 120, Loss: 3.3688, LR: 0.001000, Batch Time: 0.11s\nFold 2, Epoch 2, Batch 130, Loss: 3.4359, LR: 0.001000, Batch Time: 0.13s\nFold 2, Epoch 2, Batch 140, Loss: 4.9170, LR: 0.001000, Batch Time: 0.11s\nFold 2, Epoch 2, Batch 150, Loss: 4.9675, LR: 0.001000, Batch Time: 0.13s\nFold 2, Epoch 2, Batch 160, Loss: 3.5824, LR: 0.001000, Batch Time: 0.11s\nFold 2, Epoch 2, Batch 170, Loss: 2.6038, LR: 0.001000, Batch Time: 0.12s\nFold 2, Epoch 2, Batch 180, Loss: 4.1963, LR: 0.001000, Batch Time: 0.12s\nFold 2, Epoch 2, Batch 190, Loss: 3.5603, LR: 0.001000, Batch Time: 0.12s\nFold 2, Epoch 2, Batch 200, Loss: 3.7300, LR: 0.001000, Batch Time: 0.12s\nFold 2, Epoch 2, Batch 210, Loss: 2.6934, LR: 0.001000, Batch Time: 0.13s\nFold 2, Epoch 2, Batch 220, Loss: 5.1853, LR: 0.001000, Batch Time: 0.12s\nFold 2, Epoch 2, Batch 230, Loss: 3.8203, LR: 0.001000, Batch Time: 0.12s\nFold 2, Epoch 2, Batch 240, Loss: 4.4267, LR: 0.001000, Batch Time: 0.12s\nFold 2, Epoch 2, Batch 250, Loss: 3.3014, LR: 0.001000, Batch Time: 0.13s\nFold 2, Epoch 2, Batch 260, Loss: 2.5522, LR: 0.001000, Batch Time: 0.12s\nFold 2, Epoch 2, Batch 270, Loss: 3.0403, LR: 0.001000, Batch Time: 0.13s\nFold 2, Epoch 2, Batch 280, Loss: 3.7396, LR: 0.001000, Batch Time: 0.12s\nFold 2, Epoch 2, Batch 290, Loss: 2.7520, LR: 0.001000, Batch Time: 0.12s\nFold 2, Epoch 2, Batch 300, Loss: 3.2972, LR: 0.001000, Batch Time: 0.12s\nFold 2, Epoch 2, Batch 310, Loss: 3.0814, LR: 0.001000, Batch Time: 0.12s\nFold 2, Epoch 2, Batch 320, Loss: 2.7938, LR: 0.001000, Batch Time: 0.12s\nFold 2, Epoch 2, Batch 330, Loss: 2.9108, LR: 0.001000, Batch Time: 0.13s\nFold 2, Epoch 2, Batch 340, Loss: 6.5748, LR: 0.001000, Batch Time: 0.12s\nFold 2, Epoch 2, Batch 350, Loss: 4.0865, LR: 0.001000, Batch Time: 0.13s\nFold 2, Epoch 2, Batch 360, Loss: 4.1149, LR: 0.001000, Batch Time: 0.12s\nFold 2, Epoch 2, Batch 370, Loss: 4.0856, LR: 0.001000, Batch Time: 0.13s\nFold 2, Epoch 2, Batch 380, Loss: 3.4911, LR: 0.001000, Batch Time: 0.13s\nFold 2, Epoch 2, Batch 390, Loss: 3.1508, LR: 0.001000, Batch Time: 0.12s\nFold 2, Epoch 2, Batch 400, Loss: 3.8296, LR: 0.001000, Batch Time: 0.11s\nFold 2, Epoch 2, Batch 410, Loss: 3.2248, LR: 0.001000, Batch Time: 0.12s\nFold 2, Epoch 2, Batch 420, Loss: 3.2426, LR: 0.001000, Batch Time: 0.11s\nFold 2, Epoch 2, Batch 430, Loss: 2.8032, LR: 0.001000, Batch Time: 0.11s\nFold 2, Epoch 2, Batch 440, Loss: 4.1033, LR: 0.001000, Batch Time: 0.11s\nFold 2, Epoch 2, Batch 450, Loss: 3.5351, LR: 0.001000, Batch Time: 0.11s\nFold 2, Epoch 2, Batch 460, Loss: 3.0505, LR: 0.001000, Batch Time: 0.11s\nFold 2, Epoch 2, Batch 470, Loss: 2.8523, LR: 0.001000, Batch Time: 0.11s\nSkipped ID 12347: Image file /kaggle/input/fashion-product-images-dataset/fashion-dataset/images/12347.jpg not found\nFold 2, Epoch 2, Batch 480, Loss: 4.7041, LR: 0.001000, Batch Time: 0.11s\nFold 2, Epoch 2, Batch 490, Loss: 3.0656, LR: 0.001000, Batch Time: 0.11s\nFold 2, Epoch 2, Batch 500, Loss: 3.0746, LR: 0.001000, Batch Time: 0.11s\nFold 2, Epoch 2, Batch 510, Loss: 3.2632, LR: 0.001000, Batch Time: 0.11s\nFold 2, Epoch 2, Batch 520, Loss: 3.3738, LR: 0.001000, Batch Time: 0.13s\nFold 2, Epoch 2, Batch 530, Loss: 3.0241, LR: 0.001000, Batch Time: 0.11s\nFold 2, Epoch 2, Batch 540, Loss: 2.5894, LR: 0.001000, Batch Time: 0.13s\nFold 2, Epoch 2, Batch 550, Loss: 3.2302, LR: 0.001000, Batch Time: 0.12s\nFold 2, Epoch 2, Batch 560, Loss: 3.6533, LR: 0.001000, Batch Time: 0.13s\nFold 2, Epoch 2, Batch 570, Loss: 3.7168, LR: 0.001000, Batch Time: 0.12s\nFold 2, Epoch 2, Batch 580, Loss: 4.8884, LR: 0.001000, Batch Time: 0.13s\nFold 2, Epoch 2, Batch 590, Loss: 3.0265, LR: 0.001000, Batch Time: 0.12s\nFold 2, Epoch 2, Batch 600, Loss: 3.3456, LR: 0.001000, Batch Time: 0.11s\nFold 2, Epoch 2, Batch 610, Loss: 2.9758, LR: 0.001000, Batch Time: 0.13s\nFold 2, Epoch 2, Batch 620, Loss: 2.6766, LR: 0.001000, Batch Time: 0.11s\nFold 2, Epoch 2, Batch 630, Loss: 3.0999, LR: 0.001000, Batch Time: 0.13s\nFold 2, Epoch 2, Batch 640, Loss: 4.4338, LR: 0.001000, Batch Time: 0.13s\nFold 2, Epoch 2, Batch 650, Loss: 3.7884, LR: 0.001000, Batch Time: 0.12s\nFold 2, Epoch 2, Batch 660, Loss: 4.4279, LR: 0.001000, Batch Time: 0.11s\nFold 2, Epoch 2, Batch 670, Loss: 4.3336, LR: 0.001000, Batch Time: 0.12s\nFold 2, Epoch 2, Batch 680, Loss: 3.3906, LR: 0.001000, Batch Time: 0.11s\nFold 2, Epoch 2, Batch 690, Loss: 2.4237, LR: 0.001000, Batch Time: 0.11s\nFold 2, Epoch 2, Batch 700, Loss: 2.9974, LR: 0.001000, Batch Time: 0.11s\nSkipped ID 39403: Image file /kaggle/input/fashion-product-images-dataset/fashion-dataset/images/39403.jpg not found\nFold 2, Epoch 2, Batch 710, Loss: 3.4594, LR: 0.001000, Batch Time: 0.11s\nFold 2, Epoch 2, Batch 720, Loss: 2.7497, LR: 0.001000, Batch Time: 0.11s\nFold 2, Epoch 2, Batch 730, Loss: 3.4479, LR: 0.001000, Batch Time: 0.12s\nFold 2, Epoch 2, Batch 740, Loss: 3.0027, LR: 0.001000, Batch Time: 0.13s\nFold 2, Epoch 2, Batch 750, Loss: 3.6438, LR: 0.001000, Batch Time: 0.12s\nFold 2, Epoch 2, Batch 760, Loss: 3.5923, LR: 0.001000, Batch Time: 0.10s\nFold 2, Epoch 2, Batch 770, Loss: 2.4655, LR: 0.001000, Batch Time: 0.13s\nFold 2, Epoch 2, Batch 780, Loss: 3.4697, LR: 0.001000, Batch Time: 0.11s\nFold 2, Epoch 2, Batch 790, Loss: 3.3082, LR: 0.001000, Batch Time: 0.12s\nFold 2, Epoch 2, Batch 800, Loss: 3.0368, LR: 0.001000, Batch Time: 0.11s\nFold 2, Epoch 2, Batch 810, Loss: 2.6257, LR: 0.001000, Batch Time: 0.12s\nFold 2, Epoch 2, Batch 820, Loss: 2.7327, LR: 0.001000, Batch Time: 0.11s\nFold 2, Epoch 2, Batch 830, Loss: 2.9969, LR: 0.001000, Batch Time: 0.12s\nFold 2, Epoch 2, Batch 840, Loss: 3.1370, LR: 0.001000, Batch Time: 0.11s\nFold 2, Epoch 2, Batch 850, Loss: 3.8654, LR: 0.001000, Batch Time: 0.12s\nFold 2, Epoch 2, Batch 860, Loss: 2.5669, LR: 0.001000, Batch Time: 0.11s\nFold 2, Epoch 2, Batch 870, Loss: 2.5565, LR: 0.001000, Batch Time: 0.12s\nFold 2, Epoch 2, Batch 880, Loss: 2.7848, LR: 0.001000, Batch Time: 0.11s\nFold 2, Epoch 2, Batch 890, Loss: 3.0502, LR: 0.001000, Batch Time: 0.12s\nFold 2, Epoch 2, Batch 900, Loss: 4.3604, LR: 0.001000, Batch Time: 0.11s\nFold 2, Epoch 2, Batch 910, Loss: 3.5808, LR: 0.001000, Batch Time: 0.12s\nFold 2, Epoch 2, Batch 920, Loss: 2.2430, LR: 0.001000, Batch Time: 0.12s\nFold 2, Epoch 2, Batch 930, Loss: 4.3732, LR: 0.001000, Batch Time: 0.12s\nFold 2, Epoch 2, Batch 940, Loss: 2.7993, LR: 0.001000, Batch Time: 0.13s\nFold 2, Epoch 2, Train Loss: 3.5303, Epoch 2 Time: 568.57s\nSkipped ID 39401: Image file /kaggle/input/fashion-product-images-dataset/fashion-dataset/images/39401.jpg not found\nSkipped ID 39425: Image file /kaggle/input/fashion-product-images-dataset/fashion-dataset/images/39425.jpg not found\nFold 2, Validation Loss: 19.9857\nFold 2, Validation F1-Scores (Macro) - Color: 0.0712, Type: 0.0252, Season: 0.6544, Gender: 0.6915, Avg F1: 0.3606\nFold 2, Validation Precision (Macro) - Color: 0.0785, Type: 0.0298, Season: 0.6330, Gender: 0.6325\nFold 2, Validation Recall (Macro) - Color: 0.0915, Type: 0.0361, Season: 0.7005, Gender: 0.8098\nFold 2, Validation Accuracy - Color: 0.2485, Type: 0.0172, Season: 0.6238, Gender: 0.8482\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"},{"name":"stdout","text":"Fold 2, Epoch 3, Batch 10, Loss: 3.7274, LR: 0.001000, Batch Time: 0.11s\nFold 2, Epoch 3, Batch 20, Loss: 2.9910, LR: 0.001000, Batch Time: 0.13s\nFold 2, Epoch 3, Batch 30, Loss: 2.4251, LR: 0.001000, Batch Time: 0.11s\nFold 2, Epoch 3, Batch 40, Loss: 2.9676, LR: 0.001000, Batch Time: 0.12s\nFold 2, Epoch 3, Batch 50, Loss: 4.6254, LR: 0.001000, Batch Time: 0.11s\nFold 2, Epoch 3, Batch 60, Loss: 2.4867, LR: 0.001000, Batch Time: 0.12s\nFold 2, Epoch 3, Batch 70, Loss: 3.2761, LR: 0.001000, Batch Time: 0.11s\nFold 2, Epoch 3, Batch 80, Loss: 2.0207, LR: 0.001000, Batch Time: 0.12s\nFold 2, Epoch 3, Batch 90, Loss: 3.3797, LR: 0.001000, Batch Time: 0.11s\nFold 2, Epoch 3, Batch 100, Loss: 2.6337, LR: 0.001000, Batch Time: 0.12s\nFold 2, Epoch 3, Batch 110, Loss: 2.3788, LR: 0.001000, Batch Time: 0.11s\nFold 2, Epoch 3, Batch 120, Loss: 3.3205, LR: 0.001000, Batch Time: 0.12s\nFold 2, Epoch 3, Batch 130, Loss: 4.8689, LR: 0.001000, Batch Time: 0.11s\nFold 2, Epoch 3, Batch 140, Loss: 3.9754, LR: 0.001000, Batch Time: 0.13s\nFold 2, Epoch 3, Batch 150, Loss: 3.3224, LR: 0.001000, Batch Time: 0.13s\nFold 2, Epoch 3, Batch 160, Loss: 2.9535, LR: 0.001000, Batch Time: 0.12s\nFold 2, Epoch 3, Batch 170, Loss: 3.9876, LR: 0.001000, Batch Time: 0.13s\nFold 2, Epoch 3, Batch 180, Loss: 3.2235, LR: 0.001000, Batch Time: 0.12s\nFold 2, Epoch 3, Batch 190, Loss: 3.2635, LR: 0.001000, Batch Time: 0.13s\nSkipped ID 12347: Image file /kaggle/input/fashion-product-images-dataset/fashion-dataset/images/12347.jpg not found\nFold 2, Epoch 3, Batch 200, Loss: 2.9846, LR: 0.001000, Batch Time: 0.12s\nFold 2, Epoch 3, Batch 210, Loss: 3.3638, LR: 0.001000, Batch Time: 0.13s\nFold 2, Epoch 3, Batch 220, Loss: 3.0899, LR: 0.001000, Batch Time: 0.11s\nFold 2, Epoch 3, Batch 230, Loss: 3.7067, LR: 0.001000, Batch Time: 0.11s\nFold 2, Epoch 3, Batch 240, Loss: 3.6648, LR: 0.001000, Batch Time: 0.13s\nFold 2, Epoch 3, Batch 250, Loss: 2.3826, LR: 0.001000, Batch Time: 0.10s\nFold 2, Epoch 3, Batch 260, Loss: 2.4553, LR: 0.001000, Batch Time: 0.12s\nFold 2, Epoch 3, Batch 270, Loss: 2.8089, LR: 0.001000, Batch Time: 0.11s\nFold 2, Epoch 3, Batch 280, Loss: 2.7315, LR: 0.001000, Batch Time: 0.13s\nSkipped ID 39403: Image file /kaggle/input/fashion-product-images-dataset/fashion-dataset/images/39403.jpg not found\nFold 2, Epoch 3, Batch 290, Loss: 4.5710, LR: 0.001000, Batch Time: 0.11s\nFold 2, Epoch 3, Batch 300, Loss: 6.1823, LR: 0.001000, Batch Time: 0.12s\nFold 2, Epoch 3, Batch 310, Loss: 2.6606, LR: 0.001000, Batch Time: 0.11s\nFold 2, Epoch 3, Batch 320, Loss: 2.8652, LR: 0.001000, Batch Time: 0.13s\nFold 2, Epoch 3, Batch 330, Loss: 3.2778, LR: 0.001000, Batch Time: 0.11s\nFold 2, Epoch 3, Batch 340, Loss: 4.2298, LR: 0.001000, Batch Time: 0.12s\nFold 2, Epoch 3, Batch 350, Loss: 2.8188, LR: 0.001000, Batch Time: 0.11s\nFold 2, Epoch 3, Batch 360, Loss: 2.7386, LR: 0.001000, Batch Time: 0.12s\nFold 2, Epoch 3, Batch 370, Loss: 2.3851, LR: 0.001000, Batch Time: 0.11s\nFold 2, Epoch 3, Batch 380, Loss: 2.7549, LR: 0.001000, Batch Time: 0.13s\nFold 2, Epoch 3, Batch 390, Loss: 3.3244, LR: 0.001000, Batch Time: 0.11s\nFold 2, Epoch 3, Batch 400, Loss: 3.7606, LR: 0.001000, Batch Time: 0.12s\nFold 2, Epoch 3, Batch 410, Loss: 4.3628, LR: 0.001000, Batch Time: 0.11s\nFold 2, Epoch 3, Batch 420, Loss: 5.0952, LR: 0.001000, Batch Time: 0.12s\nFold 2, Epoch 3, Batch 430, Loss: 2.5666, LR: 0.001000, Batch Time: 0.11s\nFold 2, Epoch 3, Batch 440, Loss: 3.0978, LR: 0.001000, Batch Time: 0.11s\nFold 2, Epoch 3, Batch 450, Loss: 3.3405, LR: 0.001000, Batch Time: 0.11s\nFold 2, Epoch 3, Batch 460, Loss: 3.0963, LR: 0.001000, Batch Time: 0.11s\nFold 2, Epoch 3, Batch 470, Loss: 3.6814, LR: 0.001000, Batch Time: 0.11s\nFold 2, Epoch 3, Batch 480, Loss: 4.0260, LR: 0.001000, Batch Time: 0.11s\nFold 2, Epoch 3, Batch 490, Loss: 2.7907, LR: 0.001000, Batch Time: 0.13s\nFold 2, Epoch 3, Batch 500, Loss: 3.2142, LR: 0.001000, Batch Time: 0.11s\nFold 2, Epoch 3, Batch 510, Loss: 3.9828, LR: 0.001000, Batch Time: 0.12s\nFold 2, Epoch 3, Batch 520, Loss: 3.1674, LR: 0.001000, Batch Time: 0.11s\nFold 2, Epoch 3, Batch 530, Loss: 4.1591, LR: 0.001000, Batch Time: 0.12s\nFold 2, Epoch 3, Batch 540, Loss: 3.0936, LR: 0.001000, Batch Time: 0.13s\nFold 2, Epoch 3, Batch 550, Loss: 3.4059, LR: 0.001000, Batch Time: 0.12s\nFold 2, Epoch 3, Batch 560, Loss: 3.2305, LR: 0.001000, Batch Time: 0.13s\nFold 2, Epoch 3, Batch 570, Loss: 2.7112, LR: 0.001000, Batch Time: 0.12s\nFold 2, Epoch 3, Batch 580, Loss: 3.0036, LR: 0.001000, Batch Time: 0.12s\nFold 2, Epoch 3, Batch 590, Loss: 2.9694, LR: 0.001000, Batch Time: 0.12s\nFold 2, Epoch 3, Batch 600, Loss: 3.9793, LR: 0.001000, Batch Time: 0.11s\nFold 2, Epoch 3, Batch 610, Loss: 2.6939, LR: 0.001000, Batch Time: 0.13s\nFold 2, Epoch 3, Batch 620, Loss: 4.7488, LR: 0.001000, Batch Time: 0.13s\nFold 2, Epoch 3, Batch 630, Loss: 2.1614, LR: 0.001000, Batch Time: 0.12s\nFold 2, Epoch 3, Batch 640, Loss: 3.0082, LR: 0.001000, Batch Time: 0.11s\nFold 2, Epoch 3, Batch 650, Loss: 3.0476, LR: 0.001000, Batch Time: 0.12s\nFold 2, Epoch 3, Batch 660, Loss: 2.4444, LR: 0.001000, Batch Time: 0.11s\nFold 2, Epoch 3, Batch 670, Loss: 3.1212, LR: 0.001000, Batch Time: 0.12s\nFold 2, Epoch 3, Batch 680, Loss: 2.7799, LR: 0.001000, Batch Time: 0.11s\nFold 2, Epoch 3, Batch 690, Loss: 3.5620, LR: 0.001000, Batch Time: 0.12s\nFold 2, Epoch 3, Batch 700, Loss: 3.2261, LR: 0.001000, Batch Time: 0.11s\nFold 2, Epoch 3, Batch 710, Loss: 3.3112, LR: 0.001000, Batch Time: 0.12s\nFold 2, Epoch 3, Batch 720, Loss: 3.0019, LR: 0.001000, Batch Time: 0.11s\nFold 2, Epoch 3, Batch 730, Loss: 2.1594, LR: 0.001000, Batch Time: 0.12s\nFold 2, Epoch 3, Batch 740, Loss: 2.0779, LR: 0.001000, Batch Time: 0.11s\nFold 2, Epoch 3, Batch 750, Loss: 3.0597, LR: 0.001000, Batch Time: 0.12s\nFold 2, Epoch 3, Batch 760, Loss: 2.6814, LR: 0.001000, Batch Time: 0.13s\nFold 2, Epoch 3, Batch 770, Loss: 2.6249, LR: 0.001000, Batch Time: 0.13s\nFold 2, Epoch 3, Batch 780, Loss: 2.6537, LR: 0.001000, Batch Time: 0.13s\nFold 2, Epoch 3, Batch 790, Loss: 2.7964, LR: 0.001000, Batch Time: 0.12s\nFold 2, Epoch 3, Batch 800, Loss: 2.8667, LR: 0.001000, Batch Time: 0.13s\nFold 2, Epoch 3, Batch 810, Loss: 2.9797, LR: 0.001000, Batch Time: 0.12s\nFold 2, Epoch 3, Batch 820, Loss: 3.0581, LR: 0.001000, Batch Time: 0.13s\nFold 2, Epoch 3, Batch 830, Loss: 2.4405, LR: 0.001000, Batch Time: 0.12s\nFold 2, Epoch 3, Batch 840, Loss: 3.0523, LR: 0.001000, Batch Time: 0.11s\nFold 2, Epoch 3, Batch 850, Loss: 3.6663, LR: 0.001000, Batch Time: 0.13s\nFold 2, Epoch 3, Batch 860, Loss: 2.2058, LR: 0.001000, Batch Time: 0.11s\nFold 2, Epoch 3, Batch 870, Loss: 2.8498, LR: 0.001000, Batch Time: 0.11s\nFold 2, Epoch 3, Batch 880, Loss: 3.3918, LR: 0.001000, Batch Time: 0.11s\nFold 2, Epoch 3, Batch 890, Loss: 2.6546, LR: 0.001000, Batch Time: 0.11s\nFold 2, Epoch 3, Batch 900, Loss: 3.0363, LR: 0.001000, Batch Time: 0.11s\nFold 2, Epoch 3, Batch 910, Loss: 2.9415, LR: 0.001000, Batch Time: 0.11s\nFold 2, Epoch 3, Batch 920, Loss: 3.0082, LR: 0.001000, Batch Time: 0.12s\nFold 2, Epoch 3, Batch 930, Loss: 3.5602, LR: 0.001000, Batch Time: 0.13s\nFold 2, Epoch 3, Batch 940, Loss: 2.0728, LR: 0.001000, Batch Time: 0.12s\nFold 2, Epoch 3, Train Loss: 3.0989, Epoch 3 Time: 569.37s\nSkipped ID 39401: Image file /kaggle/input/fashion-product-images-dataset/fashion-dataset/images/39401.jpg not found\nSkipped ID 39425: Image file /kaggle/input/fashion-product-images-dataset/fashion-dataset/images/39425.jpg not found\nFold 2, Validation Loss: 21.6337\nFold 2, Validation F1-Scores (Macro) - Color: 0.0825, Type: 0.0257, Season: 0.6643, Gender: 0.7149, Avg F1: 0.3719\nFold 2, Validation Precision (Macro) - Color: 0.0844, Type: 0.0261, Season: 0.6360, Gender: 0.6622\nFold 2, Validation Recall (Macro) - Color: 0.1069, Type: 0.0384, Season: 0.7140, Gender: 0.8050\nFold 2, Validation Accuracy - Color: 0.2577, Type: 0.0174, Season: 0.6453, Gender: 0.8592\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"},{"name":"stdout","text":"Fold 2, Epoch 4, Batch 10, Loss: 1.8573, LR: 0.001000, Batch Time: 0.12s\nFold 2, Epoch 4, Batch 20, Loss: 2.7294, LR: 0.001000, Batch Time: 0.12s\nFold 2, Epoch 4, Batch 30, Loss: 3.2501, LR: 0.001000, Batch Time: 0.11s\nFold 2, Epoch 4, Batch 40, Loss: 2.5443, LR: 0.001000, Batch Time: 0.13s\nFold 2, Epoch 4, Batch 50, Loss: 2.2191, LR: 0.001000, Batch Time: 0.13s\nFold 2, Epoch 4, Batch 60, Loss: 2.5408, LR: 0.001000, Batch Time: 0.13s\nFold 2, Epoch 4, Batch 70, Loss: 2.6901, LR: 0.001000, Batch Time: 0.13s\nFold 2, Epoch 4, Batch 80, Loss: 3.0441, LR: 0.001000, Batch Time: 0.11s\nFold 2, Epoch 4, Batch 90, Loss: 2.6443, LR: 0.001000, Batch Time: 0.11s\nFold 2, Epoch 4, Batch 100, Loss: 2.9463, LR: 0.001000, Batch Time: 0.12s\nFold 2, Epoch 4, Batch 110, Loss: 2.7030, LR: 0.001000, Batch Time: 0.12s\nFold 2, Epoch 4, Batch 120, Loss: 2.3439, LR: 0.001000, Batch Time: 0.11s\nFold 2, Epoch 4, Batch 130, Loss: 2.4454, LR: 0.001000, Batch Time: 0.13s\nFold 2, Epoch 4, Batch 140, Loss: 3.7905, LR: 0.001000, Batch Time: 0.11s\nFold 2, Epoch 4, Batch 150, Loss: 3.0295, LR: 0.001000, Batch Time: 0.12s\nFold 2, Epoch 4, Batch 160, Loss: 2.7919, LR: 0.001000, Batch Time: 0.11s\nFold 2, Epoch 4, Batch 170, Loss: 2.4002, LR: 0.001000, Batch Time: 0.13s\nFold 2, Epoch 4, Batch 180, Loss: 3.1091, LR: 0.001000, Batch Time: 0.12s\nFold 2, Epoch 4, Batch 190, Loss: 3.5751, LR: 0.001000, Batch Time: 0.13s\nFold 2, Epoch 4, Batch 200, Loss: 3.0851, LR: 0.001000, Batch Time: 0.12s\nFold 2, Epoch 4, Batch 210, Loss: 4.4354, LR: 0.001000, Batch Time: 0.13s\nFold 2, Epoch 4, Batch 220, Loss: 2.4780, LR: 0.001000, Batch Time: 0.12s\nFold 2, Epoch 4, Batch 230, Loss: 1.9958, LR: 0.001000, Batch Time: 0.13s\nFold 2, Epoch 4, Batch 240, Loss: 2.5177, LR: 0.001000, Batch Time: 0.13s\nFold 2, Epoch 4, Batch 250, Loss: 2.6385, LR: 0.001000, Batch Time: 0.13s\nFold 2, Epoch 4, Batch 260, Loss: 2.7878, LR: 0.001000, Batch Time: 0.12s\nFold 2, Epoch 4, Batch 270, Loss: 2.2869, LR: 0.001000, Batch Time: 0.13s\nFold 2, Epoch 4, Batch 280, Loss: 2.8757, LR: 0.001000, Batch Time: 0.12s\nFold 2, Epoch 4, Batch 290, Loss: 2.0358, LR: 0.001000, Batch Time: 0.13s\nFold 2, Epoch 4, Batch 300, Loss: 3.0594, LR: 0.001000, Batch Time: 0.12s\nFold 2, Epoch 4, Batch 310, Loss: 2.4847, LR: 0.001000, Batch Time: 0.12s\nSkipped ID 12347: Image file /kaggle/input/fashion-product-images-dataset/fashion-dataset/images/12347.jpg not found\nFold 2, Epoch 4, Batch 320, Loss: 2.8103, LR: 0.001000, Batch Time: 0.13s\nFold 2, Epoch 4, Batch 330, Loss: 2.6498, LR: 0.001000, Batch Time: 0.12s\nFold 2, Epoch 4, Batch 340, Loss: 4.3020, LR: 0.001000, Batch Time: 0.13s\nFold 2, Epoch 4, Batch 350, Loss: 2.3539, LR: 0.001000, Batch Time: 0.13s\nFold 2, Epoch 4, Batch 360, Loss: 4.0394, LR: 0.001000, Batch Time: 0.13s\nFold 2, Epoch 4, Batch 370, Loss: 2.0478, LR: 0.001000, Batch Time: 0.12s\nFold 2, Epoch 4, Batch 380, Loss: 3.5415, LR: 0.001000, Batch Time: 0.13s\nFold 2, Epoch 4, Batch 390, Loss: 3.1547, LR: 0.001000, Batch Time: 0.13s\nFold 2, Epoch 4, Batch 400, Loss: 3.4265, LR: 0.001000, Batch Time: 0.12s\nFold 2, Epoch 4, Batch 410, Loss: 2.3991, LR: 0.001000, Batch Time: 0.12s\nFold 2, Epoch 4, Batch 420, Loss: 2.4029, LR: 0.001000, Batch Time: 0.12s\nFold 2, Epoch 4, Batch 430, Loss: 2.7582, LR: 0.001000, Batch Time: 0.13s\nFold 2, Epoch 4, Batch 440, Loss: 3.8851, LR: 0.001000, Batch Time: 0.12s\nFold 2, Epoch 4, Batch 450, Loss: 3.9444, LR: 0.001000, Batch Time: 0.13s\nFold 2, Epoch 4, Batch 460, Loss: 4.2482, LR: 0.001000, Batch Time: 0.12s\nFold 2, Epoch 4, Batch 470, Loss: 3.3164, LR: 0.001000, Batch Time: 0.13s\nFold 2, Epoch 4, Batch 480, Loss: 2.7203, LR: 0.001000, Batch Time: 0.12s\nFold 2, Epoch 4, Batch 490, Loss: 3.1792, LR: 0.001000, Batch Time: 0.13s\nFold 2, Epoch 4, Batch 500, Loss: 2.9729, LR: 0.001000, Batch Time: 0.12s\nFold 2, Epoch 4, Batch 510, Loss: 3.1669, LR: 0.001000, Batch Time: 0.11s\nFold 2, Epoch 4, Batch 520, Loss: 2.2862, LR: 0.001000, Batch Time: 0.11s\nFold 2, Epoch 4, Batch 530, Loss: 3.1422, LR: 0.001000, Batch Time: 0.12s\nFold 2, Epoch 4, Batch 540, Loss: 2.7672, LR: 0.001000, Batch Time: 0.11s\nFold 2, Epoch 4, Batch 550, Loss: 1.4495, LR: 0.001000, Batch Time: 0.12s\nFold 2, Epoch 4, Batch 560, Loss: 4.5559, LR: 0.001000, Batch Time: 0.11s\nFold 2, Epoch 4, Batch 570, Loss: 1.6796, LR: 0.001000, Batch Time: 0.12s\nFold 2, Epoch 4, Batch 580, Loss: 3.6761, LR: 0.001000, Batch Time: 0.11s\nFold 2, Epoch 4, Batch 590, Loss: 2.3993, LR: 0.001000, Batch Time: 0.12s\nFold 2, Epoch 4, Batch 600, Loss: 2.1043, LR: 0.001000, Batch Time: 0.11s\nFold 2, Epoch 4, Batch 610, Loss: 4.0805, LR: 0.001000, Batch Time: 0.12s\nFold 2, Epoch 4, Batch 620, Loss: 3.3063, LR: 0.001000, Batch Time: 0.13s\nFold 2, Epoch 4, Batch 630, Loss: 2.7449, LR: 0.001000, Batch Time: 0.12s\nFold 2, Epoch 4, Batch 640, Loss: 1.7777, LR: 0.001000, Batch Time: 0.13s\nFold 2, Epoch 4, Batch 650, Loss: 3.1288, LR: 0.001000, Batch Time: 0.12s\nFold 2, Epoch 4, Batch 660, Loss: 2.7723, LR: 0.001000, Batch Time: 0.12s\nFold 2, Epoch 4, Batch 670, Loss: 3.0781, LR: 0.001000, Batch Time: 0.12s\nSkipped ID 39403: Image file /kaggle/input/fashion-product-images-dataset/fashion-dataset/images/39403.jpg not found\nFold 2, Epoch 4, Batch 680, Loss: 2.3420, LR: 0.001000, Batch Time: 0.13s\nFold 2, Epoch 4, Batch 690, Loss: 2.1983, LR: 0.001000, Batch Time: 0.12s\nFold 2, Epoch 4, Batch 700, Loss: 2.4341, LR: 0.001000, Batch Time: 0.13s\nFold 2, Epoch 4, Batch 710, Loss: 2.7843, LR: 0.001000, Batch Time: 0.12s\nFold 2, Epoch 4, Batch 720, Loss: 2.1927, LR: 0.001000, Batch Time: 0.12s\nFold 2, Epoch 4, Batch 730, Loss: 3.0708, LR: 0.001000, Batch Time: 0.11s\nFold 2, Epoch 4, Batch 740, Loss: 2.4534, LR: 0.001000, Batch Time: 0.12s\nFold 2, Epoch 4, Batch 750, Loss: 2.0353, LR: 0.001000, Batch Time: 0.11s\nFold 2, Epoch 4, Batch 760, Loss: 2.3253, LR: 0.001000, Batch Time: 0.13s\nFold 2, Epoch 4, Batch 770, Loss: 3.5709, LR: 0.001000, Batch Time: 0.12s\nFold 2, Epoch 4, Batch 780, Loss: 2.6479, LR: 0.001000, Batch Time: 0.12s\nFold 2, Epoch 4, Batch 790, Loss: 3.9153, LR: 0.001000, Batch Time: 0.13s\nFold 2, Epoch 4, Batch 800, Loss: 2.8382, LR: 0.001000, Batch Time: 0.13s\nFold 2, Epoch 4, Batch 810, Loss: 2.6541, LR: 0.001000, Batch Time: 0.13s\nFold 2, Epoch 4, Batch 820, Loss: 3.0497, LR: 0.001000, Batch Time: 0.11s\nFold 2, Epoch 4, Batch 830, Loss: 3.0283, LR: 0.001000, Batch Time: 0.12s\nFold 2, Epoch 4, Batch 840, Loss: 3.1912, LR: 0.001000, Batch Time: 0.11s\nFold 2, Epoch 4, Batch 850, Loss: 3.4656, LR: 0.001000, Batch Time: 0.13s\nFold 2, Epoch 4, Batch 860, Loss: 3.4257, LR: 0.001000, Batch Time: 0.13s\nFold 2, Epoch 4, Batch 870, Loss: 2.3787, LR: 0.001000, Batch Time: 0.12s\nFold 2, Epoch 4, Batch 880, Loss: 2.1369, LR: 0.001000, Batch Time: 0.12s\nFold 2, Epoch 4, Batch 890, Loss: 5.1053, LR: 0.001000, Batch Time: 0.12s\nFold 2, Epoch 4, Batch 900, Loss: 3.5694, LR: 0.001000, Batch Time: 0.12s\nFold 2, Epoch 4, Batch 910, Loss: 1.9964, LR: 0.001000, Batch Time: 0.12s\nFold 2, Epoch 4, Batch 920, Loss: 3.0429, LR: 0.001000, Batch Time: 0.12s\nFold 2, Epoch 4, Batch 930, Loss: 2.4441, LR: 0.001000, Batch Time: 0.12s\nFold 2, Epoch 4, Batch 940, Loss: 3.5058, LR: 0.001000, Batch Time: 0.12s\nFold 2, Epoch 4, Train Loss: 2.8770, Epoch 4 Time: 564.37s\nSkipped ID 39401: Image file /kaggle/input/fashion-product-images-dataset/fashion-dataset/images/39401.jpg not found\nSkipped ID 39425: Image file /kaggle/input/fashion-product-images-dataset/fashion-dataset/images/39425.jpg not found\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"},{"name":"stdout","text":"Fold 2, Validation Loss: 24.0192\nFold 2, Validation F1-Scores (Macro) - Color: 0.0875, Type: 0.0280, Season: 0.6700, Gender: 0.7213, Avg F1: 0.3767\nFold 2, Validation Precision (Macro) - Color: 0.0896, Type: 0.0296, Season: 0.6400, Gender: 0.6658\nFold 2, Validation Recall (Macro) - Color: 0.1130, Type: 0.0331, Season: 0.7220, Gender: 0.8244\nFold 2, Validation Accuracy - Color: 0.2455, Type: 0.0198, Season: 0.6514, Gender: 0.8594\nEarly stopping triggered for Fold 2\nFold 3/5\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Fold 3, Epoch 1, Batch 10, Loss: 10.2857, LR: 0.001000, Batch Time: 0.13s\nFold 3, Epoch 1, Batch 20, Loss: 9.0265, LR: 0.001000, Batch Time: 0.12s\nFold 3, Epoch 1, Batch 30, Loss: 8.1291, LR: 0.001000, Batch Time: 0.13s\nSkipped ID 39425: Image file /kaggle/input/fashion-product-images-dataset/fashion-dataset/images/39425.jpg not found\nFold 3, Epoch 1, Batch 40, Loss: 7.3091, LR: 0.001000, Batch Time: 0.12s\nFold 3, Epoch 1, Batch 50, Loss: 6.1402, LR: 0.001000, Batch Time: 0.12s\nFold 3, Epoch 1, Batch 60, Loss: 6.3885, LR: 0.001000, Batch Time: 0.12s\nFold 3, Epoch 1, Batch 70, Loss: 6.7217, LR: 0.001000, Batch Time: 0.11s\nFold 3, Epoch 1, Batch 80, Loss: 8.7025, LR: 0.001000, Batch Time: 0.13s\nFold 3, Epoch 1, Batch 90, Loss: 11.3368, LR: 0.001000, Batch Time: 0.13s\nFold 3, Epoch 1, Batch 100, Loss: 5.5931, LR: 0.001000, Batch Time: 0.12s\nFold 3, Epoch 1, Batch 110, Loss: 5.7603, LR: 0.001000, Batch Time: 0.12s\nFold 3, Epoch 1, Batch 120, Loss: 5.2706, LR: 0.001000, Batch Time: 0.12s\nFold 3, Epoch 1, Batch 130, Loss: 6.5971, LR: 0.001000, Batch Time: 0.11s\nFold 3, Epoch 1, Batch 140, Loss: 8.1738, LR: 0.001000, Batch Time: 0.12s\nFold 3, Epoch 1, Batch 150, Loss: 5.3572, LR: 0.001000, Batch Time: 0.12s\nFold 3, Epoch 1, Batch 160, Loss: 7.6390, LR: 0.001000, Batch Time: 0.12s\nFold 3, Epoch 1, Batch 170, Loss: 5.2461, LR: 0.001000, Batch Time: 0.11s\nFold 3, Epoch 1, Batch 180, Loss: 5.0913, LR: 0.001000, Batch Time: 0.12s\nFold 3, Epoch 1, Batch 190, Loss: 4.9854, LR: 0.001000, Batch Time: 0.13s\nFold 3, Epoch 1, Batch 200, Loss: 4.8542, LR: 0.001000, Batch Time: 0.12s\nFold 3, Epoch 1, Batch 210, Loss: 5.1522, LR: 0.001000, Batch Time: 0.12s\nFold 3, Epoch 1, Batch 220, Loss: 5.7032, LR: 0.001000, Batch Time: 0.12s\nFold 3, Epoch 1, Batch 230, Loss: 5.3715, LR: 0.001000, Batch Time: 0.13s\nFold 3, Epoch 1, Batch 240, Loss: 5.6912, LR: 0.001000, Batch Time: 0.12s\nFold 3, Epoch 1, Batch 250, Loss: 4.4752, LR: 0.001000, Batch Time: 0.13s\nFold 3, Epoch 1, Batch 260, Loss: 4.9143, LR: 0.001000, Batch Time: 0.12s\nSkipped ID 12347: Image file /kaggle/input/fashion-product-images-dataset/fashion-dataset/images/12347.jpg not found\nFold 3, Epoch 1, Batch 270, Loss: 4.0153, LR: 0.001000, Batch Time: 0.12s\nFold 3, Epoch 1, Batch 280, Loss: 4.5757, LR: 0.001000, Batch Time: 0.12s\nFold 3, Epoch 1, Batch 290, Loss: 5.8648, LR: 0.001000, Batch Time: 0.12s\nFold 3, Epoch 1, Batch 300, Loss: 4.9500, LR: 0.001000, Batch Time: 0.12s\nFold 3, Epoch 1, Batch 310, Loss: 4.7802, LR: 0.001000, Batch Time: 0.13s\nFold 3, Epoch 1, Batch 320, Loss: 4.7290, LR: 0.001000, Batch Time: 0.12s\nFold 3, Epoch 1, Batch 330, Loss: 4.5309, LR: 0.001000, Batch Time: 0.13s\nFold 3, Epoch 1, Batch 340, Loss: 4.5865, LR: 0.001000, Batch Time: 0.12s\nFold 3, Epoch 1, Batch 350, Loss: 5.1665, LR: 0.001000, Batch Time: 0.11s\nFold 3, Epoch 1, Batch 360, Loss: 4.3798, LR: 0.001000, Batch Time: 0.12s\nFold 3, Epoch 1, Batch 370, Loss: 5.2817, LR: 0.001000, Batch Time: 0.11s\nFold 3, Epoch 1, Batch 380, Loss: 4.4006, LR: 0.001000, Batch Time: 0.13s\nFold 3, Epoch 1, Batch 390, Loss: 4.5273, LR: 0.001000, Batch Time: 0.12s\nFold 3, Epoch 1, Batch 400, Loss: 3.5564, LR: 0.001000, Batch Time: 0.12s\nFold 3, Epoch 1, Batch 410, Loss: 4.7466, LR: 0.001000, Batch Time: 0.13s\nFold 3, Epoch 1, Batch 420, Loss: 4.6203, LR: 0.001000, Batch Time: 0.12s\nFold 3, Epoch 1, Batch 430, Loss: 6.4071, LR: 0.001000, Batch Time: 0.13s\nFold 3, Epoch 1, Batch 440, Loss: 4.4271, LR: 0.001000, Batch Time: 0.12s\nFold 3, Epoch 1, Batch 450, Loss: 5.2189, LR: 0.001000, Batch Time: 0.13s\nFold 3, Epoch 1, Batch 460, Loss: 4.0328, LR: 0.001000, Batch Time: 0.12s\nFold 3, Epoch 1, Batch 470, Loss: 3.7416, LR: 0.001000, Batch Time: 0.12s\nSkipped ID 39401: Image file /kaggle/input/fashion-product-images-dataset/fashion-dataset/images/39401.jpg not found\nFold 3, Epoch 1, Batch 480, Loss: 4.0459, LR: 0.001000, Batch Time: 0.12s\nFold 3, Epoch 1, Batch 490, Loss: 4.0931, LR: 0.001000, Batch Time: 0.13s\nFold 3, Epoch 1, Batch 500, Loss: 4.4605, LR: 0.001000, Batch Time: 0.12s\nFold 3, Epoch 1, Batch 510, Loss: 3.9603, LR: 0.001000, Batch Time: 0.13s\nFold 3, Epoch 1, Batch 520, Loss: 4.2243, LR: 0.001000, Batch Time: 0.12s\nFold 3, Epoch 1, Batch 530, Loss: 4.7198, LR: 0.001000, Batch Time: 0.12s\nFold 3, Epoch 1, Batch 540, Loss: 4.3331, LR: 0.001000, Batch Time: 0.12s\nFold 3, Epoch 1, Batch 550, Loss: 4.7400, LR: 0.001000, Batch Time: 0.13s\nFold 3, Epoch 1, Batch 560, Loss: 4.8274, LR: 0.001000, Batch Time: 0.12s\nFold 3, Epoch 1, Batch 570, Loss: 5.2253, LR: 0.001000, Batch Time: 0.12s\nFold 3, Epoch 1, Batch 580, Loss: 3.6266, LR: 0.001000, Batch Time: 0.11s\nFold 3, Epoch 1, Batch 590, Loss: 4.4239, LR: 0.001000, Batch Time: 0.13s\nFold 3, Epoch 1, Batch 600, Loss: 4.6977, LR: 0.001000, Batch Time: 0.12s\nFold 3, Epoch 1, Batch 610, Loss: 3.4203, LR: 0.001000, Batch Time: 0.13s\nFold 3, Epoch 1, Batch 620, Loss: 4.2361, LR: 0.001000, Batch Time: 0.12s\nFold 3, Epoch 1, Batch 630, Loss: 4.1231, LR: 0.001000, Batch Time: 0.12s\nFold 3, Epoch 1, Batch 640, Loss: 3.7187, LR: 0.001000, Batch Time: 0.12s\nSkipped ID 39403: Image file /kaggle/input/fashion-product-images-dataset/fashion-dataset/images/39403.jpg not found\nFold 3, Epoch 1, Batch 650, Loss: 3.6245, LR: 0.001000, Batch Time: 0.13s\nFold 3, Epoch 1, Batch 660, Loss: 4.7105, LR: 0.001000, Batch Time: 0.13s\nFold 3, Epoch 1, Batch 670, Loss: 3.3750, LR: 0.001000, Batch Time: 0.13s\nFold 3, Epoch 1, Batch 680, Loss: 5.8040, LR: 0.001000, Batch Time: 0.12s\nFold 3, Epoch 1, Batch 690, Loss: 3.8560, LR: 0.001000, Batch Time: 0.13s\nFold 3, Epoch 1, Batch 700, Loss: 3.4475, LR: 0.001000, Batch Time: 0.12s\nFold 3, Epoch 1, Batch 710, Loss: 3.6617, LR: 0.001000, Batch Time: 0.12s\nFold 3, Epoch 1, Batch 720, Loss: 4.2694, LR: 0.001000, Batch Time: 0.13s\nFold 3, Epoch 1, Batch 730, Loss: 5.7337, LR: 0.001000, Batch Time: 0.13s\nFold 3, Epoch 1, Batch 740, Loss: 3.5106, LR: 0.001000, Batch Time: 0.13s\nFold 3, Epoch 1, Batch 750, Loss: 4.6631, LR: 0.001000, Batch Time: 0.12s\nFold 3, Epoch 1, Batch 760, Loss: 4.3250, LR: 0.001000, Batch Time: 0.12s\nFold 3, Epoch 1, Batch 770, Loss: 3.6075, LR: 0.001000, Batch Time: 0.12s\nFold 3, Epoch 1, Batch 780, Loss: 3.7010, LR: 0.001000, Batch Time: 0.12s\nFold 3, Epoch 1, Batch 790, Loss: 5.1580, LR: 0.001000, Batch Time: 0.13s\nFold 3, Epoch 1, Batch 800, Loss: 5.4922, LR: 0.001000, Batch Time: 0.12s\nFold 3, Epoch 1, Batch 810, Loss: 3.8341, LR: 0.001000, Batch Time: 0.12s\nFold 3, Epoch 1, Batch 820, Loss: 4.4791, LR: 0.001000, Batch Time: 0.11s\nFold 3, Epoch 1, Batch 830, Loss: 4.1968, LR: 0.001000, Batch Time: 0.13s\nFold 3, Epoch 1, Batch 840, Loss: 3.9326, LR: 0.001000, Batch Time: 0.11s\nFold 3, Epoch 1, Batch 850, Loss: 3.1305, LR: 0.001000, Batch Time: 0.12s\nFold 3, Epoch 1, Batch 860, Loss: 6.5396, LR: 0.001000, Batch Time: 0.11s\nFold 3, Epoch 1, Batch 870, Loss: 3.5500, LR: 0.001000, Batch Time: 0.13s\nFold 3, Epoch 1, Batch 880, Loss: 4.7749, LR: 0.001000, Batch Time: 0.13s\nFold 3, Epoch 1, Batch 890, Loss: 3.5679, LR: 0.001000, Batch Time: 0.11s\nFold 3, Epoch 1, Batch 900, Loss: 3.9578, LR: 0.001000, Batch Time: 0.12s\nFold 3, Epoch 1, Batch 910, Loss: 4.2855, LR: 0.001000, Batch Time: 0.12s\nFold 3, Epoch 1, Batch 920, Loss: 5.3797, LR: 0.001000, Batch Time: 0.13s\nFold 3, Epoch 1, Batch 930, Loss: 3.3995, LR: 0.001000, Batch Time: 0.13s\nFold 3, Epoch 1, Batch 940, Loss: 2.3559, LR: 0.001000, Batch Time: 0.13s\nFold 3, Epoch 1, Train Loss: 5.2998, Epoch 1 Time: 571.94s\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"},{"name":"stdout","text":"Fold 3, Validation Loss: 17.4834\nFold 3, Validation F1-Scores (Macro) - Color: 0.0704, Type: 0.0335, Season: 0.6479, Gender: 0.6884, Avg F1: 0.3601\nFold 3, Validation Precision (Macro) - Color: 0.0856, Type: 0.0447, Season: 0.6195, Gender: 0.6287\nFold 3, Validation Recall (Macro) - Color: 0.0899, Type: 0.0367, Season: 0.6999, Gender: 0.8025\nFold 3, Validation Accuracy - Color: 0.2200, Type: 0.0370, Season: 0.6327, Gender: 0.8398\nSaved best model from Fold 3 at /kaggle/working/best_model.pth (Avg F1: 0.3601)\nFold 3, Epoch 2, Batch 10, Loss: 3.4443, LR: 0.001000, Batch Time: 0.12s\nFold 3, Epoch 2, Batch 20, Loss: 7.4697, LR: 0.001000, Batch Time: 0.12s\nFold 3, Epoch 2, Batch 30, Loss: 3.8788, LR: 0.001000, Batch Time: 0.12s\nFold 3, Epoch 2, Batch 40, Loss: 4.2115, LR: 0.001000, Batch Time: 0.12s\nFold 3, Epoch 2, Batch 50, Loss: 3.1568, LR: 0.001000, Batch Time: 0.12s\nFold 3, Epoch 2, Batch 60, Loss: 3.7573, LR: 0.001000, Batch Time: 0.13s\nFold 3, Epoch 2, Batch 70, Loss: 3.5892, LR: 0.001000, Batch Time: 0.12s\nFold 3, Epoch 2, Batch 80, Loss: 3.9508, LR: 0.001000, Batch Time: 0.13s\nFold 3, Epoch 2, Batch 90, Loss: 4.8938, LR: 0.001000, Batch Time: 0.11s\nFold 3, Epoch 2, Batch 100, Loss: 4.0114, LR: 0.001000, Batch Time: 0.13s\nFold 3, Epoch 2, Batch 110, Loss: 5.2516, LR: 0.001000, Batch Time: 0.11s\nFold 3, Epoch 2, Batch 120, Loss: 5.2805, LR: 0.001000, Batch Time: 0.13s\nFold 3, Epoch 2, Batch 130, Loss: 4.0691, LR: 0.001000, Batch Time: 0.11s\nFold 3, Epoch 2, Batch 140, Loss: 3.9639, LR: 0.001000, Batch Time: 0.12s\nFold 3, Epoch 2, Batch 150, Loss: 3.2085, LR: 0.001000, Batch Time: 0.12s\nFold 3, Epoch 2, Batch 160, Loss: 2.8521, LR: 0.001000, Batch Time: 0.12s\nFold 3, Epoch 2, Batch 170, Loss: 3.9591, LR: 0.001000, Batch Time: 0.12s\nFold 3, Epoch 2, Batch 180, Loss: 4.2517, LR: 0.001000, Batch Time: 0.12s\nFold 3, Epoch 2, Batch 190, Loss: 3.2071, LR: 0.001000, Batch Time: 0.12s\nFold 3, Epoch 2, Batch 200, Loss: 3.2202, LR: 0.001000, Batch Time: 0.13s\nFold 3, Epoch 2, Batch 210, Loss: 2.3604, LR: 0.001000, Batch Time: 0.12s\nFold 3, Epoch 2, Batch 220, Loss: 3.3074, LR: 0.001000, Batch Time: 0.11s\nFold 3, Epoch 2, Batch 230, Loss: 4.5869, LR: 0.001000, Batch Time: 0.13s\nFold 3, Epoch 2, Batch 240, Loss: 6.1861, LR: 0.001000, Batch Time: 0.12s\nFold 3, Epoch 2, Batch 250, Loss: 5.1699, LR: 0.001000, Batch Time: 0.11s\nFold 3, Epoch 2, Batch 260, Loss: 3.8632, LR: 0.001000, Batch Time: 0.12s\nFold 3, Epoch 2, Batch 270, Loss: 3.7491, LR: 0.001000, Batch Time: 0.11s\nFold 3, Epoch 2, Batch 280, Loss: 3.9741, LR: 0.001000, Batch Time: 0.12s\nFold 3, Epoch 2, Batch 290, Loss: 4.5414, LR: 0.001000, Batch Time: 0.11s\nSkipped ID 12347: Image file /kaggle/input/fashion-product-images-dataset/fashion-dataset/images/12347.jpg not found\nFold 3, Epoch 2, Batch 300, Loss: 3.7567, LR: 0.001000, Batch Time: 0.12s\nFold 3, Epoch 2, Batch 310, Loss: 2.9680, LR: 0.001000, Batch Time: 0.11s\nFold 3, Epoch 2, Batch 320, Loss: 3.5279, LR: 0.001000, Batch Time: 0.12s\nFold 3, Epoch 2, Batch 330, Loss: 3.9029, LR: 0.001000, Batch Time: 0.12s\nFold 3, Epoch 2, Batch 340, Loss: 3.6699, LR: 0.001000, Batch Time: 0.12s\nFold 3, Epoch 2, Batch 350, Loss: 2.4677, LR: 0.001000, Batch Time: 0.11s\nFold 3, Epoch 2, Batch 360, Loss: 3.9314, LR: 0.001000, Batch Time: 0.12s\nFold 3, Epoch 2, Batch 370, Loss: 4.2468, LR: 0.001000, Batch Time: 0.11s\nFold 3, Epoch 2, Batch 380, Loss: 4.7082, LR: 0.001000, Batch Time: 0.12s\nFold 3, Epoch 2, Batch 390, Loss: 2.9480, LR: 0.001000, Batch Time: 0.13s\nFold 3, Epoch 2, Batch 400, Loss: 3.3635, LR: 0.001000, Batch Time: 0.13s\nFold 3, Epoch 2, Batch 410, Loss: 4.1460, LR: 0.001000, Batch Time: 0.11s\nFold 3, Epoch 2, Batch 420, Loss: 3.6409, LR: 0.001000, Batch Time: 0.12s\nFold 3, Epoch 2, Batch 430, Loss: 4.1042, LR: 0.001000, Batch Time: 0.13s\nFold 3, Epoch 2, Batch 440, Loss: 3.1785, LR: 0.001000, Batch Time: 0.13s\nSkipped ID 39425: Image file /kaggle/input/fashion-product-images-dataset/fashion-dataset/images/39425.jpg not found\nFold 3, Epoch 2, Batch 450, Loss: 3.5350, LR: 0.001000, Batch Time: 0.13s\nFold 3, Epoch 2, Batch 460, Loss: 3.5164, LR: 0.001000, Batch Time: 0.12s\nFold 3, Epoch 2, Batch 470, Loss: 5.5885, LR: 0.001000, Batch Time: 0.13s\nFold 3, Epoch 2, Batch 480, Loss: 3.1474, LR: 0.001000, Batch Time: 0.12s\nFold 3, Epoch 2, Batch 490, Loss: 3.7102, LR: 0.001000, Batch Time: 0.13s\nSkipped ID 39401: Image file /kaggle/input/fashion-product-images-dataset/fashion-dataset/images/39401.jpg not found\nFold 3, Epoch 2, Batch 500, Loss: 2.8289, LR: 0.001000, Batch Time: 0.12s\nFold 3, Epoch 2, Batch 510, Loss: 2.9078, LR: 0.001000, Batch Time: 0.13s\nFold 3, Epoch 2, Batch 520, Loss: 2.7787, LR: 0.001000, Batch Time: 0.12s\nFold 3, Epoch 2, Batch 530, Loss: 4.4401, LR: 0.001000, Batch Time: 0.13s\nFold 3, Epoch 2, Batch 540, Loss: 3.2107, LR: 0.001000, Batch Time: 0.12s\nFold 3, Epoch 2, Batch 550, Loss: 3.7833, LR: 0.001000, Batch Time: 0.13s\nFold 3, Epoch 2, Batch 560, Loss: 3.7431, LR: 0.001000, Batch Time: 0.13s\nFold 3, Epoch 2, Batch 570, Loss: 3.5641, LR: 0.001000, Batch Time: 0.11s\nFold 3, Epoch 2, Batch 580, Loss: 3.4711, LR: 0.001000, Batch Time: 0.13s\nFold 3, Epoch 2, Batch 590, Loss: 2.9346, LR: 0.001000, Batch Time: 0.13s\nFold 3, Epoch 2, Batch 600, Loss: 2.7118, LR: 0.001000, Batch Time: 0.12s\nSkipped ID 39403: Image file /kaggle/input/fashion-product-images-dataset/fashion-dataset/images/39403.jpg not found\nFold 3, Epoch 2, Batch 610, Loss: 2.6761, LR: 0.001000, Batch Time: 0.13s\nFold 3, Epoch 2, Batch 620, Loss: 3.6478, LR: 0.001000, Batch Time: 0.13s\nFold 3, Epoch 2, Batch 630, Loss: 3.5413, LR: 0.001000, Batch Time: 0.13s\nFold 3, Epoch 2, Batch 640, Loss: 4.4254, LR: 0.001000, Batch Time: 0.12s\nFold 3, Epoch 2, Batch 650, Loss: 3.4583, LR: 0.001000, Batch Time: 0.13s\nFold 3, Epoch 2, Batch 660, Loss: 4.6119, LR: 0.001000, Batch Time: 0.12s\nFold 3, Epoch 2, Batch 670, Loss: 3.8654, LR: 0.001000, Batch Time: 0.13s\nFold 3, Epoch 2, Batch 680, Loss: 3.2963, LR: 0.001000, Batch Time: 0.13s\nFold 3, Epoch 2, Batch 690, Loss: 3.4653, LR: 0.001000, Batch Time: 0.13s\nFold 3, Epoch 2, Batch 700, Loss: 3.3096, LR: 0.001000, Batch Time: 0.12s\nFold 3, Epoch 2, Batch 710, Loss: 2.8337, LR: 0.001000, Batch Time: 0.11s\nFold 3, Epoch 2, Batch 720, Loss: 3.7375, LR: 0.001000, Batch Time: 0.12s\nFold 3, Epoch 2, Batch 730, Loss: 4.4058, LR: 0.001000, Batch Time: 0.12s\nFold 3, Epoch 2, Batch 740, Loss: 3.4865, LR: 0.001000, Batch Time: 0.12s\nFold 3, Epoch 2, Batch 750, Loss: 3.9183, LR: 0.001000, Batch Time: 0.11s\nFold 3, Epoch 2, Batch 760, Loss: 2.7066, LR: 0.001000, Batch Time: 0.12s\nFold 3, Epoch 2, Batch 770, Loss: 4.8935, LR: 0.001000, Batch Time: 0.13s\nFold 3, Epoch 2, Batch 780, Loss: 3.2190, LR: 0.001000, Batch Time: 0.12s\nFold 3, Epoch 2, Batch 790, Loss: 3.5723, LR: 0.001000, Batch Time: 0.13s\nFold 3, Epoch 2, Batch 800, Loss: 3.0394, LR: 0.001000, Batch Time: 0.12s\nFold 3, Epoch 2, Batch 810, Loss: 4.7176, LR: 0.001000, Batch Time: 0.11s\nFold 3, Epoch 2, Batch 820, Loss: 2.5611, LR: 0.001000, Batch Time: 0.13s\nFold 3, Epoch 2, Batch 830, Loss: 3.0655, LR: 0.001000, Batch Time: 0.11s\nFold 3, Epoch 2, Batch 840, Loss: 3.2027, LR: 0.001000, Batch Time: 0.12s\nFold 3, Epoch 2, Batch 850, Loss: 3.6522, LR: 0.001000, Batch Time: 0.11s\nFold 3, Epoch 2, Batch 860, Loss: 5.1024, LR: 0.001000, Batch Time: 0.12s\nFold 3, Epoch 2, Batch 870, Loss: 2.7540, LR: 0.001000, Batch Time: 0.11s\nFold 3, Epoch 2, Batch 880, Loss: 3.7354, LR: 0.001000, Batch Time: 0.12s\nFold 3, Epoch 2, Batch 890, Loss: 2.5899, LR: 0.001000, Batch Time: 0.11s\nFold 3, Epoch 2, Batch 900, Loss: 3.3959, LR: 0.001000, Batch Time: 0.12s\nFold 3, Epoch 2, Batch 910, Loss: 3.1989, LR: 0.001000, Batch Time: 0.11s\nFold 3, Epoch 2, Batch 920, Loss: 2.9456, LR: 0.001000, Batch Time: 0.13s\nFold 3, Epoch 2, Batch 930, Loss: 2.7641, LR: 0.001000, Batch Time: 0.11s\nFold 3, Epoch 2, Batch 940, Loss: 4.0339, LR: 0.001000, Batch Time: 0.12s\nFold 3, Epoch 2, Train Loss: 3.6818, Epoch 2 Time: 568.77s\nFold 3, Validation Loss: 20.3194\nFold 3, Validation F1-Scores (Macro) - Color: 0.0763, Type: 0.0312, Season: 0.6599, Gender: 0.6932, Avg F1: 0.3652\nFold 3, Validation Precision (Macro) - Color: 0.0915, Type: 0.0364, Season: 0.6325, Gender: 0.6344\nFold 3, Validation Recall (Macro) - Color: 0.0934, Type: 0.0290, Season: 0.7114, Gender: 0.8135\nFold 3, Validation Accuracy - Color: 0.2422, Type: 0.0383, Season: 0.6386, Gender: 0.8510\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"},{"name":"stdout","text":"Fold 3, Epoch 3, Batch 10, Loss: 2.8282, LR: 0.001000, Batch Time: 0.11s\nFold 3, Epoch 3, Batch 20, Loss: 3.8507, LR: 0.001000, Batch Time: 0.13s\nFold 3, Epoch 3, Batch 30, Loss: 2.8722, LR: 0.001000, Batch Time: 0.11s\nFold 3, Epoch 3, Batch 40, Loss: 2.8287, LR: 0.001000, Batch Time: 0.12s\nFold 3, Epoch 3, Batch 50, Loss: 3.4391, LR: 0.001000, Batch Time: 0.11s\nFold 3, Epoch 3, Batch 60, Loss: 3.1066, LR: 0.001000, Batch Time: 0.12s\nFold 3, Epoch 3, Batch 70, Loss: 2.7286, LR: 0.001000, Batch Time: 0.11s\nFold 3, Epoch 3, Batch 80, Loss: 3.5345, LR: 0.001000, Batch Time: 0.13s\nFold 3, Epoch 3, Batch 90, Loss: 3.4188, LR: 0.001000, Batch Time: 0.11s\nFold 3, Epoch 3, Batch 100, Loss: 3.7362, LR: 0.001000, Batch Time: 0.12s\nFold 3, Epoch 3, Batch 110, Loss: 3.4286, LR: 0.001000, Batch Time: 0.11s\nFold 3, Epoch 3, Batch 120, Loss: 2.3021, LR: 0.001000, Batch Time: 0.11s\nFold 3, Epoch 3, Batch 130, Loss: 3.4234, LR: 0.001000, Batch Time: 0.12s\nFold 3, Epoch 3, Batch 140, Loss: 3.3597, LR: 0.001000, Batch Time: 0.12s\nFold 3, Epoch 3, Batch 150, Loss: 3.0063, LR: 0.001000, Batch Time: 0.11s\nFold 3, Epoch 3, Batch 160, Loss: 2.5664, LR: 0.001000, Batch Time: 0.13s\nFold 3, Epoch 3, Batch 170, Loss: 2.7285, LR: 0.001000, Batch Time: 0.13s\nFold 3, Epoch 3, Batch 180, Loss: 2.9991, LR: 0.001000, Batch Time: 0.12s\nFold 3, Epoch 3, Batch 190, Loss: 3.8753, LR: 0.001000, Batch Time: 0.13s\nFold 3, Epoch 3, Batch 200, Loss: 3.2768, LR: 0.001000, Batch Time: 0.13s\nFold 3, Epoch 3, Batch 210, Loss: 2.8649, LR: 0.001000, Batch Time: 0.13s\nFold 3, Epoch 3, Batch 220, Loss: 3.5290, LR: 0.001000, Batch Time: 0.12s\nFold 3, Epoch 3, Batch 230, Loss: 3.4914, LR: 0.001000, Batch Time: 0.13s\nFold 3, Epoch 3, Batch 240, Loss: 2.3952, LR: 0.001000, Batch Time: 0.12s\nFold 3, Epoch 3, Batch 250, Loss: 3.5120, LR: 0.001000, Batch Time: 0.11s\nFold 3, Epoch 3, Batch 260, Loss: 2.2971, LR: 0.001000, Batch Time: 0.13s\nFold 3, Epoch 3, Batch 270, Loss: 2.8163, LR: 0.001000, Batch Time: 0.13s\nFold 3, Epoch 3, Batch 280, Loss: 3.8199, LR: 0.001000, Batch Time: 0.12s\nFold 3, Epoch 3, Batch 290, Loss: 4.5267, LR: 0.001000, Batch Time: 0.11s\nFold 3, Epoch 3, Batch 300, Loss: 3.5838, LR: 0.001000, Batch Time: 0.12s\nFold 3, Epoch 3, Batch 310, Loss: 3.0445, LR: 0.001000, Batch Time: 0.11s\nFold 3, Epoch 3, Batch 320, Loss: 2.6184, LR: 0.001000, Batch Time: 0.12s\nFold 3, Epoch 3, Batch 330, Loss: 2.4850, LR: 0.001000, Batch Time: 0.13s\nFold 3, Epoch 3, Batch 340, Loss: 3.6833, LR: 0.001000, Batch Time: 0.12s\nFold 3, Epoch 3, Batch 350, Loss: 3.0139, LR: 0.001000, Batch Time: 0.13s\nFold 3, Epoch 3, Batch 360, Loss: 2.8786, LR: 0.001000, Batch Time: 0.13s\nFold 3, Epoch 3, Batch 370, Loss: 3.2031, LR: 0.001000, Batch Time: 0.13s\nFold 3, Epoch 3, Batch 380, Loss: 3.3969, LR: 0.001000, Batch Time: 0.12s\nFold 3, Epoch 3, Batch 390, Loss: 2.6768, LR: 0.001000, Batch Time: 0.13s\nFold 3, Epoch 3, Batch 400, Loss: 4.2939, LR: 0.001000, Batch Time: 0.12s\nFold 3, Epoch 3, Batch 410, Loss: 3.5393, LR: 0.001000, Batch Time: 0.12s\nFold 3, Epoch 3, Batch 420, Loss: 4.4876, LR: 0.001000, Batch Time: 0.12s\nFold 3, Epoch 3, Batch 430, Loss: 2.5093, LR: 0.001000, Batch Time: 0.13s\nFold 3, Epoch 3, Batch 440, Loss: 2.3924, LR: 0.001000, Batch Time: 0.12s\nFold 3, Epoch 3, Batch 450, Loss: 3.8061, LR: 0.001000, Batch Time: 0.13s\nFold 3, Epoch 3, Batch 460, Loss: 2.6688, LR: 0.001000, Batch Time: 0.13s\nFold 3, Epoch 3, Batch 470, Loss: 2.8778, LR: 0.001000, Batch Time: 0.11s\nFold 3, Epoch 3, Batch 480, Loss: 2.8199, LR: 0.001000, Batch Time: 0.12s\nFold 3, Epoch 3, Batch 490, Loss: 3.8841, LR: 0.001000, Batch Time: 0.11s\nFold 3, Epoch 3, Batch 500, Loss: 2.4645, LR: 0.001000, Batch Time: 0.12s\nFold 3, Epoch 3, Batch 510, Loss: 2.5829, LR: 0.001000, Batch Time: 0.13s\nFold 3, Epoch 3, Batch 520, Loss: 3.3139, LR: 0.001000, Batch Time: 0.12s\nFold 3, Epoch 3, Batch 530, Loss: 2.6695, LR: 0.001000, Batch Time: 0.13s\nFold 3, Epoch 3, Batch 540, Loss: 2.6808, LR: 0.001000, Batch Time: 0.12s\nFold 3, Epoch 3, Batch 550, Loss: 3.1764, LR: 0.001000, Batch Time: 0.13s\nFold 3, Epoch 3, Batch 560, Loss: 2.8598, LR: 0.001000, Batch Time: 0.12s\nFold 3, Epoch 3, Batch 570, Loss: 2.9275, LR: 0.001000, Batch Time: 0.13s\nFold 3, Epoch 3, Batch 580, Loss: 3.2382, LR: 0.001000, Batch Time: 0.12s\nFold 3, Epoch 3, Batch 590, Loss: 3.8757, LR: 0.001000, Batch Time: 0.13s\nFold 3, Epoch 3, Batch 600, Loss: 2.6869, LR: 0.001000, Batch Time: 0.13s\nFold 3, Epoch 3, Batch 610, Loss: 3.6523, LR: 0.001000, Batch Time: 0.13s\nFold 3, Epoch 3, Batch 620, Loss: 2.9800, LR: 0.001000, Batch Time: 0.12s\nFold 3, Epoch 3, Batch 630, Loss: 3.8494, LR: 0.001000, Batch Time: 0.11s\nSkipped ID 39403: Image file /kaggle/input/fashion-product-images-dataset/fashion-dataset/images/39403.jpg not found\nFold 3, Epoch 3, Batch 640, Loss: 3.9558, LR: 0.001000, Batch Time: 0.13s\nFold 3, Epoch 3, Batch 650, Loss: 2.6140, LR: 0.001000, Batch Time: 0.11s\nFold 3, Epoch 3, Batch 660, Loss: 2.8365, LR: 0.001000, Batch Time: 0.12s\nFold 3, Epoch 3, Batch 670, Loss: 2.2777, LR: 0.001000, Batch Time: 0.11s\nFold 3, Epoch 3, Batch 680, Loss: 3.2091, LR: 0.001000, Batch Time: 0.13s\nFold 3, Epoch 3, Batch 690, Loss: 3.0810, LR: 0.001000, Batch Time: 0.11s\nFold 3, Epoch 3, Batch 700, Loss: 3.4196, LR: 0.001000, Batch Time: 0.12s\nFold 3, Epoch 3, Batch 710, Loss: 3.5035, LR: 0.001000, Batch Time: 0.11s\nFold 3, Epoch 3, Batch 720, Loss: 3.4111, LR: 0.001000, Batch Time: 0.13s\nSkipped ID 39401: Image file /kaggle/input/fashion-product-images-dataset/fashion-dataset/images/39401.jpg not found\nFold 3, Epoch 3, Batch 730, Loss: 2.5776, LR: 0.001000, Batch Time: 0.12s\nFold 3, Epoch 3, Batch 740, Loss: 2.9283, LR: 0.001000, Batch Time: 0.13s\nFold 3, Epoch 3, Batch 750, Loss: 2.6312, LR: 0.001000, Batch Time: 0.12s\nFold 3, Epoch 3, Batch 760, Loss: 2.5319, LR: 0.001000, Batch Time: 0.12s\nFold 3, Epoch 3, Batch 770, Loss: 2.9642, LR: 0.001000, Batch Time: 0.12s\nFold 3, Epoch 3, Batch 780, Loss: 2.8532, LR: 0.001000, Batch Time: 0.13s\nFold 3, Epoch 3, Batch 790, Loss: 2.1254, LR: 0.001000, Batch Time: 0.13s\nFold 3, Epoch 3, Batch 800, Loss: 3.4979, LR: 0.001000, Batch Time: 0.13s\nSkipped ID 39425: Image file /kaggle/input/fashion-product-images-dataset/fashion-dataset/images/39425.jpg not found\nFold 3, Epoch 3, Batch 810, Loss: 3.5149, LR: 0.001000, Batch Time: 0.13s\nFold 3, Epoch 3, Batch 820, Loss: 2.7901, LR: 0.001000, Batch Time: 0.12s\nFold 3, Epoch 3, Batch 830, Loss: 1.6859, LR: 0.001000, Batch Time: 0.13s\nFold 3, Epoch 3, Batch 840, Loss: 3.2779, LR: 0.001000, Batch Time: 0.12s\nSkipped ID 12347: Image file /kaggle/input/fashion-product-images-dataset/fashion-dataset/images/12347.jpg not found\nFold 3, Epoch 3, Batch 850, Loss: 3.2745, LR: 0.001000, Batch Time: 0.12s\nFold 3, Epoch 3, Batch 860, Loss: 2.2184, LR: 0.001000, Batch Time: 0.13s\nFold 3, Epoch 3, Batch 870, Loss: 3.2978, LR: 0.001000, Batch Time: 0.12s\nFold 3, Epoch 3, Batch 880, Loss: 2.6038, LR: 0.001000, Batch Time: 0.13s\nFold 3, Epoch 3, Batch 890, Loss: 2.9507, LR: 0.001000, Batch Time: 0.12s\nFold 3, Epoch 3, Batch 900, Loss: 2.7808, LR: 0.001000, Batch Time: 0.12s\nFold 3, Epoch 3, Batch 910, Loss: 2.6415, LR: 0.001000, Batch Time: 0.12s\nFold 3, Epoch 3, Batch 920, Loss: 3.2630, LR: 0.001000, Batch Time: 0.12s\nFold 3, Epoch 3, Batch 930, Loss: 2.5512, LR: 0.001000, Batch Time: 0.12s\nFold 3, Epoch 3, Batch 940, Loss: 6.2738, LR: 0.001000, Batch Time: 0.13s\nFold 3, Epoch 3, Train Loss: 3.2127, Epoch 3 Time: 573.40s\nFold 3, Validation Loss: 21.8908\nFold 3, Validation F1-Scores (Macro) - Color: 0.0862, Type: 0.0408, Season: 0.6521, Gender: 0.7409, Avg F1: 0.3800\nFold 3, Validation Precision (Macro) - Color: 0.0962, Type: 0.0473, Season: 0.6295, Gender: 0.6844\nFold 3, Validation Recall (Macro) - Color: 0.1097, Type: 0.0403, Season: 0.7124, Gender: 0.8412\nFold 3, Validation Accuracy - Color: 0.2489, Type: 0.0436, Season: 0.6232, Gender: 0.8591\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"},{"name":"stdout","text":"Fold 3, Epoch 4, Batch 10, Loss: 2.8885, LR: 0.001000, Batch Time: 0.11s\nFold 3, Epoch 4, Batch 20, Loss: 2.4011, LR: 0.001000, Batch Time: 0.12s\nFold 3, Epoch 4, Batch 30, Loss: 2.6797, LR: 0.001000, Batch Time: 0.13s\nFold 3, Epoch 4, Batch 40, Loss: 2.5674, LR: 0.001000, Batch Time: 0.13s\nFold 3, Epoch 4, Batch 50, Loss: 3.3029, LR: 0.001000, Batch Time: 0.11s\nFold 3, Epoch 4, Batch 60, Loss: 2.5515, LR: 0.001000, Batch Time: 0.12s\nFold 3, Epoch 4, Batch 70, Loss: 4.3022, LR: 0.001000, Batch Time: 0.11s\nFold 3, Epoch 4, Batch 80, Loss: 3.8097, LR: 0.001000, Batch Time: 0.13s\nFold 3, Epoch 4, Batch 90, Loss: 2.4905, LR: 0.001000, Batch Time: 0.13s\nFold 3, Epoch 4, Batch 100, Loss: 2.3630, LR: 0.001000, Batch Time: 0.12s\nFold 3, Epoch 4, Batch 110, Loss: 2.9113, LR: 0.001000, Batch Time: 0.11s\nFold 3, Epoch 4, Batch 120, Loss: 2.7122, LR: 0.001000, Batch Time: 0.12s\nFold 3, Epoch 4, Batch 130, Loss: 2.8492, LR: 0.001000, Batch Time: 0.11s\nFold 3, Epoch 4, Batch 140, Loss: 3.4946, LR: 0.001000, Batch Time: 0.11s\nFold 3, Epoch 4, Batch 150, Loss: 3.7833, LR: 0.001000, Batch Time: 0.12s\nFold 3, Epoch 4, Batch 160, Loss: 3.0250, LR: 0.001000, Batch Time: 0.12s\nFold 3, Epoch 4, Batch 170, Loss: 2.6857, LR: 0.001000, Batch Time: 0.11s\nFold 3, Epoch 4, Batch 180, Loss: 3.3490, LR: 0.001000, Batch Time: 0.12s\nFold 3, Epoch 4, Batch 190, Loss: 2.9650, LR: 0.001000, Batch Time: 0.13s\nFold 3, Epoch 4, Batch 200, Loss: 3.5489, LR: 0.001000, Batch Time: 0.12s\nFold 3, Epoch 4, Batch 210, Loss: 2.9559, LR: 0.001000, Batch Time: 0.13s\nFold 3, Epoch 4, Batch 220, Loss: 2.0601, LR: 0.001000, Batch Time: 0.12s\nSkipped ID 12347: Image file /kaggle/input/fashion-product-images-dataset/fashion-dataset/images/12347.jpg not found\nFold 3, Epoch 4, Batch 230, Loss: 2.9356, LR: 0.001000, Batch Time: 0.11s\nFold 3, Epoch 4, Batch 240, Loss: 2.3420, LR: 0.001000, Batch Time: 0.12s\nFold 3, Epoch 4, Batch 250, Loss: 2.9907, LR: 0.001000, Batch Time: 0.11s\nFold 3, Epoch 4, Batch 260, Loss: 2.8704, LR: 0.001000, Batch Time: 0.12s\nFold 3, Epoch 4, Batch 270, Loss: 2.7703, LR: 0.001000, Batch Time: 0.13s\nFold 3, Epoch 4, Batch 280, Loss: 2.3115, LR: 0.001000, Batch Time: 0.12s\nFold 3, Epoch 4, Batch 290, Loss: 3.7535, LR: 0.001000, Batch Time: 0.13s\nFold 3, Epoch 4, Batch 300, Loss: 3.7184, LR: 0.001000, Batch Time: 0.12s\nFold 3, Epoch 4, Batch 310, Loss: 4.1016, LR: 0.001000, Batch Time: 0.13s\nFold 3, Epoch 4, Batch 320, Loss: 2.5679, LR: 0.001000, Batch Time: 0.12s\nFold 3, Epoch 4, Batch 330, Loss: 2.9570, LR: 0.001000, Batch Time: 0.13s\nFold 3, Epoch 4, Batch 340, Loss: 2.6722, LR: 0.001000, Batch Time: 0.13s\nSkipped ID 39401: Image file /kaggle/input/fashion-product-images-dataset/fashion-dataset/images/39401.jpg not found\nFold 3, Epoch 4, Batch 350, Loss: 4.0770, LR: 0.001000, Batch Time: 0.13s\nFold 3, Epoch 4, Batch 360, Loss: 3.3281, LR: 0.001000, Batch Time: 0.12s\nFold 3, Epoch 4, Batch 370, Loss: 1.9615, LR: 0.001000, Batch Time: 0.13s\nFold 3, Epoch 4, Batch 380, Loss: 3.0562, LR: 0.001000, Batch Time: 0.12s\nFold 3, Epoch 4, Batch 390, Loss: 4.1349, LR: 0.001000, Batch Time: 0.11s\nFold 3, Epoch 4, Batch 400, Loss: 3.4950, LR: 0.001000, Batch Time: 0.12s\nFold 3, Epoch 4, Batch 410, Loss: 2.6689, LR: 0.001000, Batch Time: 0.13s\nFold 3, Epoch 4, Batch 420, Loss: 3.3206, LR: 0.001000, Batch Time: 0.12s\nFold 3, Epoch 4, Batch 430, Loss: 2.8811, LR: 0.001000, Batch Time: 0.11s\nFold 3, Epoch 4, Batch 440, Loss: 3.1346, LR: 0.001000, Batch Time: 0.12s\nFold 3, Epoch 4, Batch 450, Loss: 2.3111, LR: 0.001000, Batch Time: 0.12s\nFold 3, Epoch 4, Batch 460, Loss: 2.9769, LR: 0.001000, Batch Time: 0.12s\nFold 3, Epoch 4, Batch 470, Loss: 2.3526, LR: 0.001000, Batch Time: 0.11s\nFold 3, Epoch 4, Batch 480, Loss: 2.2158, LR: 0.001000, Batch Time: 0.11s\nFold 3, Epoch 4, Batch 490, Loss: 3.2593, LR: 0.001000, Batch Time: 0.11s\nFold 3, Epoch 4, Batch 500, Loss: 2.5289, LR: 0.001000, Batch Time: 0.11s\nFold 3, Epoch 4, Batch 510, Loss: 3.6801, LR: 0.001000, Batch Time: 0.13s\nFold 3, Epoch 4, Batch 520, Loss: 2.5765, LR: 0.001000, Batch Time: 0.11s\nFold 3, Epoch 4, Batch 530, Loss: 2.9523, LR: 0.001000, Batch Time: 0.11s\nFold 3, Epoch 4, Batch 540, Loss: 4.2394, LR: 0.001000, Batch Time: 0.11s\nFold 3, Epoch 4, Batch 550, Loss: 2.8580, LR: 0.001000, Batch Time: 0.11s\nFold 3, Epoch 4, Batch 560, Loss: 2.7589, LR: 0.001000, Batch Time: 0.11s\nFold 3, Epoch 4, Batch 570, Loss: 2.5840, LR: 0.001000, Batch Time: 0.11s\nFold 3, Epoch 4, Batch 580, Loss: 2.2357, LR: 0.001000, Batch Time: 0.11s\nFold 3, Epoch 4, Batch 590, Loss: 3.7530, LR: 0.001000, Batch Time: 0.11s\nFold 3, Epoch 4, Batch 600, Loss: 2.8454, LR: 0.001000, Batch Time: 0.12s\nFold 3, Epoch 4, Batch 610, Loss: 3.6847, LR: 0.001000, Batch Time: 0.11s\nFold 3, Epoch 4, Batch 620, Loss: 2.7831, LR: 0.001000, Batch Time: 0.12s\nFold 3, Epoch 4, Batch 630, Loss: 2.6611, LR: 0.001000, Batch Time: 0.11s\nFold 3, Epoch 4, Batch 640, Loss: 1.8171, LR: 0.001000, Batch Time: 0.12s\nFold 3, Epoch 4, Batch 650, Loss: 4.0328, LR: 0.001000, Batch Time: 0.12s\nFold 3, Epoch 4, Batch 660, Loss: 2.7526, LR: 0.001000, Batch Time: 0.12s\nSkipped ID 39425: Image file /kaggle/input/fashion-product-images-dataset/fashion-dataset/images/39425.jpg not found\nFold 3, Epoch 4, Batch 670, Loss: 3.3272, LR: 0.001000, Batch Time: 0.11s\nFold 3, Epoch 4, Batch 680, Loss: 2.7878, LR: 0.001000, Batch Time: 0.13s\nFold 3, Epoch 4, Batch 690, Loss: 4.4782, LR: 0.001000, Batch Time: 0.13s\nFold 3, Epoch 4, Batch 700, Loss: 2.5704, LR: 0.001000, Batch Time: 0.12s\nFold 3, Epoch 4, Batch 710, Loss: 3.5100, LR: 0.001000, Batch Time: 0.11s\nFold 3, Epoch 4, Batch 720, Loss: 3.5898, LR: 0.001000, Batch Time: 0.13s\nFold 3, Epoch 4, Batch 730, Loss: 2.8967, LR: 0.001000, Batch Time: 0.11s\nFold 3, Epoch 4, Batch 740, Loss: 2.1824, LR: 0.001000, Batch Time: 0.12s\nFold 3, Epoch 4, Batch 750, Loss: 1.9899, LR: 0.001000, Batch Time: 0.11s\nFold 3, Epoch 4, Batch 760, Loss: 2.8884, LR: 0.001000, Batch Time: 0.13s\nFold 3, Epoch 4, Batch 770, Loss: 2.1529, LR: 0.001000, Batch Time: 0.11s\nFold 3, Epoch 4, Batch 780, Loss: 2.6299, LR: 0.001000, Batch Time: 0.12s\nFold 3, Epoch 4, Batch 790, Loss: 2.7816, LR: 0.001000, Batch Time: 0.11s\nFold 3, Epoch 4, Batch 800, Loss: 3.4684, LR: 0.001000, Batch Time: 0.11s\nFold 3, Epoch 4, Batch 810, Loss: 2.9045, LR: 0.001000, Batch Time: 0.13s\nFold 3, Epoch 4, Batch 820, Loss: 4.0511, LR: 0.001000, Batch Time: 0.12s\nFold 3, Epoch 4, Batch 830, Loss: 3.0019, LR: 0.001000, Batch Time: 0.11s\nFold 3, Epoch 4, Batch 840, Loss: 2.8958, LR: 0.001000, Batch Time: 0.12s\nFold 3, Epoch 4, Batch 850, Loss: 2.5407, LR: 0.001000, Batch Time: 0.12s\nFold 3, Epoch 4, Batch 860, Loss: 3.1150, LR: 0.001000, Batch Time: 0.12s\nFold 3, Epoch 4, Batch 870, Loss: 2.8366, LR: 0.001000, Batch Time: 0.12s\nSkipped ID 39403: Image file /kaggle/input/fashion-product-images-dataset/fashion-dataset/images/39403.jpg not found\nFold 3, Epoch 4, Batch 880, Loss: 2.8045, LR: 0.001000, Batch Time: 0.12s\nFold 3, Epoch 4, Batch 890, Loss: 3.0209, LR: 0.001000, Batch Time: 0.11s\nFold 3, Epoch 4, Batch 900, Loss: 4.6997, LR: 0.001000, Batch Time: 0.13s\nFold 3, Epoch 4, Batch 910, Loss: 2.3456, LR: 0.001000, Batch Time: 0.11s\nFold 3, Epoch 4, Batch 920, Loss: 2.7666, LR: 0.001000, Batch Time: 0.11s\nFold 3, Epoch 4, Batch 930, Loss: 2.8978, LR: 0.001000, Batch Time: 0.11s\nFold 3, Epoch 4, Batch 940, Loss: 3.7952, LR: 0.001000, Batch Time: 0.12s\nFold 3, Epoch 4, Train Loss: 2.9289, Epoch 4 Time: 566.51s\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"},{"name":"stdout","text":"Fold 3, Validation Loss: 23.1391\nFold 3, Validation F1-Scores (Macro) - Color: 0.0828, Type: 0.0404, Season: 0.6605, Gender: 0.7202, Avg F1: 0.3760\nFold 3, Validation Precision (Macro) - Color: 0.0958, Type: 0.0496, Season: 0.6314, Gender: 0.6597\nFold 3, Validation Recall (Macro) - Color: 0.0983, Type: 0.0384, Season: 0.7196, Gender: 0.8277\nFold 3, Validation Accuracy - Color: 0.2538, Type: 0.0355, Season: 0.6390, Gender: 0.8589\nEarly stopping triggered for Fold 3\nFold 4/5\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Fold 4, Epoch 1, Batch 10, Loss: 10.0544, LR: 0.001000, Batch Time: 0.13s\nFold 4, Epoch 1, Batch 20, Loss: 9.5584, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 1, Batch 30, Loss: 8.9005, LR: 0.001000, Batch Time: 0.13s\nFold 4, Epoch 1, Batch 40, Loss: 7.6096, LR: 0.001000, Batch Time: 0.11s\nFold 4, Epoch 1, Batch 50, Loss: 7.3650, LR: 0.001000, Batch Time: 0.13s\nFold 4, Epoch 1, Batch 60, Loss: 7.5503, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 1, Batch 70, Loss: 7.1494, LR: 0.001000, Batch Time: 0.13s\nFold 4, Epoch 1, Batch 80, Loss: 6.8752, LR: 0.001000, Batch Time: 0.11s\nFold 4, Epoch 1, Batch 90, Loss: 5.2513, LR: 0.001000, Batch Time: 0.13s\nFold 4, Epoch 1, Batch 100, Loss: 6.7270, LR: 0.001000, Batch Time: 0.11s\nFold 4, Epoch 1, Batch 110, Loss: 6.6401, LR: 0.001000, Batch Time: 0.13s\nFold 4, Epoch 1, Batch 120, Loss: 6.5523, LR: 0.001000, Batch Time: 0.11s\nFold 4, Epoch 1, Batch 130, Loss: 6.9701, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 1, Batch 140, Loss: 5.4575, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 1, Batch 150, Loss: 6.3310, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 1, Batch 160, Loss: 8.1587, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 1, Batch 170, Loss: 9.2023, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 1, Batch 180, Loss: 5.1160, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 1, Batch 190, Loss: 5.9045, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 1, Batch 200, Loss: 4.7304, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 1, Batch 210, Loss: 6.4553, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 1, Batch 220, Loss: 4.9839, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 1, Batch 230, Loss: 3.7733, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 1, Batch 240, Loss: 5.3717, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 1, Batch 250, Loss: 5.0678, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 1, Batch 260, Loss: 6.4850, LR: 0.001000, Batch Time: 0.11s\nFold 4, Epoch 1, Batch 270, Loss: 4.3222, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 1, Batch 280, Loss: 4.7595, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 1, Batch 290, Loss: 5.5177, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 1, Batch 300, Loss: 4.6432, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 1, Batch 310, Loss: 5.0125, LR: 0.001000, Batch Time: 0.11s\nFold 4, Epoch 1, Batch 320, Loss: 5.7564, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 1, Batch 330, Loss: 6.1149, LR: 0.001000, Batch Time: 0.13s\nFold 4, Epoch 1, Batch 340, Loss: 4.5076, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 1, Batch 350, Loss: 5.0591, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 1, Batch 360, Loss: 4.5788, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 1, Batch 370, Loss: 4.8081, LR: 0.001000, Batch Time: 0.11s\nFold 4, Epoch 1, Batch 380, Loss: 3.9821, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 1, Batch 390, Loss: 5.9763, LR: 0.001000, Batch Time: 0.11s\nFold 4, Epoch 1, Batch 400, Loss: 4.5985, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 1, Batch 410, Loss: 5.0409, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 1, Batch 420, Loss: 5.7891, LR: 0.001000, Batch Time: 0.13s\nFold 4, Epoch 1, Batch 430, Loss: 5.1070, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 1, Batch 440, Loss: 3.8922, LR: 0.001000, Batch Time: 0.11s\nFold 4, Epoch 1, Batch 450, Loss: 3.9050, LR: 0.001000, Batch Time: 0.11s\nFold 4, Epoch 1, Batch 460, Loss: 4.4532, LR: 0.001000, Batch Time: 0.11s\nFold 4, Epoch 1, Batch 470, Loss: 4.4157, LR: 0.001000, Batch Time: 0.11s\nFold 4, Epoch 1, Batch 480, Loss: 8.6348, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 1, Batch 490, Loss: 5.0479, LR: 0.001000, Batch Time: 0.11s\nFold 4, Epoch 1, Batch 500, Loss: 4.3013, LR: 0.001000, Batch Time: 0.11s\nFold 4, Epoch 1, Batch 510, Loss: 4.1402, LR: 0.001000, Batch Time: 0.11s\nFold 4, Epoch 1, Batch 520, Loss: 3.7580, LR: 0.001000, Batch Time: 0.11s\nFold 4, Epoch 1, Batch 530, Loss: 4.3917, LR: 0.001000, Batch Time: 0.11s\nFold 4, Epoch 1, Batch 540, Loss: 8.8635, LR: 0.001000, Batch Time: 0.11s\nFold 4, Epoch 1, Batch 550, Loss: 3.7887, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 1, Batch 560, Loss: 4.8106, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 1, Batch 570, Loss: 3.6136, LR: 0.001000, Batch Time: 0.13s\nFold 4, Epoch 1, Batch 580, Loss: 4.2527, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 1, Batch 590, Loss: 4.4244, LR: 0.001000, Batch Time: 0.11s\nFold 4, Epoch 1, Batch 600, Loss: 4.4557, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 1, Batch 610, Loss: 3.6698, LR: 0.001000, Batch Time: 0.11s\nFold 4, Epoch 1, Batch 620, Loss: 4.6788, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 1, Batch 630, Loss: 4.7506, LR: 0.001000, Batch Time: 0.11s\nFold 4, Epoch 1, Batch 640, Loss: 3.8359, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 1, Batch 650, Loss: 4.4371, LR: 0.001000, Batch Time: 0.11s\nFold 4, Epoch 1, Batch 660, Loss: 4.6827, LR: 0.001000, Batch Time: 0.13s\nFold 4, Epoch 1, Batch 670, Loss: 4.4087, LR: 0.001000, Batch Time: 0.11s\nFold 4, Epoch 1, Batch 680, Loss: 4.2097, LR: 0.001000, Batch Time: 0.12s\nSkipped ID 39401: Image file /kaggle/input/fashion-product-images-dataset/fashion-dataset/images/39401.jpg not found\nFold 4, Epoch 1, Batch 690, Loss: 3.1482, LR: 0.001000, Batch Time: 0.11s\nFold 4, Epoch 1, Batch 700, Loss: 6.0817, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 1, Batch 710, Loss: 4.7379, LR: 0.001000, Batch Time: 0.11s\nFold 4, Epoch 1, Batch 720, Loss: 4.5449, LR: 0.001000, Batch Time: 0.13s\nFold 4, Epoch 1, Batch 730, Loss: 6.8319, LR: 0.001000, Batch Time: 0.11s\nSkipped ID 39425: Image file /kaggle/input/fashion-product-images-dataset/fashion-dataset/images/39425.jpg not found\nFold 4, Epoch 1, Batch 740, Loss: 3.0293, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 1, Batch 750, Loss: 4.6440, LR: 0.001000, Batch Time: 0.11s\nFold 4, Epoch 1, Batch 760, Loss: 3.2160, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 1, Batch 770, Loss: 7.3081, LR: 0.001000, Batch Time: 0.11s\nFold 4, Epoch 1, Batch 780, Loss: 4.1750, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 1, Batch 790, Loss: 4.6812, LR: 0.001000, Batch Time: 0.11s\nFold 4, Epoch 1, Batch 800, Loss: 4.3439, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 1, Batch 810, Loss: 3.4160, LR: 0.001000, Batch Time: 0.11s\nFold 4, Epoch 1, Batch 820, Loss: 4.4111, LR: 0.001000, Batch Time: 0.13s\nFold 4, Epoch 1, Batch 830, Loss: 4.1038, LR: 0.001000, Batch Time: 0.11s\nFold 4, Epoch 1, Batch 840, Loss: 4.5671, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 1, Batch 850, Loss: 3.3626, LR: 0.001000, Batch Time: 0.11s\nFold 4, Epoch 1, Batch 860, Loss: 3.1475, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 1, Batch 870, Loss: 3.9339, LR: 0.001000, Batch Time: 0.11s\nFold 4, Epoch 1, Batch 880, Loss: 4.3133, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 1, Batch 890, Loss: 3.2096, LR: 0.001000, Batch Time: 0.11s\nFold 4, Epoch 1, Batch 900, Loss: 3.8990, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 1, Batch 910, Loss: 3.6695, LR: 0.001000, Batch Time: 0.11s\nFold 4, Epoch 1, Batch 920, Loss: 4.2868, LR: 0.001000, Batch Time: 0.13s\nFold 4, Epoch 1, Batch 930, Loss: 4.4559, LR: 0.001000, Batch Time: 0.11s\nFold 4, Epoch 1, Batch 940, Loss: 3.7639, LR: 0.001000, Batch Time: 0.13s\nFold 4, Epoch 1, Train Loss: 5.0949, Epoch 1 Time: 448.39s\nSkipped ID 12347: Image file /kaggle/input/fashion-product-images-dataset/fashion-dataset/images/12347.jpg not found\nSkipped ID 39403: Image file /kaggle/input/fashion-product-images-dataset/fashion-dataset/images/39403.jpg not found\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"},{"name":"stdout","text":"Fold 4, Validation Loss: 14.2334\nFold 4, Validation F1-Scores (Macro) - Color: 0.2423, Type: 0.0317, Season: 0.6194, Gender: 0.6785, Avg F1: 0.3930\nFold 4, Validation Precision (Macro) - Color: 0.2491, Type: 0.0409, Season: 0.5913, Gender: 0.6222\nFold 4, Validation Recall (Macro) - Color: 0.3235, Type: 0.0359, Season: 0.6890, Gender: 0.7972\nFold 4, Validation Accuracy - Color: 0.3985, Type: 0.0274, Season: 0.6102, Gender: 0.8347\nSaved best model from Fold 4 at /kaggle/working/best_model.pth (Avg F1: 0.3930)\nFold 4, Epoch 2, Batch 10, Loss: 3.1843, LR: 0.001000, Batch Time: 0.11s\nSkipped ID 39401: Image file /kaggle/input/fashion-product-images-dataset/fashion-dataset/images/39401.jpg not found\nFold 4, Epoch 2, Batch 20, Loss: 4.8901, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 2, Batch 30, Loss: 3.2312, LR: 0.001000, Batch Time: 0.13s\nFold 4, Epoch 2, Batch 40, Loss: 1.7118, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 2, Batch 50, Loss: 2.3412, LR: 0.001000, Batch Time: 0.13s\nFold 4, Epoch 2, Batch 60, Loss: 4.0223, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 2, Batch 70, Loss: 3.7863, LR: 0.001000, Batch Time: 0.13s\nFold 4, Epoch 2, Batch 80, Loss: 3.2789, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 2, Batch 90, Loss: 3.2896, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 2, Batch 100, Loss: 3.1409, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 2, Batch 110, Loss: 6.4710, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 2, Batch 120, Loss: 3.7397, LR: 0.001000, Batch Time: 0.13s\nFold 4, Epoch 2, Batch 130, Loss: 3.5893, LR: 0.001000, Batch Time: 0.13s\nFold 4, Epoch 2, Batch 140, Loss: 3.4040, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 2, Batch 150, Loss: 4.0380, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 2, Batch 160, Loss: 3.3876, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 2, Batch 170, Loss: 3.0869, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 2, Batch 180, Loss: 3.7585, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 2, Batch 190, Loss: 3.6398, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 2, Batch 200, Loss: 4.9198, LR: 0.001000, Batch Time: 0.13s\nFold 4, Epoch 2, Batch 210, Loss: 5.8235, LR: 0.001000, Batch Time: 0.13s\nFold 4, Epoch 2, Batch 220, Loss: 2.7498, LR: 0.001000, Batch Time: 0.13s\nFold 4, Epoch 2, Batch 230, Loss: 3.7516, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 2, Batch 240, Loss: 3.9222, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 2, Batch 250, Loss: 3.6292, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 2, Batch 260, Loss: 4.1153, LR: 0.001000, Batch Time: 0.11s\nFold 4, Epoch 2, Batch 270, Loss: 4.8341, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 2, Batch 280, Loss: 3.2993, LR: 0.001000, Batch Time: 0.13s\nFold 4, Epoch 2, Batch 290, Loss: 3.1361, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 2, Batch 300, Loss: 3.4655, LR: 0.001000, Batch Time: 0.13s\nFold 4, Epoch 2, Batch 310, Loss: 3.5798, LR: 0.001000, Batch Time: 0.13s\nSkipped ID 39425: Image file /kaggle/input/fashion-product-images-dataset/fashion-dataset/images/39425.jpg not found\nFold 4, Epoch 2, Batch 320, Loss: 3.0179, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 2, Batch 330, Loss: 3.6642, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 2, Batch 340, Loss: 3.7507, LR: 0.001000, Batch Time: 0.11s\nFold 4, Epoch 2, Batch 350, Loss: 3.6477, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 2, Batch 360, Loss: 3.0705, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 2, Batch 370, Loss: 2.7680, LR: 0.001000, Batch Time: 0.13s\nFold 4, Epoch 2, Batch 380, Loss: 3.9892, LR: 0.001000, Batch Time: 0.11s\nFold 4, Epoch 2, Batch 390, Loss: 4.2528, LR: 0.001000, Batch Time: 0.11s\nFold 4, Epoch 2, Batch 400, Loss: 3.3959, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 2, Batch 410, Loss: 4.4624, LR: 0.001000, Batch Time: 0.11s\nFold 4, Epoch 2, Batch 420, Loss: 4.8502, LR: 0.001000, Batch Time: 0.11s\nFold 4, Epoch 2, Batch 430, Loss: 2.8574, LR: 0.001000, Batch Time: 0.11s\nFold 4, Epoch 2, Batch 440, Loss: 3.4506, LR: 0.001000, Batch Time: 0.13s\nFold 4, Epoch 2, Batch 450, Loss: 5.4733, LR: 0.001000, Batch Time: 0.11s\nFold 4, Epoch 2, Batch 460, Loss: 3.0056, LR: 0.001000, Batch Time: 0.11s\nFold 4, Epoch 2, Batch 470, Loss: 3.5732, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 2, Batch 480, Loss: 3.6328, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 2, Batch 490, Loss: 2.3020, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 2, Batch 500, Loss: 6.0068, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 2, Batch 510, Loss: 3.3639, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 2, Batch 520, Loss: 3.6735, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 2, Batch 530, Loss: 2.8444, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 2, Batch 540, Loss: 4.1218, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 2, Batch 550, Loss: 3.6340, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 2, Batch 560, Loss: 2.8800, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 2, Batch 570, Loss: 3.3163, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 2, Batch 580, Loss: 4.2319, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 2, Batch 590, Loss: 2.9904, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 2, Batch 600, Loss: 3.1522, LR: 0.001000, Batch Time: 0.13s\nFold 4, Epoch 2, Batch 610, Loss: 3.5700, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 2, Batch 620, Loss: 4.6454, LR: 0.001000, Batch Time: 0.13s\nFold 4, Epoch 2, Batch 630, Loss: 3.0614, LR: 0.001000, Batch Time: 0.13s\nFold 4, Epoch 2, Batch 640, Loss: 4.8183, LR: 0.001000, Batch Time: 0.13s\nFold 4, Epoch 2, Batch 650, Loss: 3.3725, LR: 0.001000, Batch Time: 0.13s\nFold 4, Epoch 2, Batch 660, Loss: 2.2391, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 2, Batch 670, Loss: 2.5447, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 2, Batch 680, Loss: 3.0252, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 2, Batch 690, Loss: 3.1295, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 2, Batch 700, Loss: 6.0446, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 2, Batch 710, Loss: 2.2768, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 2, Batch 720, Loss: 2.8883, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 2, Batch 730, Loss: 4.2733, LR: 0.001000, Batch Time: 0.13s\nFold 4, Epoch 2, Batch 740, Loss: 3.1602, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 2, Batch 750, Loss: 3.9070, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 2, Batch 760, Loss: 5.9798, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 2, Batch 770, Loss: 3.3756, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 2, Batch 780, Loss: 3.4711, LR: 0.001000, Batch Time: 0.13s\nFold 4, Epoch 2, Batch 790, Loss: 4.1262, LR: 0.001000, Batch Time: 0.13s\nFold 4, Epoch 2, Batch 800, Loss: 3.3966, LR: 0.001000, Batch Time: 0.13s\nFold 4, Epoch 2, Batch 810, Loss: 2.7385, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 2, Batch 820, Loss: 3.3164, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 2, Batch 830, Loss: 3.4401, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 2, Batch 840, Loss: 2.8578, LR: 0.001000, Batch Time: 0.13s\nFold 4, Epoch 2, Batch 850, Loss: 3.4235, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 2, Batch 860, Loss: 2.7329, LR: 0.001000, Batch Time: 0.13s\nFold 4, Epoch 2, Batch 870, Loss: 3.5056, LR: 0.001000, Batch Time: 0.11s\nFold 4, Epoch 2, Batch 880, Loss: 3.7799, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 2, Batch 890, Loss: 2.9240, LR: 0.001000, Batch Time: 0.11s\nFold 4, Epoch 2, Batch 900, Loss: 3.8969, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 2, Batch 910, Loss: 3.3069, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 2, Batch 920, Loss: 3.6579, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 2, Batch 930, Loss: 4.0380, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 2, Batch 940, Loss: 3.2106, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 2, Train Loss: 3.5831, Epoch 2 Time: 447.95s\nSkipped ID 12347: Image file /kaggle/input/fashion-product-images-dataset/fashion-dataset/images/12347.jpg not found\nSkipped ID 39403: Image file /kaggle/input/fashion-product-images-dataset/fashion-dataset/images/39403.jpg not found\nFold 4, Validation Loss: 15.9953\nFold 4, Validation F1-Scores (Macro) - Color: 0.2723, Type: 0.0316, Season: 0.6246, Gender: 0.7342, Avg F1: 0.4157\nFold 4, Validation Precision (Macro) - Color: 0.2692, Type: 0.0382, Season: 0.6004, Gender: 0.6779\nFold 4, Validation Recall (Macro) - Color: 0.3563, Type: 0.0334, Season: 0.6921, Gender: 0.8244\nFold 4, Validation Accuracy - Color: 0.4361, Type: 0.0306, Season: 0.6095, Gender: 0.8563\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"},{"name":"stdout","text":"Fold 4, Epoch 3, Batch 10, Loss: 2.8384, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 3, Batch 20, Loss: 2.9484, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 3, Batch 30, Loss: 3.2086, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 3, Batch 40, Loss: 3.0102, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 3, Batch 50, Loss: 3.2715, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 3, Batch 60, Loss: 3.2649, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 3, Batch 70, Loss: 3.6307, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 3, Batch 80, Loss: 3.6794, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 3, Batch 90, Loss: 3.4608, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 3, Batch 100, Loss: 2.1700, LR: 0.001000, Batch Time: 0.13s\nFold 4, Epoch 3, Batch 110, Loss: 2.5800, LR: 0.001000, Batch Time: 0.13s\nFold 4, Epoch 3, Batch 120, Loss: 3.1860, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 3, Batch 130, Loss: 5.2150, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 3, Batch 140, Loss: 2.5724, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 3, Batch 150, Loss: 3.4649, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 3, Batch 160, Loss: 2.4279, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 3, Batch 170, Loss: 3.6460, LR: 0.001000, Batch Time: 0.13s\nFold 4, Epoch 3, Batch 180, Loss: 3.0811, LR: 0.001000, Batch Time: 0.13s\nFold 4, Epoch 3, Batch 190, Loss: 3.6689, LR: 0.001000, Batch Time: 0.11s\nFold 4, Epoch 3, Batch 200, Loss: 2.1268, LR: 0.001000, Batch Time: 0.13s\nFold 4, Epoch 3, Batch 210, Loss: 3.5890, LR: 0.001000, Batch Time: 0.11s\nFold 4, Epoch 3, Batch 220, Loss: 2.9782, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 3, Batch 230, Loss: 2.6824, LR: 0.001000, Batch Time: 0.11s\nFold 4, Epoch 3, Batch 240, Loss: 3.3483, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 3, Batch 250, Loss: 3.2707, LR: 0.001000, Batch Time: 0.11s\nFold 4, Epoch 3, Batch 260, Loss: 3.6435, LR: 0.001000, Batch Time: 0.13s\nFold 4, Epoch 3, Batch 270, Loss: 3.5482, LR: 0.001000, Batch Time: 0.11s\nFold 4, Epoch 3, Batch 280, Loss: 3.2907, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 3, Batch 290, Loss: 4.2458, LR: 0.001000, Batch Time: 0.11s\nFold 4, Epoch 3, Batch 300, Loss: 2.8351, LR: 0.001000, Batch Time: 0.13s\nFold 4, Epoch 3, Batch 310, Loss: 2.9140, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 3, Batch 320, Loss: 3.0154, LR: 0.001000, Batch Time: 0.13s\nFold 4, Epoch 3, Batch 330, Loss: 2.9496, LR: 0.001000, Batch Time: 0.13s\nFold 4, Epoch 3, Batch 340, Loss: 4.5785, LR: 0.001000, Batch Time: 0.13s\nFold 4, Epoch 3, Batch 350, Loss: 3.4511, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 3, Batch 360, Loss: 3.7626, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 3, Batch 370, Loss: 2.9646, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 3, Batch 380, Loss: 3.5254, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 3, Batch 390, Loss: 3.0380, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 3, Batch 400, Loss: 3.3770, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 3, Batch 410, Loss: 2.9645, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 3, Batch 420, Loss: 3.9277, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 3, Batch 430, Loss: 3.0590, LR: 0.001000, Batch Time: 0.13s\nFold 4, Epoch 3, Batch 440, Loss: 3.2792, LR: 0.001000, Batch Time: 0.13s\nFold 4, Epoch 3, Batch 450, Loss: 2.5656, LR: 0.001000, Batch Time: 0.13s\nFold 4, Epoch 3, Batch 460, Loss: 3.2275, LR: 0.001000, Batch Time: 0.12s\nSkipped ID 39425: Image file /kaggle/input/fashion-product-images-dataset/fashion-dataset/images/39425.jpg not found\nFold 4, Epoch 3, Batch 470, Loss: 3.3371, LR: 0.001000, Batch Time: 0.13s\nFold 4, Epoch 3, Batch 480, Loss: 2.5497, LR: 0.001000, Batch Time: 0.13s\nFold 4, Epoch 3, Batch 490, Loss: 3.1147, LR: 0.001000, Batch Time: 0.13s\nFold 4, Epoch 3, Batch 500, Loss: 3.3773, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 3, Batch 510, Loss: 2.5910, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 3, Batch 520, Loss: 3.3458, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 3, Batch 530, Loss: 3.2636, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 3, Batch 540, Loss: 2.5864, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 3, Batch 550, Loss: 2.8698, LR: 0.001000, Batch Time: 0.13s\nFold 4, Epoch 3, Batch 560, Loss: 3.7311, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 3, Batch 570, Loss: 2.7797, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 3, Batch 580, Loss: 2.9246, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 3, Batch 590, Loss: 3.2669, LR: 0.001000, Batch Time: 0.12s\nSkipped ID 39401: Image file /kaggle/input/fashion-product-images-dataset/fashion-dataset/images/39401.jpg not found\nFold 4, Epoch 3, Batch 600, Loss: 2.7605, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 3, Batch 610, Loss: 3.6615, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 3, Batch 620, Loss: 2.8436, LR: 0.001000, Batch Time: 0.13s\nFold 4, Epoch 3, Batch 630, Loss: 3.5303, LR: 0.001000, Batch Time: 0.13s\nFold 4, Epoch 3, Batch 640, Loss: 2.3205, LR: 0.001000, Batch Time: 0.13s\nFold 4, Epoch 3, Batch 650, Loss: 3.1088, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 3, Batch 660, Loss: 2.4162, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 3, Batch 670, Loss: 3.2315, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 3, Batch 680, Loss: 2.5113, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 3, Batch 690, Loss: 3.7916, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 3, Batch 700, Loss: 2.8615, LR: 0.001000, Batch Time: 0.13s\nFold 4, Epoch 3, Batch 710, Loss: 2.9678, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 3, Batch 720, Loss: 3.3032, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 3, Batch 730, Loss: 2.4098, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 3, Batch 740, Loss: 3.3861, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 3, Batch 750, Loss: 2.9239, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 3, Batch 760, Loss: 3.4359, LR: 0.001000, Batch Time: 0.13s\nFold 4, Epoch 3, Batch 770, Loss: 2.4094, LR: 0.001000, Batch Time: 0.13s\nFold 4, Epoch 3, Batch 780, Loss: 3.8732, LR: 0.001000, Batch Time: 0.13s\nFold 4, Epoch 3, Batch 790, Loss: 2.9725, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 3, Batch 800, Loss: 2.5719, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 3, Batch 810, Loss: 2.9898, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 3, Batch 820, Loss: 2.4278, LR: 0.001000, Batch Time: 0.13s\nFold 4, Epoch 3, Batch 830, Loss: 2.7941, LR: 0.001000, Batch Time: 0.13s\nFold 4, Epoch 3, Batch 840, Loss: 3.9645, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 3, Batch 850, Loss: 4.2531, LR: 0.001000, Batch Time: 0.13s\nFold 4, Epoch 3, Batch 860, Loss: 3.5737, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 3, Batch 870, Loss: 3.0150, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 3, Batch 880, Loss: 2.3235, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 3, Batch 890, Loss: 3.5433, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 3, Batch 900, Loss: 3.6214, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 3, Batch 910, Loss: 2.8400, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 3, Batch 920, Loss: 3.9531, LR: 0.001000, Batch Time: 0.13s\nFold 4, Epoch 3, Batch 930, Loss: 3.7271, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 3, Batch 940, Loss: 2.9804, LR: 0.001000, Batch Time: 0.13s\nFold 4, Epoch 3, Train Loss: 3.1703, Epoch 3 Time: 454.01s\nSkipped ID 12347: Image file /kaggle/input/fashion-product-images-dataset/fashion-dataset/images/12347.jpg not found\nSkipped ID 39403: Image file /kaggle/input/fashion-product-images-dataset/fashion-dataset/images/39403.jpg not found\nFold 4, Validation Loss: 17.5078\nFold 4, Validation F1-Scores (Macro) - Color: 0.2864, Type: 0.0370, Season: 0.6467, Gender: 0.7168, Avg F1: 0.4217\nFold 4, Validation Precision (Macro) - Color: 0.2826, Type: 0.0385, Season: 0.6176, Gender: 0.6593\nFold 4, Validation Recall (Macro) - Color: 0.3691, Type: 0.0416, Season: 0.7006, Gender: 0.8243\nFold 4, Validation Accuracy - Color: 0.4628, Type: 0.0326, Season: 0.6352, Gender: 0.8579\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"},{"name":"stdout","text":"Fold 4, Epoch 4, Batch 10, Loss: 2.1555, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 4, Batch 20, Loss: 2.2021, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 4, Batch 30, Loss: 2.8285, LR: 0.001000, Batch Time: 0.11s\nFold 4, Epoch 4, Batch 40, Loss: 3.7260, LR: 0.001000, Batch Time: 0.13s\nFold 4, Epoch 4, Batch 50, Loss: 3.4710, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 4, Batch 60, Loss: 3.0944, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 4, Batch 70, Loss: 3.9838, LR: 0.001000, Batch Time: 0.11s\nFold 4, Epoch 4, Batch 80, Loss: 4.1849, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 4, Batch 90, Loss: 2.3927, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 4, Batch 100, Loss: 3.1969, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 4, Batch 110, Loss: 2.5287, LR: 0.001000, Batch Time: 0.13s\nFold 4, Epoch 4, Batch 120, Loss: 3.0185, LR: 0.001000, Batch Time: 0.13s\nFold 4, Epoch 4, Batch 130, Loss: 2.3231, LR: 0.001000, Batch Time: 0.13s\nFold 4, Epoch 4, Batch 140, Loss: 2.4597, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 4, Batch 150, Loss: 2.0957, LR: 0.001000, Batch Time: 0.13s\nFold 4, Epoch 4, Batch 160, Loss: 3.8337, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 4, Batch 170, Loss: 2.1784, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 4, Batch 180, Loss: 2.2702, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 4, Batch 190, Loss: 1.5895, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 4, Batch 200, Loss: 2.5059, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 4, Batch 210, Loss: 3.3218, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 4, Batch 220, Loss: 2.4704, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 4, Batch 230, Loss: 3.4136, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 4, Batch 240, Loss: 3.2625, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 4, Batch 250, Loss: 3.1640, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 4, Batch 260, Loss: 2.9019, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 4, Batch 270, Loss: 2.6367, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 4, Batch 280, Loss: 3.3562, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 4, Batch 290, Loss: 2.2092, LR: 0.001000, Batch Time: 0.11s\nFold 4, Epoch 4, Batch 300, Loss: 2.7965, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 4, Batch 310, Loss: 2.0308, LR: 0.001000, Batch Time: 0.11s\nFold 4, Epoch 4, Batch 320, Loss: 2.9145, LR: 0.001000, Batch Time: 0.13s\nFold 4, Epoch 4, Batch 330, Loss: 2.3202, LR: 0.001000, Batch Time: 0.11s\nFold 4, Epoch 4, Batch 340, Loss: 2.9711, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 4, Batch 350, Loss: 3.3166, LR: 0.001000, Batch Time: 0.11s\nFold 4, Epoch 4, Batch 360, Loss: 2.5041, LR: 0.001000, Batch Time: 0.13s\nFold 4, Epoch 4, Batch 370, Loss: 2.5817, LR: 0.001000, Batch Time: 0.11s\nFold 4, Epoch 4, Batch 380, Loss: 2.8946, LR: 0.001000, Batch Time: 0.13s\nFold 4, Epoch 4, Batch 390, Loss: 2.1249, LR: 0.001000, Batch Time: 0.11s\nFold 4, Epoch 4, Batch 400, Loss: 3.3065, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 4, Batch 410, Loss: 2.7963, LR: 0.001000, Batch Time: 0.11s\nFold 4, Epoch 4, Batch 420, Loss: 3.6859, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 4, Batch 430, Loss: 2.4542, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 4, Batch 440, Loss: 2.3701, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 4, Batch 450, Loss: 2.3194, LR: 0.001000, Batch Time: 0.13s\nFold 4, Epoch 4, Batch 460, Loss: 2.8898, LR: 0.001000, Batch Time: 0.13s\nFold 4, Epoch 4, Batch 470, Loss: 2.6479, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 4, Batch 480, Loss: 3.0620, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 4, Batch 490, Loss: 2.5777, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 4, Batch 500, Loss: 2.3615, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 4, Batch 510, Loss: 3.4537, LR: 0.001000, Batch Time: 0.13s\nFold 4, Epoch 4, Batch 520, Loss: 3.4519, LR: 0.001000, Batch Time: 0.13s\nFold 4, Epoch 4, Batch 530, Loss: 2.5921, LR: 0.001000, Batch Time: 0.13s\nFold 4, Epoch 4, Batch 540, Loss: 3.2575, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 4, Batch 550, Loss: 2.5313, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 4, Batch 560, Loss: 2.1668, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 4, Batch 570, Loss: 2.6415, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 4, Batch 580, Loss: 2.8056, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 4, Batch 590, Loss: 3.7014, LR: 0.001000, Batch Time: 0.13s\nFold 4, Epoch 4, Batch 600, Loss: 3.6914, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 4, Batch 610, Loss: 3.3693, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 4, Batch 620, Loss: 3.8249, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 4, Batch 630, Loss: 3.0260, LR: 0.001000, Batch Time: 0.11s\nFold 4, Epoch 4, Batch 640, Loss: 2.4697, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 4, Batch 650, Loss: 2.5422, LR: 0.001000, Batch Time: 0.11s\nFold 4, Epoch 4, Batch 660, Loss: 3.4508, LR: 0.001000, Batch Time: 0.11s\nFold 4, Epoch 4, Batch 670, Loss: 2.3231, LR: 0.001000, Batch Time: 0.11s\nFold 4, Epoch 4, Batch 680, Loss: 2.9274, LR: 0.001000, Batch Time: 0.11s\nFold 4, Epoch 4, Batch 690, Loss: 1.9685, LR: 0.001000, Batch Time: 0.11s\nFold 4, Epoch 4, Batch 700, Loss: 2.9934, LR: 0.001000, Batch Time: 0.11s\nSkipped ID 39425: Image file /kaggle/input/fashion-product-images-dataset/fashion-dataset/images/39425.jpg not found\nFold 4, Epoch 4, Batch 710, Loss: 2.7395, LR: 0.001000, Batch Time: 0.11s\nFold 4, Epoch 4, Batch 720, Loss: 3.6251, LR: 0.001000, Batch Time: 0.11s\nFold 4, Epoch 4, Batch 730, Loss: 4.2189, LR: 0.001000, Batch Time: 0.11s\nFold 4, Epoch 4, Batch 740, Loss: 3.1273, LR: 0.001000, Batch Time: 0.11s\nFold 4, Epoch 4, Batch 750, Loss: 1.8998, LR: 0.001000, Batch Time: 0.11s\nFold 4, Epoch 4, Batch 760, Loss: 3.8000, LR: 0.001000, Batch Time: 0.11s\nFold 4, Epoch 4, Batch 770, Loss: 2.8248, LR: 0.001000, Batch Time: 0.11s\nFold 4, Epoch 4, Batch 780, Loss: 2.7454, LR: 0.001000, Batch Time: 0.11s\nFold 4, Epoch 4, Batch 790, Loss: 3.9163, LR: 0.001000, Batch Time: 0.11s\nFold 4, Epoch 4, Batch 800, Loss: 2.6395, LR: 0.001000, Batch Time: 0.11s\nFold 4, Epoch 4, Batch 810, Loss: 4.1116, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 4, Batch 820, Loss: 3.2908, LR: 0.001000, Batch Time: 0.11s\nFold 4, Epoch 4, Batch 830, Loss: 2.9320, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 4, Batch 840, Loss: 4.3852, LR: 0.001000, Batch Time: 0.11s\nFold 4, Epoch 4, Batch 850, Loss: 2.7047, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 4, Batch 860, Loss: 2.8051, LR: 0.001000, Batch Time: 0.11s\nFold 4, Epoch 4, Batch 870, Loss: 3.5246, LR: 0.001000, Batch Time: 0.12s\nSkipped ID 39401: Image file /kaggle/input/fashion-product-images-dataset/fashion-dataset/images/39401.jpg not found\nFold 4, Epoch 4, Batch 880, Loss: 2.8552, LR: 0.001000, Batch Time: 0.11s\nFold 4, Epoch 4, Batch 890, Loss: 3.1914, LR: 0.001000, Batch Time: 0.12s\nFold 4, Epoch 4, Batch 900, Loss: 3.6238, LR: 0.001000, Batch Time: 0.11s\nFold 4, Epoch 4, Batch 910, Loss: 2.9090, LR: 0.001000, Batch Time: 0.11s\nFold 4, Epoch 4, Batch 920, Loss: 2.7410, LR: 0.001000, Batch Time: 0.11s\nFold 4, Epoch 4, Batch 930, Loss: 2.6859, LR: 0.001000, Batch Time: 0.11s\nFold 4, Epoch 4, Batch 940, Loss: 3.8853, LR: 0.001000, Batch Time: 0.11s\nFold 4, Epoch 4, Train Loss: 2.9139, Epoch 4 Time: 452.86s\nSkipped ID 12347: Image file /kaggle/input/fashion-product-images-dataset/fashion-dataset/images/12347.jpg not found\nSkipped ID 39403: Image file /kaggle/input/fashion-product-images-dataset/fashion-dataset/images/39403.jpg not found\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"},{"name":"stdout","text":"Fold 4, Validation Loss: 19.6364\nFold 4, Validation F1-Scores (Macro) - Color: 0.2969, Type: 0.0420, Season: 0.6583, Gender: 0.7026, Avg F1: 0.4249\nFold 4, Validation Precision (Macro) - Color: 0.2858, Type: 0.0449, Season: 0.6290, Gender: 0.6421\nFold 4, Validation Recall (Macro) - Color: 0.4201, Type: 0.0453, Season: 0.7089, Gender: 0.8155\nFold 4, Validation Accuracy - Color: 0.4657, Type: 0.0334, Season: 0.6485, Gender: 0.8534\nEarly stopping triggered for Fold 4\nFold 5/5\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Fold 5, Epoch 1, Batch 10, Loss: 10.2194, LR: 0.001000, Batch Time: 0.12s\nFold 5, Epoch 1, Batch 20, Loss: 8.4697, LR: 0.001000, Batch Time: 0.12s\nFold 5, Epoch 1, Batch 30, Loss: 7.6328, LR: 0.001000, Batch Time: 0.11s\nFold 5, Epoch 1, Batch 40, Loss: 7.2539, LR: 0.001000, Batch Time: 0.12s\nFold 5, Epoch 1, Batch 50, Loss: 8.1824, LR: 0.001000, Batch Time: 0.11s\nFold 5, Epoch 1, Batch 60, Loss: 6.3494, LR: 0.001000, Batch Time: 0.12s\nFold 5, Epoch 1, Batch 70, Loss: 7.5950, LR: 0.001000, Batch Time: 0.11s\nFold 5, Epoch 1, Batch 80, Loss: 7.3437, LR: 0.001000, Batch Time: 0.12s\nFold 5, Epoch 1, Batch 90, Loss: 7.3042, LR: 0.001000, Batch Time: 0.11s\nFold 5, Epoch 1, Batch 100, Loss: 5.7118, LR: 0.001000, Batch Time: 0.12s\nFold 5, Epoch 1, Batch 110, Loss: 7.0501, LR: 0.001000, Batch Time: 0.11s\nFold 5, Epoch 1, Batch 120, Loss: 4.7708, LR: 0.001000, Batch Time: 0.12s\nFold 5, Epoch 1, Batch 130, Loss: 5.2638, LR: 0.001000, Batch Time: 0.11s\nFold 5, Epoch 1, Batch 140, Loss: 5.9792, LR: 0.001000, Batch Time: 0.12s\nFold 5, Epoch 1, Batch 150, Loss: 6.7937, LR: 0.001000, Batch Time: 0.13s\nFold 5, Epoch 1, Batch 160, Loss: 4.6283, LR: 0.001000, Batch Time: 0.12s\nFold 5, Epoch 1, Batch 170, Loss: 6.4045, LR: 0.001000, Batch Time: 0.11s\nFold 5, Epoch 1, Batch 180, Loss: 4.9951, LR: 0.001000, Batch Time: 0.12s\nFold 5, Epoch 1, Batch 190, Loss: 7.2769, LR: 0.001000, Batch Time: 0.11s\nFold 5, Epoch 1, Batch 200, Loss: 5.3743, LR: 0.001000, Batch Time: 0.13s\nFold 5, Epoch 1, Batch 210, Loss: 5.6326, LR: 0.001000, Batch Time: 0.11s\nFold 5, Epoch 1, Batch 220, Loss: 4.6252, LR: 0.001000, Batch Time: 0.12s\nFold 5, Epoch 1, Batch 230, Loss: 6.1153, LR: 0.001000, Batch Time: 0.11s\nFold 5, Epoch 1, Batch 240, Loss: 3.6978, LR: 0.001000, Batch Time: 0.12s\nFold 5, Epoch 1, Batch 250, Loss: 4.2269, LR: 0.001000, Batch Time: 0.11s\nFold 5, Epoch 1, Batch 260, Loss: 4.0460, LR: 0.001000, Batch Time: 0.12s\nFold 5, Epoch 1, Batch 270, Loss: 4.5922, LR: 0.001000, Batch Time: 0.11s\nFold 5, Epoch 1, Batch 280, Loss: 5.5688, LR: 0.001000, Batch Time: 0.13s\nFold 5, Epoch 1, Batch 290, Loss: 4.1863, LR: 0.001000, Batch Time: 0.11s\nFold 5, Epoch 1, Batch 300, Loss: 5.2136, LR: 0.001000, Batch Time: 0.13s\nFold 5, Epoch 1, Batch 310, Loss: 6.2310, LR: 0.001000, Batch Time: 0.11s\nFold 5, Epoch 1, Batch 320, Loss: 5.7864, LR: 0.001000, Batch Time: 0.12s\nFold 5, Epoch 1, Batch 330, Loss: 4.6166, LR: 0.001000, Batch Time: 0.11s\nSkipped ID 39401: Image file /kaggle/input/fashion-product-images-dataset/fashion-dataset/images/39401.jpg not found\nFold 5, Epoch 1, Batch 340, Loss: 4.1753, LR: 0.001000, Batch Time: 0.13s\nFold 5, Epoch 1, Batch 350, Loss: 3.5446, LR: 0.001000, Batch Time: 0.11s\nFold 5, Epoch 1, Batch 360, Loss: 5.7002, LR: 0.001000, Batch Time: 0.12s\nFold 5, Epoch 1, Batch 370, Loss: 5.1278, LR: 0.001000, Batch Time: 0.11s\nFold 5, Epoch 1, Batch 380, Loss: 4.0297, LR: 0.001000, Batch Time: 0.11s\nFold 5, Epoch 1, Batch 390, Loss: 3.5082, LR: 0.001000, Batch Time: 0.11s\nFold 5, Epoch 1, Batch 400, Loss: 7.1093, LR: 0.001000, Batch Time: 0.12s\nFold 5, Epoch 1, Batch 410, Loss: 4.6994, LR: 0.001000, Batch Time: 0.11s\nFold 5, Epoch 1, Batch 420, Loss: 4.2008, LR: 0.001000, Batch Time: 0.12s\nFold 5, Epoch 1, Batch 430, Loss: 4.8063, LR: 0.001000, Batch Time: 0.11s\nFold 5, Epoch 1, Batch 440, Loss: 7.0673, LR: 0.001000, Batch Time: 0.12s\nFold 5, Epoch 1, Batch 450, Loss: 4.0779, LR: 0.001000, Batch Time: 0.11s\nFold 5, Epoch 1, Batch 460, Loss: 4.3026, LR: 0.001000, Batch Time: 0.12s\nFold 5, Epoch 1, Batch 470, Loss: 5.0264, LR: 0.001000, Batch Time: 0.11s\nFold 5, Epoch 1, Batch 480, Loss: 4.9722, LR: 0.001000, Batch Time: 0.11s\nFold 5, Epoch 1, Batch 490, Loss: 3.5918, LR: 0.001000, Batch Time: 0.11s\nFold 5, Epoch 1, Batch 500, Loss: 3.8436, LR: 0.001000, Batch Time: 0.11s\nSkipped ID 12347: Image file /kaggle/input/fashion-product-images-dataset/fashion-dataset/images/12347.jpg not found\nFold 5, Epoch 1, Batch 510, Loss: 4.1749, LR: 0.001000, Batch Time: 0.11s\nFold 5, Epoch 1, Batch 520, Loss: 4.9727, LR: 0.001000, Batch Time: 0.11s\nFold 5, Epoch 1, Batch 530, Loss: 4.4155, LR: 0.001000, Batch Time: 0.12s\nFold 5, Epoch 1, Batch 540, Loss: 5.0875, LR: 0.001000, Batch Time: 0.11s\nFold 5, Epoch 1, Batch 550, Loss: 8.5424, LR: 0.001000, Batch Time: 0.12s\nFold 5, Epoch 1, Batch 560, Loss: 4.6797, LR: 0.001000, Batch Time: 0.13s\nFold 5, Epoch 1, Batch 570, Loss: 3.3001, LR: 0.001000, Batch Time: 0.12s\nFold 5, Epoch 1, Batch 580, Loss: 3.6258, LR: 0.001000, Batch Time: 0.11s\nFold 5, Epoch 1, Batch 590, Loss: 3.5125, LR: 0.001000, Batch Time: 0.12s\nFold 5, Epoch 1, Batch 600, Loss: 3.5866, LR: 0.001000, Batch Time: 0.11s\nFold 5, Epoch 1, Batch 610, Loss: 4.1564, LR: 0.001000, Batch Time: 0.12s\nFold 5, Epoch 1, Batch 620, Loss: 4.4316, LR: 0.001000, Batch Time: 0.11s\nFold 5, Epoch 1, Batch 630, Loss: 5.1859, LR: 0.001000, Batch Time: 0.13s\nSkipped ID 39403: Image file /kaggle/input/fashion-product-images-dataset/fashion-dataset/images/39403.jpg not found\nFold 5, Epoch 1, Batch 640, Loss: 3.7358, LR: 0.001000, Batch Time: 0.11s\nFold 5, Epoch 1, Batch 650, Loss: 4.0925, LR: 0.001000, Batch Time: 0.13s\nSkipped ID 39425: Image file /kaggle/input/fashion-product-images-dataset/fashion-dataset/images/39425.jpg not found\nFold 5, Epoch 1, Batch 660, Loss: 3.3365, LR: 0.001000, Batch Time: 0.11s\nFold 5, Epoch 1, Batch 670, Loss: 3.7128, LR: 0.001000, Batch Time: 0.12s\nFold 5, Epoch 1, Batch 680, Loss: 3.7999, LR: 0.001000, Batch Time: 0.11s\nFold 5, Epoch 1, Batch 690, Loss: 3.2093, LR: 0.001000, Batch Time: 0.12s\nFold 5, Epoch 1, Batch 700, Loss: 3.3651, LR: 0.001000, Batch Time: 0.11s\nFold 5, Epoch 1, Batch 710, Loss: 5.4978, LR: 0.001000, Batch Time: 0.12s\nFold 5, Epoch 1, Batch 720, Loss: 4.8955, LR: 0.001000, Batch Time: 0.11s\nFold 5, Epoch 1, Batch 730, Loss: 4.7667, LR: 0.001000, Batch Time: 0.12s\nFold 5, Epoch 1, Batch 740, Loss: 3.3427, LR: 0.001000, Batch Time: 0.11s\nFold 5, Epoch 1, Batch 750, Loss: 6.2012, LR: 0.001000, Batch Time: 0.12s\nFold 5, Epoch 1, Batch 760, Loss: 3.1196, LR: 0.001000, Batch Time: 0.11s\nFold 5, Epoch 1, Batch 770, Loss: 3.4386, LR: 0.001000, Batch Time: 0.12s\nFold 5, Epoch 1, Batch 780, Loss: 4.8876, LR: 0.001000, Batch Time: 0.11s\nFold 5, Epoch 1, Batch 790, Loss: 4.7003, LR: 0.001000, Batch Time: 0.12s\nFold 5, Epoch 1, Batch 800, Loss: 5.1588, LR: 0.001000, Batch Time: 0.11s\nFold 5, Epoch 1, Batch 810, Loss: 3.1020, LR: 0.001000, Batch Time: 0.12s\nFold 5, Epoch 1, Batch 820, Loss: 3.7227, LR: 0.001000, Batch Time: 0.11s\nFold 5, Epoch 1, Batch 830, Loss: 4.1370, LR: 0.001000, Batch Time: 0.12s\nFold 5, Epoch 1, Batch 840, Loss: 3.7086, LR: 0.001000, Batch Time: 0.11s\nFold 5, Epoch 1, Batch 850, Loss: 4.1043, LR: 0.001000, Batch Time: 0.12s\nFold 5, Epoch 1, Batch 860, Loss: 5.3415, LR: 0.001000, Batch Time: 0.11s\nFold 5, Epoch 1, Batch 870, Loss: 3.3130, LR: 0.001000, Batch Time: 0.12s\nFold 5, Epoch 1, Batch 880, Loss: 5.9039, LR: 0.001000, Batch Time: 0.11s\nFold 5, Epoch 1, Batch 890, Loss: 6.0855, LR: 0.001000, Batch Time: 0.11s\nFold 5, Epoch 1, Batch 900, Loss: 5.2519, LR: 0.001000, Batch Time: 0.11s\nFold 5, Epoch 1, Batch 910, Loss: 3.1402, LR: 0.001000, Batch Time: 0.12s\nFold 5, Epoch 1, Batch 920, Loss: 3.9523, LR: 0.001000, Batch Time: 0.11s\nFold 5, Epoch 1, Batch 930, Loss: 3.3486, LR: 0.001000, Batch Time: 0.12s\nFold 5, Epoch 1, Batch 940, Loss: 3.4130, LR: 0.001000, Batch Time: 0.11s\nFold 5, Epoch 1, Train Loss: 4.9026, Epoch 1 Time: 450.00s\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"},{"name":"stdout","text":"Fold 5, Validation Loss: 12.3533\nFold 5, Validation F1-Scores (Macro) - Color: 0.2714, Type: 0.0307, Season: 0.6355, Gender: 0.6834, Avg F1: 0.4053\nFold 5, Validation Precision (Macro) - Color: 0.2693, Type: 0.0361, Season: 0.6143, Gender: 0.6267\nFold 5, Validation Recall (Macro) - Color: 0.3404, Type: 0.0290, Season: 0.7030, Gender: 0.7899\nFold 5, Validation Accuracy - Color: 0.5010, Type: 0.0317, Season: 0.6062, Gender: 0.8460\nSaved best model from Fold 5 at /kaggle/working/best_model.pth (Avg F1: 0.4053)\nFold 5, Epoch 2, Batch 10, Loss: 2.7746, LR: 0.001000, Batch Time: 0.11s\nFold 5, Epoch 2, Batch 20, Loss: 3.2333, LR: 0.001000, Batch Time: 0.11s\nFold 5, Epoch 2, Batch 30, Loss: 5.0225, LR: 0.001000, Batch Time: 0.11s\nFold 5, Epoch 2, Batch 40, Loss: 3.7041, LR: 0.001000, Batch Time: 0.11s\nFold 5, Epoch 2, Batch 50, Loss: 3.4939, LR: 0.001000, Batch Time: 0.11s\nFold 5, Epoch 2, Batch 60, Loss: 2.8950, LR: 0.001000, Batch Time: 0.11s\nFold 5, Epoch 2, Batch 70, Loss: 6.9072, LR: 0.001000, Batch Time: 0.11s\nSkipped ID 39425: Image file /kaggle/input/fashion-product-images-dataset/fashion-dataset/images/39425.jpg not found\nFold 5, Epoch 2, Batch 80, Loss: 3.3796, LR: 0.001000, Batch Time: 0.11s\nFold 5, Epoch 2, Batch 90, Loss: 2.9759, LR: 0.001000, Batch Time: 0.11s\nFold 5, Epoch 2, Batch 100, Loss: 3.3307, LR: 0.001000, Batch Time: 0.11s\nFold 5, Epoch 2, Batch 110, Loss: 3.4944, LR: 0.001000, Batch Time: 0.11s\nFold 5, Epoch 2, Batch 120, Loss: 2.7165, LR: 0.001000, Batch Time: 0.11s\nSkipped ID 39403: Image file /kaggle/input/fashion-product-images-dataset/fashion-dataset/images/39403.jpg not found\nFold 5, Epoch 2, Batch 130, Loss: 2.7278, LR: 0.001000, Batch Time: 0.11s\nFold 5, Epoch 2, Batch 140, Loss: 3.0451, LR: 0.001000, Batch Time: 0.11s\nFold 5, Epoch 2, Batch 150, Loss: 2.5675, LR: 0.001000, Batch Time: 0.12s\nFold 5, Epoch 2, Batch 160, Loss: 4.5580, LR: 0.001000, Batch Time: 0.11s\nFold 5, Epoch 2, Batch 170, Loss: 3.3586, LR: 0.001000, Batch Time: 0.12s\nFold 5, Epoch 2, Batch 180, Loss: 3.1633, LR: 0.001000, Batch Time: 0.11s\nFold 5, Epoch 2, Batch 190, Loss: 3.0981, LR: 0.001000, Batch Time: 0.12s\nFold 5, Epoch 2, Batch 200, Loss: 3.3461, LR: 0.001000, Batch Time: 0.11s\nFold 5, Epoch 2, Batch 210, Loss: 2.6484, LR: 0.001000, Batch Time: 0.12s\nFold 5, Epoch 2, Batch 220, Loss: 3.4803, LR: 0.001000, Batch Time: 0.11s\nFold 5, Epoch 2, Batch 230, Loss: 4.1804, LR: 0.001000, Batch Time: 0.12s\nFold 5, Epoch 2, Batch 240, Loss: 2.3510, LR: 0.001000, Batch Time: 0.11s\nFold 5, Epoch 2, Batch 250, Loss: 2.9751, LR: 0.001000, Batch Time: 0.12s\nFold 5, Epoch 2, Batch 260, Loss: 4.7643, LR: 0.001000, Batch Time: 0.11s\nFold 5, Epoch 2, Batch 270, Loss: 4.0146, LR: 0.001000, Batch Time: 0.12s\nFold 5, Epoch 2, Batch 280, Loss: 3.2574, LR: 0.001000, Batch Time: 0.11s\nFold 5, Epoch 2, Batch 290, Loss: 3.3200, LR: 0.001000, Batch Time: 0.12s\nFold 5, Epoch 2, Batch 300, Loss: 3.1865, LR: 0.001000, Batch Time: 0.11s\nFold 5, Epoch 2, Batch 310, Loss: 3.6075, LR: 0.001000, Batch Time: 0.12s\nFold 5, Epoch 2, Batch 320, Loss: 2.3985, LR: 0.001000, Batch Time: 0.13s\nFold 5, Epoch 2, Batch 330, Loss: 4.8364, LR: 0.001000, Batch Time: 0.13s\nFold 5, Epoch 2, Batch 340, Loss: 3.2367, LR: 0.001000, Batch Time: 0.13s\nFold 5, Epoch 2, Batch 350, Loss: 3.1328, LR: 0.001000, Batch Time: 0.12s\nFold 5, Epoch 2, Batch 360, Loss: 3.4051, LR: 0.001000, Batch Time: 0.11s\nFold 5, Epoch 2, Batch 370, Loss: 3.4911, LR: 0.001000, Batch Time: 0.12s\nFold 5, Epoch 2, Batch 380, Loss: 2.8986, LR: 0.001000, Batch Time: 0.12s\nFold 5, Epoch 2, Batch 390, Loss: 2.9154, LR: 0.001000, Batch Time: 0.12s\nFold 5, Epoch 2, Batch 400, Loss: 3.3196, LR: 0.001000, Batch Time: 0.12s\nFold 5, Epoch 2, Batch 410, Loss: 3.0110, LR: 0.001000, Batch Time: 0.12s\nSkipped ID 12347: Image file /kaggle/input/fashion-product-images-dataset/fashion-dataset/images/12347.jpg not found\nFold 5, Epoch 2, Batch 420, Loss: 5.1095, LR: 0.001000, Batch Time: 0.13s\nFold 5, Epoch 2, Batch 430, Loss: 2.5648, LR: 0.001000, Batch Time: 0.12s\nFold 5, Epoch 2, Batch 440, Loss: 3.6998, LR: 0.001000, Batch Time: 0.13s\nFold 5, Epoch 2, Batch 450, Loss: 3.9788, LR: 0.001000, Batch Time: 0.13s\nFold 5, Epoch 2, Batch 460, Loss: 3.3419, LR: 0.001000, Batch Time: 0.12s\nFold 5, Epoch 2, Batch 470, Loss: 3.3495, LR: 0.001000, Batch Time: 0.12s\nFold 5, Epoch 2, Batch 480, Loss: 2.7784, LR: 0.001000, Batch Time: 0.12s\nFold 5, Epoch 2, Batch 490, Loss: 5.1914, LR: 0.001000, Batch Time: 0.13s\nFold 5, Epoch 2, Batch 500, Loss: 3.5139, LR: 0.001000, Batch Time: 0.13s\nFold 5, Epoch 2, Batch 510, Loss: 2.9468, LR: 0.001000, Batch Time: 0.13s\nFold 5, Epoch 2, Batch 520, Loss: 4.0794, LR: 0.001000, Batch Time: 0.12s\nFold 5, Epoch 2, Batch 530, Loss: 2.8438, LR: 0.001000, Batch Time: 0.12s\nFold 5, Epoch 2, Batch 540, Loss: 4.0854, LR: 0.001000, Batch Time: 0.12s\nFold 5, Epoch 2, Batch 550, Loss: 4.4548, LR: 0.001000, Batch Time: 0.13s\nFold 5, Epoch 2, Batch 560, Loss: 3.1995, LR: 0.001000, Batch Time: 0.12s\nFold 5, Epoch 2, Batch 570, Loss: 4.7796, LR: 0.001000, Batch Time: 0.12s\nFold 5, Epoch 2, Batch 580, Loss: 3.1079, LR: 0.001000, Batch Time: 0.12s\nFold 5, Epoch 2, Batch 590, Loss: 3.3193, LR: 0.001000, Batch Time: 0.12s\nSkipped ID 39401: Image file /kaggle/input/fashion-product-images-dataset/fashion-dataset/images/39401.jpg not found\nFold 5, Epoch 2, Batch 600, Loss: 3.3877, LR: 0.001000, Batch Time: 0.12s\nFold 5, Epoch 2, Batch 610, Loss: 3.5624, LR: 0.001000, Batch Time: 0.13s\nFold 5, Epoch 2, Batch 620, Loss: 3.5954, LR: 0.001000, Batch Time: 0.12s\nFold 5, Epoch 2, Batch 630, Loss: 4.2462, LR: 0.001000, Batch Time: 0.13s\nFold 5, Epoch 2, Batch 640, Loss: 3.4207, LR: 0.001000, Batch Time: 0.11s\nFold 5, Epoch 2, Batch 650, Loss: 5.6054, LR: 0.001000, Batch Time: 0.13s\nFold 5, Epoch 2, Batch 660, Loss: 3.2315, LR: 0.001000, Batch Time: 0.11s\nFold 5, Epoch 2, Batch 670, Loss: 4.5230, LR: 0.001000, Batch Time: 0.12s\nFold 5, Epoch 2, Batch 680, Loss: 3.3135, LR: 0.001000, Batch Time: 0.11s\nFold 5, Epoch 2, Batch 690, Loss: 3.0817, LR: 0.001000, Batch Time: 0.13s\nFold 5, Epoch 2, Batch 700, Loss: 5.0153, LR: 0.001000, Batch Time: 0.12s\nFold 5, Epoch 2, Batch 710, Loss: 2.8720, LR: 0.001000, Batch Time: 0.13s\nFold 5, Epoch 2, Batch 720, Loss: 3.2542, LR: 0.001000, Batch Time: 0.11s\nFold 5, Epoch 2, Batch 730, Loss: 3.4951, LR: 0.001000, Batch Time: 0.12s\nFold 5, Epoch 2, Batch 740, Loss: 3.3755, LR: 0.001000, Batch Time: 0.11s\nFold 5, Epoch 2, Batch 750, Loss: 3.2295, LR: 0.001000, Batch Time: 0.13s\nFold 5, Epoch 2, Batch 760, Loss: 4.1314, LR: 0.001000, Batch Time: 0.12s\nFold 5, Epoch 2, Batch 770, Loss: 2.8913, LR: 0.001000, Batch Time: 0.13s\nFold 5, Epoch 2, Batch 780, Loss: 5.1697, LR: 0.001000, Batch Time: 0.11s\nFold 5, Epoch 2, Batch 790, Loss: 2.7441, LR: 0.001000, Batch Time: 0.12s\nFold 5, Epoch 2, Batch 800, Loss: 3.4887, LR: 0.001000, Batch Time: 0.12s\nFold 5, Epoch 2, Batch 810, Loss: 4.5319, LR: 0.001000, Batch Time: 0.13s\nFold 5, Epoch 2, Batch 820, Loss: 3.1581, LR: 0.001000, Batch Time: 0.12s\nFold 5, Epoch 2, Batch 830, Loss: 2.6670, LR: 0.001000, Batch Time: 0.13s\nFold 5, Epoch 2, Batch 840, Loss: 3.0275, LR: 0.001000, Batch Time: 0.12s\nFold 5, Epoch 2, Batch 850, Loss: 5.0825, LR: 0.001000, Batch Time: 0.12s\nFold 5, Epoch 2, Batch 860, Loss: 3.0402, LR: 0.001000, Batch Time: 0.11s\nFold 5, Epoch 2, Batch 870, Loss: 3.0331, LR: 0.001000, Batch Time: 0.12s\nFold 5, Epoch 2, Batch 880, Loss: 2.7994, LR: 0.001000, Batch Time: 0.13s\nFold 5, Epoch 2, Batch 890, Loss: 2.5290, LR: 0.001000, Batch Time: 0.12s\nFold 5, Epoch 2, Batch 900, Loss: 2.7052, LR: 0.001000, Batch Time: 0.13s\nFold 5, Epoch 2, Batch 910, Loss: 3.0317, LR: 0.001000, Batch Time: 0.12s\nFold 5, Epoch 2, Batch 920, Loss: 2.9730, LR: 0.001000, Batch Time: 0.13s\nFold 5, Epoch 2, Batch 930, Loss: 2.9508, LR: 0.001000, Batch Time: 0.12s\nFold 5, Epoch 2, Batch 940, Loss: 3.5694, LR: 0.001000, Batch Time: 0.11s\nFold 5, Epoch 2, Train Loss: 3.4778, Epoch 2 Time: 570.60s\nFold 5, Validation Loss: 13.5845\nFold 5, Validation F1-Scores (Macro) - Color: 0.2939, Type: 0.0353, Season: 0.6607, Gender: 0.6883, Avg F1: 0.4196\nFold 5, Validation Precision (Macro) - Color: 0.2879, Type: 0.0483, Season: 0.6307, Gender: 0.6346\nFold 5, Validation Recall (Macro) - Color: 0.3794, Type: 0.0356, Season: 0.7178, Gender: 0.7984\nFold 5, Validation Accuracy - Color: 0.5062, Type: 0.0265, Season: 0.6410, Gender: 0.8501\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"},{"name":"stdout","text":"Fold 5, Epoch 3, Batch 10, Loss: 2.1855, LR: 0.001000, Batch Time: 0.12s\nFold 5, Epoch 3, Batch 20, Loss: 2.8926, LR: 0.001000, Batch Time: 0.12s\nFold 5, Epoch 3, Batch 30, Loss: 2.4129, LR: 0.001000, Batch Time: 0.12s\nFold 5, Epoch 3, Batch 40, Loss: 2.5849, LR: 0.001000, Batch Time: 0.12s\nFold 5, Epoch 3, Batch 50, Loss: 3.9259, LR: 0.001000, Batch Time: 0.12s\nFold 5, Epoch 3, Batch 60, Loss: 1.8808, LR: 0.001000, Batch Time: 0.12s\nFold 5, Epoch 3, Batch 70, Loss: 2.3532, LR: 0.001000, Batch Time: 0.12s\nFold 5, Epoch 3, Batch 80, Loss: 2.5266, LR: 0.001000, Batch Time: 0.12s\nFold 5, Epoch 3, Batch 90, Loss: 2.4777, LR: 0.001000, Batch Time: 0.13s\nFold 5, Epoch 3, Batch 100, Loss: 2.5939, LR: 0.001000, Batch Time: 0.12s\nFold 5, Epoch 3, Batch 110, Loss: 3.4952, LR: 0.001000, Batch Time: 0.13s\nFold 5, Epoch 3, Batch 120, Loss: 3.0998, LR: 0.001000, Batch Time: 0.12s\nFold 5, Epoch 3, Batch 130, Loss: 4.3076, LR: 0.001000, Batch Time: 0.12s\nFold 5, Epoch 3, Batch 140, Loss: 2.6010, LR: 0.001000, Batch Time: 0.12s\nFold 5, Epoch 3, Batch 150, Loss: 2.5994, LR: 0.001000, Batch Time: 0.12s\nFold 5, Epoch 3, Batch 160, Loss: 4.5017, LR: 0.001000, Batch Time: 0.13s\nFold 5, Epoch 3, Batch 170, Loss: 2.6801, LR: 0.001000, Batch Time: 0.12s\nFold 5, Epoch 3, Batch 180, Loss: 3.4365, LR: 0.001000, Batch Time: 0.11s\nFold 5, Epoch 3, Batch 190, Loss: 2.6727, LR: 0.001000, Batch Time: 0.12s\nFold 5, Epoch 3, Batch 200, Loss: 2.0934, LR: 0.001000, Batch Time: 0.11s\nFold 5, Epoch 3, Batch 210, Loss: 3.6788, LR: 0.001000, Batch Time: 0.13s\nFold 5, Epoch 3, Batch 220, Loss: 2.3719, LR: 0.001000, Batch Time: 0.11s\nFold 5, Epoch 3, Batch 230, Loss: 3.1562, LR: 0.001000, Batch Time: 0.13s\nFold 5, Epoch 3, Batch 240, Loss: 2.2585, LR: 0.001000, Batch Time: 0.11s\nFold 5, Epoch 3, Batch 250, Loss: 2.8761, LR: 0.001000, Batch Time: 0.12s\nFold 5, Epoch 3, Batch 260, Loss: 3.2134, LR: 0.001000, Batch Time: 0.12s\nFold 5, Epoch 3, Batch 270, Loss: 2.5039, LR: 0.001000, Batch Time: 0.13s\nFold 5, Epoch 3, Batch 280, Loss: 2.3541, LR: 0.001000, Batch Time: 0.12s\nFold 5, Epoch 3, Batch 290, Loss: 6.6629, LR: 0.001000, Batch Time: 0.13s\nFold 5, Epoch 3, Batch 300, Loss: 2.9972, LR: 0.001000, Batch Time: 0.11s\nFold 5, Epoch 3, Batch 310, Loss: 2.6446, LR: 0.001000, Batch Time: 0.11s\nFold 5, Epoch 3, Batch 320, Loss: 2.2065, LR: 0.001000, Batch Time: 0.11s\nFold 5, Epoch 3, Batch 330, Loss: 2.9460, LR: 0.001000, Batch Time: 0.13s\nFold 5, Epoch 3, Batch 340, Loss: 2.5685, LR: 0.001000, Batch Time: 0.11s\nFold 5, Epoch 3, Batch 350, Loss: 3.5377, LR: 0.001000, Batch Time: 0.13s\nFold 5, Epoch 3, Batch 360, Loss: 3.5411, LR: 0.001000, Batch Time: 0.12s\nFold 5, Epoch 3, Batch 370, Loss: 2.2717, LR: 0.001000, Batch Time: 0.13s\nFold 5, Epoch 3, Batch 380, Loss: 1.9971, LR: 0.001000, Batch Time: 0.12s\nFold 5, Epoch 3, Batch 390, Loss: 2.3478, LR: 0.001000, Batch Time: 0.11s\nSkipped ID 39403: Image file /kaggle/input/fashion-product-images-dataset/fashion-dataset/images/39403.jpg not found\nFold 5, Epoch 3, Batch 400, Loss: 3.5356, LR: 0.001000, Batch Time: 0.11s\nFold 5, Epoch 3, Batch 410, Loss: 2.2492, LR: 0.001000, Batch Time: 0.12s\nFold 5, Epoch 3, Batch 420, Loss: 3.8882, LR: 0.001000, Batch Time: 0.11s\nFold 5, Epoch 3, Batch 430, Loss: 3.0960, LR: 0.001000, Batch Time: 0.11s\nFold 5, Epoch 3, Batch 440, Loss: 2.1225, LR: 0.001000, Batch Time: 0.10s\nFold 5, Epoch 3, Batch 450, Loss: 2.6777, LR: 0.001000, Batch Time: 0.11s\nFold 5, Epoch 3, Batch 460, Loss: 2.7097, LR: 0.001000, Batch Time: 0.11s\nFold 5, Epoch 3, Batch 470, Loss: 2.8011, LR: 0.001000, Batch Time: 0.11s\nFold 5, Epoch 3, Batch 480, Loss: 2.3968, LR: 0.001000, Batch Time: 0.12s\nFold 5, Epoch 3, Batch 490, Loss: 3.1268, LR: 0.001000, Batch Time: 0.11s\nFold 5, Epoch 3, Batch 500, Loss: 4.1368, LR: 0.001000, Batch Time: 0.12s\nFold 5, Epoch 3, Batch 510, Loss: 3.3073, LR: 0.001000, Batch Time: 0.11s\nFold 5, Epoch 3, Batch 520, Loss: 3.5080, LR: 0.001000, Batch Time: 0.12s\nFold 5, Epoch 3, Batch 530, Loss: 2.7038, LR: 0.001000, Batch Time: 0.11s\nFold 5, Epoch 3, Batch 540, Loss: 3.9877, LR: 0.001000, Batch Time: 0.12s\nFold 5, Epoch 3, Batch 550, Loss: 2.8311, LR: 0.001000, Batch Time: 0.13s\nFold 5, Epoch 3, Batch 560, Loss: 2.5338, LR: 0.001000, Batch Time: 0.12s\nFold 5, Epoch 3, Batch 570, Loss: 2.8145, LR: 0.001000, Batch Time: 0.13s\nFold 5, Epoch 3, Batch 580, Loss: 2.5647, LR: 0.001000, Batch Time: 0.12s\nFold 5, Epoch 3, Batch 590, Loss: 2.5663, LR: 0.001000, Batch Time: 0.13s\nFold 5, Epoch 3, Batch 600, Loss: 3.5299, LR: 0.001000, Batch Time: 0.12s\nFold 5, Epoch 3, Batch 610, Loss: 2.3430, LR: 0.001000, Batch Time: 0.13s\nFold 5, Epoch 3, Batch 620, Loss: 2.5426, LR: 0.001000, Batch Time: 0.12s\nFold 5, Epoch 3, Batch 630, Loss: 2.6339, LR: 0.001000, Batch Time: 0.13s\nFold 5, Epoch 3, Batch 640, Loss: 2.9362, LR: 0.001000, Batch Time: 0.12s\nFold 5, Epoch 3, Batch 650, Loss: 2.4683, LR: 0.001000, Batch Time: 0.11s\nFold 5, Epoch 3, Batch 660, Loss: 3.1590, LR: 0.001000, Batch Time: 0.12s\nFold 5, Epoch 3, Batch 670, Loss: 6.0465, LR: 0.001000, Batch Time: 0.11s\nFold 5, Epoch 3, Batch 680, Loss: 3.3828, LR: 0.001000, Batch Time: 0.12s\nFold 5, Epoch 3, Batch 690, Loss: 2.2740, LR: 0.001000, Batch Time: 0.13s\nFold 5, Epoch 3, Batch 700, Loss: 3.0934, LR: 0.001000, Batch Time: 0.12s\nFold 5, Epoch 3, Batch 710, Loss: 4.0989, LR: 0.001000, Batch Time: 0.13s\nFold 5, Epoch 3, Batch 720, Loss: 2.9644, LR: 0.001000, Batch Time: 0.11s\nFold 5, Epoch 3, Batch 730, Loss: 3.3889, LR: 0.001000, Batch Time: 0.11s\nFold 5, Epoch 3, Batch 740, Loss: 3.4409, LR: 0.001000, Batch Time: 0.11s\nSkipped ID 39401: Image file /kaggle/input/fashion-product-images-dataset/fashion-dataset/images/39401.jpg not found\nFold 5, Epoch 3, Batch 750, Loss: 3.6979, LR: 0.001000, Batch Time: 0.12s\nFold 5, Epoch 3, Batch 760, Loss: 2.5197, LR: 0.001000, Batch Time: 0.13s\nSkipped ID 39425: Image file /kaggle/input/fashion-product-images-dataset/fashion-dataset/images/39425.jpg not found\nFold 5, Epoch 3, Batch 770, Loss: 2.6623, LR: 0.001000, Batch Time: 0.11s\nFold 5, Epoch 3, Batch 780, Loss: 3.6512, LR: 0.001000, Batch Time: 0.12s\nFold 5, Epoch 3, Batch 790, Loss: 3.4337, LR: 0.001000, Batch Time: 0.12s\nFold 5, Epoch 3, Batch 800, Loss: 3.8826, LR: 0.001000, Batch Time: 0.11s\nFold 5, Epoch 3, Batch 810, Loss: 3.0566, LR: 0.001000, Batch Time: 0.11s\nFold 5, Epoch 3, Batch 820, Loss: 2.8395, LR: 0.001000, Batch Time: 0.11s\nFold 5, Epoch 3, Batch 830, Loss: 3.3382, LR: 0.001000, Batch Time: 0.11s\nSkipped ID 12347: Image file /kaggle/input/fashion-product-images-dataset/fashion-dataset/images/12347.jpg not found\nFold 5, Epoch 3, Batch 840, Loss: 3.8322, LR: 0.001000, Batch Time: 0.11s\nFold 5, Epoch 3, Batch 850, Loss: 2.5422, LR: 0.001000, Batch Time: 0.11s\nFold 5, Epoch 3, Batch 860, Loss: 3.3694, LR: 0.001000, Batch Time: 0.11s\nFold 5, Epoch 3, Batch 870, Loss: 2.0058, LR: 0.001000, Batch Time: 0.12s\nFold 5, Epoch 3, Batch 880, Loss: 2.9495, LR: 0.001000, Batch Time: 0.11s\nFold 5, Epoch 3, Batch 890, Loss: 2.9246, LR: 0.001000, Batch Time: 0.13s\nFold 5, Epoch 3, Batch 900, Loss: 4.1844, LR: 0.001000, Batch Time: 0.11s\nFold 5, Epoch 3, Batch 910, Loss: 2.7691, LR: 0.001000, Batch Time: 0.12s\nFold 5, Epoch 3, Batch 920, Loss: 2.9954, LR: 0.001000, Batch Time: 0.11s\nFold 5, Epoch 3, Batch 930, Loss: 2.0789, LR: 0.001000, Batch Time: 0.12s\nFold 5, Epoch 3, Batch 940, Loss: 3.0270, LR: 0.001000, Batch Time: 0.11s\nFold 5, Epoch 3, Train Loss: 3.0537, Epoch 3 Time: 564.96s\nFold 5, Validation Loss: 14.7471\nFold 5, Validation F1-Scores (Macro) - Color: 0.3060, Type: 0.0356, Season: 0.6617, Gender: 0.7355, Avg F1: 0.4347\nFold 5, Validation Precision (Macro) - Color: 0.2938, Type: 0.0380, Season: 0.6299, Gender: 0.6845\nFold 5, Validation Recall (Macro) - Color: 0.4057, Type: 0.0377, Season: 0.7250, Gender: 0.8148\nFold 5, Validation Accuracy - Color: 0.5237, Type: 0.0317, Season: 0.6518, Gender: 0.8687\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"},{"name":"stdout","text":"Fold 5, Epoch 4, Batch 10, Loss: 3.1778, LR: 0.001000, Batch Time: 0.11s\nFold 5, Epoch 4, Batch 20, Loss: 3.0147, LR: 0.001000, Batch Time: 0.12s\nFold 5, Epoch 4, Batch 30, Loss: 4.6906, LR: 0.001000, Batch Time: 0.11s\nFold 5, Epoch 4, Batch 40, Loss: 1.8728, LR: 0.001000, Batch Time: 0.12s\nFold 5, Epoch 4, Batch 50, Loss: 1.8967, LR: 0.001000, Batch Time: 0.12s\nFold 5, Epoch 4, Batch 60, Loss: 2.8500, LR: 0.001000, Batch Time: 0.12s\nFold 5, Epoch 4, Batch 70, Loss: 3.2646, LR: 0.001000, Batch Time: 0.11s\nFold 5, Epoch 4, Batch 80, Loss: 3.1452, LR: 0.001000, Batch Time: 0.12s\nFold 5, Epoch 4, Batch 90, Loss: 1.8550, LR: 0.001000, Batch Time: 0.13s\nFold 5, Epoch 4, Batch 100, Loss: 2.7099, LR: 0.001000, Batch Time: 0.12s\nFold 5, Epoch 4, Batch 110, Loss: 2.8721, LR: 0.001000, Batch Time: 0.11s\nFold 5, Epoch 4, Batch 120, Loss: 1.9094, LR: 0.001000, Batch Time: 0.12s\nSkipped ID 12347: Image file /kaggle/input/fashion-product-images-dataset/fashion-dataset/images/12347.jpg not found\nFold 5, Epoch 4, Batch 130, Loss: 2.2164, LR: 0.001000, Batch Time: 0.11s\nFold 5, Epoch 4, Batch 140, Loss: 3.2204, LR: 0.001000, Batch Time: 0.12s\nFold 5, Epoch 4, Batch 150, Loss: 2.7945, LR: 0.001000, Batch Time: 0.11s\nFold 5, Epoch 4, Batch 160, Loss: 2.6016, LR: 0.001000, Batch Time: 0.12s\nFold 5, Epoch 4, Batch 170, Loss: 2.5975, LR: 0.001000, Batch Time: 0.11s\nFold 5, Epoch 4, Batch 180, Loss: 2.3543, LR: 0.001000, Batch Time: 0.12s\nFold 5, Epoch 4, Batch 190, Loss: 1.8914, LR: 0.001000, Batch Time: 0.13s\nFold 5, Epoch 4, Batch 200, Loss: 2.2271, LR: 0.001000, Batch Time: 0.12s\nFold 5, Epoch 4, Batch 210, Loss: 2.6698, LR: 0.001000, Batch Time: 0.13s\nSkipped ID 39401: Image file /kaggle/input/fashion-product-images-dataset/fashion-dataset/images/39401.jpg not found\nFold 5, Epoch 4, Batch 220, Loss: 4.3372, LR: 0.001000, Batch Time: 0.12s\nFold 5, Epoch 4, Batch 230, Loss: 2.7153, LR: 0.001000, Batch Time: 0.13s\nFold 5, Epoch 4, Batch 240, Loss: 3.0030, LR: 0.001000, Batch Time: 0.12s\nFold 5, Epoch 4, Batch 250, Loss: 2.2187, LR: 0.001000, Batch Time: 0.11s\nFold 5, Epoch 4, Batch 260, Loss: 2.3786, LR: 0.001000, Batch Time: 0.12s\nFold 5, Epoch 4, Batch 270, Loss: 2.1830, LR: 0.001000, Batch Time: 0.13s\nFold 5, Epoch 4, Batch 280, Loss: 3.7316, LR: 0.001000, Batch Time: 0.13s\nFold 5, Epoch 4, Batch 290, Loss: 3.2411, LR: 0.001000, Batch Time: 0.11s\nFold 5, Epoch 4, Batch 300, Loss: 3.5578, LR: 0.001000, Batch Time: 0.13s\nFold 5, Epoch 4, Batch 310, Loss: 3.2111, LR: 0.001000, Batch Time: 0.11s\nFold 5, Epoch 4, Batch 320, Loss: 3.3975, LR: 0.001000, Batch Time: 0.12s\nFold 5, Epoch 4, Batch 330, Loss: 1.9911, LR: 0.001000, Batch Time: 0.13s\nFold 5, Epoch 4, Batch 340, Loss: 3.1475, LR: 0.001000, Batch Time: 0.12s\nFold 5, Epoch 4, Batch 350, Loss: 3.4318, LR: 0.001000, Batch Time: 0.12s\nFold 5, Epoch 4, Batch 360, Loss: 2.8427, LR: 0.001000, Batch Time: 0.13s\nFold 5, Epoch 4, Batch 370, Loss: 2.6414, LR: 0.001000, Batch Time: 0.13s\nFold 5, Epoch 4, Batch 380, Loss: 2.7722, LR: 0.001000, Batch Time: 0.12s\nFold 5, Epoch 4, Batch 390, Loss: 3.4799, LR: 0.001000, Batch Time: 0.13s\nFold 5, Epoch 4, Batch 400, Loss: 3.2233, LR: 0.001000, Batch Time: 0.12s\nFold 5, Epoch 4, Batch 410, Loss: 3.2893, LR: 0.001000, Batch Time: 0.13s\nFold 5, Epoch 4, Batch 420, Loss: 3.4274, LR: 0.001000, Batch Time: 0.13s\nFold 5, Epoch 4, Batch 430, Loss: 2.1436, LR: 0.001000, Batch Time: 0.11s\nFold 5, Epoch 4, Batch 440, Loss: 2.9379, LR: 0.001000, Batch Time: 0.12s\nFold 5, Epoch 4, Batch 450, Loss: 1.8803, LR: 0.001000, Batch Time: 0.11s\nFold 5, Epoch 4, Batch 460, Loss: 3.2018, LR: 0.001000, Batch Time: 0.12s\nFold 5, Epoch 4, Batch 470, Loss: 3.6508, LR: 0.001000, Batch Time: 0.13s\nFold 5, Epoch 4, Batch 480, Loss: 3.3899, LR: 0.001000, Batch Time: 0.12s\nFold 5, Epoch 4, Batch 490, Loss: 2.5833, LR: 0.001000, Batch Time: 0.13s\nFold 5, Epoch 4, Batch 500, Loss: 2.9361, LR: 0.001000, Batch Time: 0.13s\nFold 5, Epoch 4, Batch 510, Loss: 2.8174, LR: 0.001000, Batch Time: 0.13s\nFold 5, Epoch 4, Batch 520, Loss: 2.9490, LR: 0.001000, Batch Time: 0.12s\nFold 5, Epoch 4, Batch 530, Loss: 2.8474, LR: 0.001000, Batch Time: 0.11s\nFold 5, Epoch 4, Batch 540, Loss: 2.7461, LR: 0.001000, Batch Time: 0.12s\nFold 5, Epoch 4, Batch 550, Loss: 2.8525, LR: 0.001000, Batch Time: 0.13s\nFold 5, Epoch 4, Batch 560, Loss: 3.0079, LR: 0.001000, Batch Time: 0.12s\nFold 5, Epoch 4, Batch 570, Loss: 2.5823, LR: 0.001000, Batch Time: 0.11s\nFold 5, Epoch 4, Batch 580, Loss: 2.0836, LR: 0.001000, Batch Time: 0.12s\nFold 5, Epoch 4, Batch 590, Loss: 2.9701, LR: 0.001000, Batch Time: 0.13s\nFold 5, Epoch 4, Batch 600, Loss: 4.3069, LR: 0.001000, Batch Time: 0.12s\nFold 5, Epoch 4, Batch 610, Loss: 2.6254, LR: 0.001000, Batch Time: 0.13s\nFold 5, Epoch 4, Batch 620, Loss: 2.6116, LR: 0.001000, Batch Time: 0.12s\nFold 5, Epoch 4, Batch 630, Loss: 1.8481, LR: 0.001000, Batch Time: 0.11s\nFold 5, Epoch 4, Batch 640, Loss: 2.9394, LR: 0.001000, Batch Time: 0.12s\nFold 5, Epoch 4, Batch 650, Loss: 3.0418, LR: 0.001000, Batch Time: 0.12s\nFold 5, Epoch 4, Batch 660, Loss: 3.1809, LR: 0.001000, Batch Time: 0.12s\nSkipped ID 39403: Image file /kaggle/input/fashion-product-images-dataset/fashion-dataset/images/39403.jpg not found\nFold 5, Epoch 4, Batch 670, Loss: 3.4913, LR: 0.001000, Batch Time: 0.13s\nFold 5, Epoch 4, Batch 680, Loss: 2.9897, LR: 0.001000, Batch Time: 0.12s\nFold 5, Epoch 4, Batch 690, Loss: 2.5337, LR: 0.001000, Batch Time: 0.13s\nFold 5, Epoch 4, Batch 700, Loss: 2.3389, LR: 0.001000, Batch Time: 0.12s\nFold 5, Epoch 4, Batch 710, Loss: 3.2361, LR: 0.001000, Batch Time: 0.13s\nFold 5, Epoch 4, Batch 720, Loss: 3.7838, LR: 0.001000, Batch Time: 0.12s\nFold 5, Epoch 4, Batch 730, Loss: 1.9565, LR: 0.001000, Batch Time: 0.13s\nFold 5, Epoch 4, Batch 740, Loss: 3.4060, LR: 0.001000, Batch Time: 0.12s\nFold 5, Epoch 4, Batch 750, Loss: 2.8976, LR: 0.001000, Batch Time: 0.13s\nFold 5, Epoch 4, Batch 760, Loss: 2.9889, LR: 0.001000, Batch Time: 0.12s\nSkipped ID 39425: Image file /kaggle/input/fashion-product-images-dataset/fashion-dataset/images/39425.jpg not found\nFold 5, Epoch 4, Batch 770, Loss: 3.3533, LR: 0.001000, Batch Time: 0.11s\nFold 5, Epoch 4, Batch 780, Loss: 1.9131, LR: 0.001000, Batch Time: 0.11s\nFold 5, Epoch 4, Batch 790, Loss: 2.3253, LR: 0.001000, Batch Time: 0.11s\nFold 5, Epoch 4, Batch 800, Loss: 2.8431, LR: 0.001000, Batch Time: 0.11s\nFold 5, Epoch 4, Batch 810, Loss: 3.4386, LR: 0.001000, Batch Time: 0.12s\nFold 5, Epoch 4, Batch 820, Loss: 2.6014, LR: 0.001000, Batch Time: 0.11s\nFold 5, Epoch 4, Batch 830, Loss: 1.9176, LR: 0.001000, Batch Time: 0.12s\nFold 5, Epoch 4, Batch 840, Loss: 3.3586, LR: 0.001000, Batch Time: 0.12s\nFold 5, Epoch 4, Batch 850, Loss: 2.5861, LR: 0.001000, Batch Time: 0.11s\nFold 5, Epoch 4, Batch 860, Loss: 2.0972, LR: 0.001000, Batch Time: 0.12s\nFold 5, Epoch 4, Batch 870, Loss: 3.3243, LR: 0.001000, Batch Time: 0.13s\nFold 5, Epoch 4, Batch 880, Loss: 2.7541, LR: 0.001000, Batch Time: 0.12s\nFold 5, Epoch 4, Batch 890, Loss: 2.7352, LR: 0.001000, Batch Time: 0.13s\nFold 5, Epoch 4, Batch 900, Loss: 2.0129, LR: 0.001000, Batch Time: 0.12s\nFold 5, Epoch 4, Batch 910, Loss: 3.2346, LR: 0.001000, Batch Time: 0.13s\nFold 5, Epoch 4, Batch 920, Loss: 2.0831, LR: 0.001000, Batch Time: 0.12s\nFold 5, Epoch 4, Batch 930, Loss: 2.8301, LR: 0.001000, Batch Time: 0.13s\nFold 5, Epoch 4, Batch 940, Loss: 3.4593, LR: 0.001000, Batch Time: 0.12s\nFold 5, Epoch 4, Train Loss: 2.8063, Epoch 4 Time: 573.73s\nFold 5, Validation Loss: 15.6335\nFold 5, Validation F1-Scores (Macro) - Color: 0.3180, Type: 0.0406, Season: 0.6709, Gender: 0.7178, Avg F1: 0.4368\nFold 5, Validation Precision (Macro) - Color: 0.3118, Type: 0.0536, Season: 0.6429, Gender: 0.6658\nFold 5, Validation Recall (Macro) - Color: 0.4065, Type: 0.0403, Season: 0.7186, Gender: 0.8036\nFold 5, Validation Accuracy - Color: 0.5335, Type: 0.0346, Season: 0.6496, Gender: 0.8628\nEarly stopping triggered for Fold 5\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"}],"execution_count":13},{"cell_type":"markdown","source":"### Plotting Metrics for K-Fold Cross-Validation\n\nThis code generates plots to visualize the performance metrics of the `MultiTaskModel` across k-fold cross-validation.\n\n#### Key Components:\n- **Loss Curves**: Plots training and validation loss for each fold, showing model convergence over epochs.\n- **Task Metrics**: For each task (color, type, season, gender), plots macro-averaged F1-score, precision, recall, and accuracy over epochs, highlighting performance on imbalanced classes (e.g., 'Spring', 'Girls').\n- **Loss Contribution**: Creates a bar plot showing the average loss contribution of each task (color, type, season, gender) for each fold, indicating which tasks are harder to learn.\n\nThe macro-averaged F1-score is emphasized in the task metrics plots, as it’s the most significant metric for evaluating performance on imbalanced classes, ensuring minority classes are adequately represented. These visualizations help assess model performance and identify areas for improvement across folds.","metadata":{}},{"cell_type":"code","source":"# Plot metrics for each fold\nfor fold, epoch_metrics in enumerate(fold_metrics):\n    # Define epoch range for plotting\n    epochs = range(1, len(epoch_metrics['train_loss']) + 1)\n    \n    # Plot training and validation loss curves\n    plt.figure(figsize=(12, 8))\n    plt.plot(epochs, epoch_metrics['train_loss'], label='Train Loss', color='#1f77b4')\n    plt.plot(epochs, epoch_metrics['val_loss'], label='Validation Loss', color='#ff7f0e')\n    plt.title(f'Fold {fold+1} Loss Curve')  # Set title for loss plot\n    plt.xlabel('Epoch')\n    plt.ylabel('Loss')\n    plt.legend()\n    plt.grid(True)\n    plt.savefig(f'/kaggle/working/fold_{fold+1}_loss_curve.png')  # Save loss plot\n    plt.close()\n\n    # Plot metrics (F1, precision, recall, accuracy) for each task\n    for task in tasks:\n        plt.figure(figsize=(12, 8))\n        plt.plot(epochs, epoch_metrics[f'val_f1_{task}'], label='F1-Score (Macro)', color='#1f77b4')\n        plt.plot(epochs, epoch_metrics[f'val_precision_{task}'], label='Precision (Macro)', color='#ff7f0e')\n        plt.plot(epochs, epoch_metrics[f'val_recall_{task}'], label='Recall (Macro)', color='#2ca02c')\n        plt.plot(epochs, epoch_metrics[f'val_accuracy_{task}'], label='Accuracy', color='#d62728')\n        plt.title(f'Fold {fold+1} {task.capitalize()} Metrics')  # Set title for task metrics\n        plt.xlabel('Epoch')\n        plt.ylabel('Score')\n        plt.legend()\n        plt.grid(True)\n        plt.savefig(f'/kaggle/working/fold_{fold+1}_{task}_metrics.png')  # Save task metrics plot\n        plt.close()\n\n    # Plot average loss contribution per task\n    plt.figure(figsize=(10, 6))\n    loss_contributions = [\n        np.mean(epoch_metrics['loss_color']),\n        np.mean(epoch_metrics['loss_type']),\n        np.mean(epoch_metrics['loss_season']),\n        np.mean(epoch_metrics['loss_gender'])\n    ]\n    plt.bar(tasks, loss_contributions, color=['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728'])\n    plt.title(f'Fold {fold+1} Average Loss Contribution per Task')  # Set title for loss contribution\n    plt.xlabel('Task')\n    plt.ylabel('Average Loss')\n    plt.savefig(f'/kaggle/working/fold_{fold+1}_loss_contribution.png')  # Save loss contribution plot\n    plt.close()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T11:13:21.170403Z","iopub.execute_input":"2025-07-20T11:13:21.171290Z","iopub.status.idle":"2025-07-20T11:13:26.606993Z","shell.execute_reply.started":"2025-07-20T11:13:21.171257Z","shell.execute_reply":"2025-07-20T11:13:26.606054Z"}},"outputs":[],"execution_count":14},{"cell_type":"markdown","source":"### Fold Results Summary and Cross-Fold Visualizations\n\nThis code summarizes the k-fold cross-validation results for the `MultiTaskModel` and visualizes average metrics across folds.\n\n#### Key Components:\n- **Results Summary**: Prints per-fold metrics, including best validation loss, macro-averaged F1-scores, precision, recall, accuracy for each task (color, type, season, gender), and skipped image IDs from `FashionDataset`. Also displays the best fold based on average F1-score.\n- **Average Metrics Calculation**: Computes mean metrics (F1, precision, recall, accuracy, loss) across epochs for each fold and task.\n- **Metrics Plot**: Plots task-specific F1-score, precision, recall, and accuracy across folds to show performance consistency.\n- **Loss Contribution Plot**: Creates a bar plot of average loss per task across folds, highlighting tasks with higher difficulty.\n\n","metadata":{}},{"cell_type":"code","source":"# Print summary of results for each fold\nprint(\"\\nFold Results Summary:\")\nfor result in fold_results:\n    # Display best validation loss and average F1-score for the fold\n    print(f\"Fold {result['fold']}: Best Validation Loss: {result['best_val_loss']:.4f}, Avg F1: {result['avg_f1']:.4f}\")\n    # Display macro-averaged F1-scores for each task\n    print(f\"Fold {result['fold']}: Validation F1-Scores (Macro) - Color: {result['val_f1_color']:.4f}, Type: {result['val_f1_type']:.4f}, Season: {result['val_f1_season']:.4f}, Gender: {result['val_f1_gender']:.4f}\")\n    # Display macro-averaged precision for each task\n    print(f\"Fold {result['fold']}: Validation Precision (Macro) - Color: {result['val_precision_color']:.4f}, Type: {result['val_precision_type']:.4f}, Season: {result['val_precision_season']:.4f}, Gender: {result['val_precision_gender']:.4f}\")\n    # Display macro-averaged recall for each task\n    print(f\"Fold {result['fold']}: Validation Recall (Macro) - Color: {result['val_recall_color']:.4f}, Type: {result['val_recall_type']:.4f}, Season: {result['val_recall_season']:.4f}, Gender: {result['val_recall_gender']:.4f}\")\n    # Display accuracy for each task\n    print(f\"Fold {result['fold']}: Validation Accuracy - Color: {result['val_accuracy_color']:.4f}, Type: {result['val_accuracy_type']:.4f}, Season: {result['val_accuracy_season']:.4f}, Gender: {result['val_accuracy_gender']:.4f}\")\n    # Display skipped image IDs for train and validation sets\n    \n# Print the best fold and its average F1-score\nprint(f\"\\nBest Fold: {best_fold} with Avg F1-Score: {best_avg_f1:.4f}\")\n\n# Initialize dictionary to store average metrics across folds\navg_metrics = {\n    'val_loss': [], 'loss_color': [], 'loss_type': [], 'loss_season': [], 'loss_gender': []\n}\nfor task in tasks:\n    # Add task-specific metrics to dictionary\n    avg_metrics[f'val_f1_{task}'] = []\n    avg_metrics[f'val_precision_{task}'] = []\n    avg_metrics[f'val_recall_{task}'] = []\n    avg_metrics[f'val_accuracy_{task}'] = []\n\n# Compute average metrics for each fold\nfor fold in range(k):\n    for metric in avg_metrics.keys():\n        if metric.startswith('val_') and any(metric.endswith(task) for task in tasks):\n            # Compute mean for task-specific validation metrics\n            avg_metrics[metric].append(np.mean(fold_metrics[fold][metric]))\n        elif metric.startswith('loss_'):\n            # Compute mean for loss metrics\n            avg_metrics[metric].append(np.mean(fold_metrics[fold][metric]))\n\n# Plot average metrics across folds\nplt.figure(figsize=(12, 8))\nfor metric in ['val_f1', 'val_precision', 'val_recall', 'val_accuracy']:\n    for task in tasks:\n        # Plot task-specific metric across folds\n        plt.plot(range(1, k+1), avg_metrics[f'{metric}_{task}'], label=f'{metric.capitalize()} {task.capitalize()}')\nplt.title('Average Metrics Across Folds')  # Set title for metrics plot\nplt.xlabel('Fold')\nplt.ylabel('Score')\nplt.legend()\nplt.grid(True)\nplt.savefig('/kaggle/working/average_metrics_across_folds.png')  # Save metrics plot\nplt.close()\n\n# Plot average loss contribution across folds\nplt.figure(figsize=(10, 6))\nplt.bar(tasks, [np.mean(avg_metrics[f'loss_{task}']) for task in tasks], color=['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728'])\nplt.title('Average Loss Contribution Across Folds')  # Set title for loss contribution\nplt.xlabel('Task')\nplt.ylabel('Average Loss')\nplt.savefig('/kaggle/working/average_loss_contribution.png')  # Save loss contribution plot\nplt.close()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T14:43:42.497986Z","iopub.execute_input":"2025-07-20T14:43:42.498687Z","iopub.status.idle":"2025-07-20T14:43:42.893806Z","shell.execute_reply.started":"2025-07-20T14:43:42.498659Z","shell.execute_reply":"2025-07-20T14:43:42.893225Z"}},"outputs":[{"name":"stdout","text":"\nFold Results Summary:\nFold 1: Best Validation Loss: 15.0288, Avg F1: 0.3739\nFold 1: Validation F1-Scores (Macro) - Color: 0.0817, Type: 0.0328, Season: 0.6667, Gender: 0.7146\nFold 1: Validation Precision (Macro) - Color: 0.0922, Type: 0.0377, Season: 0.6377, Gender: 0.6564\nFold 1: Validation Recall (Macro) - Color: 0.1234, Type: 0.0385, Season: 0.7168, Gender: 0.8197\nFold 1: Validation Accuracy - Color: 0.2603, Type: 0.0182, Season: 0.6497, Gender: 0.8586\nFold 2: Best Validation Loss: 18.2874, Avg F1: 0.3767\nFold 2: Validation F1-Scores (Macro) - Color: 0.0875, Type: 0.0280, Season: 0.6700, Gender: 0.7213\nFold 2: Validation Precision (Macro) - Color: 0.0896, Type: 0.0296, Season: 0.6400, Gender: 0.6658\nFold 2: Validation Recall (Macro) - Color: 0.1130, Type: 0.0331, Season: 0.7220, Gender: 0.8244\nFold 2: Validation Accuracy - Color: 0.2455, Type: 0.0198, Season: 0.6514, Gender: 0.8594\nFold 3: Best Validation Loss: 17.4834, Avg F1: 0.3760\nFold 3: Validation F1-Scores (Macro) - Color: 0.0828, Type: 0.0404, Season: 0.6605, Gender: 0.7202\nFold 3: Validation Precision (Macro) - Color: 0.0958, Type: 0.0496, Season: 0.6314, Gender: 0.6597\nFold 3: Validation Recall (Macro) - Color: 0.0983, Type: 0.0384, Season: 0.7196, Gender: 0.8277\nFold 3: Validation Accuracy - Color: 0.2538, Type: 0.0355, Season: 0.6390, Gender: 0.8589\nFold 4: Best Validation Loss: 14.2334, Avg F1: 0.4249\nFold 4: Validation F1-Scores (Macro) - Color: 0.2969, Type: 0.0420, Season: 0.6583, Gender: 0.7026\nFold 4: Validation Precision (Macro) - Color: 0.2858, Type: 0.0449, Season: 0.6290, Gender: 0.6421\nFold 4: Validation Recall (Macro) - Color: 0.4201, Type: 0.0453, Season: 0.7089, Gender: 0.8155\nFold 4: Validation Accuracy - Color: 0.4657, Type: 0.0334, Season: 0.6485, Gender: 0.8534\nFold 5: Best Validation Loss: 12.3533, Avg F1: 0.4368\nFold 5: Validation F1-Scores (Macro) - Color: 0.3180, Type: 0.0406, Season: 0.6709, Gender: 0.7178\nFold 5: Validation Precision (Macro) - Color: 0.3118, Type: 0.0536, Season: 0.6429, Gender: 0.6658\nFold 5: Validation Recall (Macro) - Color: 0.4065, Type: 0.0403, Season: 0.7186, Gender: 0.8036\nFold 5: Validation Accuracy - Color: 0.5335, Type: 0.0346, Season: 0.6496, Gender: 0.8628\n\nBest Fold: 5 with Avg F1-Score: 0.4053\n","output_type":"stream"}],"execution_count":31},{"cell_type":"markdown","source":"## Final Test Evaluation and Visualization\n\nThis code evaluates the `MultiTaskModel` on the test set using the best model (from Cell 8) and visualizes the results.\n\n#### Key Components:\n- **Test Dataset and DataLoader**: Creates a `FashionDataset` and `DataLoader` for the test set (from Cell 5) with the same transformations and minority class handling.\n- **Model Evaluation**: Loads the best model weights, sets the model to evaluation mode, and computes predictions on the test set without gradient computation.\n- **Metrics Calculation**: Calculates average test loss and macro-averaged F1-score, precision, recall, and accuracy for each task (color, type, season, gender).\n- **Results Output**: Prints test loss, task-specific metrics, and skipped image IDs from `FashionDataset`.\n- **Confusion Matrices**: Plots a 2x2 grid of confusion matrices for each task, visualizing prediction errors.\n- **Class-wise F1-Scores**: Plots bar charts of per-class F1-scores for each task, highlighting class-specific performance.\n- **Error Handling**: Checks if the best model file exists, skipping evaluation if not found.\n","metadata":{}},{"cell_type":"code","source":"# Final evaluation on the test set using the best model\nif os.path.exists(best_model_path):\n    # Create test dataset and DataLoader\n    test_dataset = FashionDataset(test_data, img_dir, transform=transform, minority_classes=minority_classes)\n    test_loader = create_dataloader(test_dataset, batch_size=32, shuffle=False, num_workers=4)\n    \n    # Load best model weights and set to evaluation mode\n    model.load_state_dict(torch.load(best_model_path))\n    model.eval()\n    \n    # Initialize test metrics\n    test_loss = 0.0\n    test_count = 0\n    test_color_true, test_color_pred = [], []\n    test_type_true, test_type_pred = [], []\n    test_season_true, test_season_pred = [], []\n    test_gender_true, test_gender_pred = [], []\n    \n    # Evaluate on test set without gradient computation\n    with torch.no_grad():\n        for batch in test_loader:\n            if batch is None:\n                continue\n            # Load batch data and move to device\n            images, colors, types, seasons, genders = batch\n            images, colors, types, seasons, genders = (\n                images.to(device), colors.to(device), types.to(device),\n                seasons.to(device), genders.to(device)\n            )\n            # Forward pass\n            color_pred, type_pred, season_pred, gender_pred = model(images)\n            # Compute total test loss\n            test_loss += (criterion_color(color_pred, colors) + criterion_type(type_pred, types) +\n                          criterion_season(season_pred, seasons) + criterion_gender(gender_pred, genders)).item()\n            test_count += 1\n            # Store true and predicted labels for metrics\n            test_color_true.extend(colors.cpu().numpy())\n            test_color_pred.extend(torch.argmax(color_pred, dim=1).cpu().numpy())\n            test_type_true.extend(types.cpu().numpy())\n            test_type_pred.extend(torch.argmax(type_pred, dim=1).cpu().numpy())\n            test_season_true.extend(seasons.cpu().numpy())\n            test_season_pred.extend(torch.argmax(season_pred, dim=1).cpu().numpy())\n            test_gender_true.extend(genders.cpu().numpy())\n            test_gender_pred.extend(torch.argmax(gender_pred, dim=1).cpu().numpy())\n    \n    # Compute average test loss\n    avg_test_loss = test_loss / test_count if test_count > 0 else float('inf')\n    \n    # Calculate macro-averaged metrics for each task\n    test_f1_color = f1_score(test_color_true, test_color_pred, average='macro')\n    test_f1_type = f1_score(test_type_true, test_type_pred, average='macro')\n    test_f1_season = f1_score(test_season_true, test_season_pred, average='macro')\n    test_f1_gender = f1_score(test_gender_true, test_gender_pred, average='macro')\n    test_precision_color = precision_score(test_color_true, test_color_pred, average='macro')\n    test_precision_type = precision_score(test_type_true, test_type_pred, average='macro')\n    test_precision_season = precision_score(test_season_true, test_season_pred, average='macro')\n    test_precision_gender = precision_score(test_gender_true, test_gender_pred, average='macro')\n    test_recall_color = recall_score(test_color_true, test_color_pred, average='macro')\n    test_recall_type = recall_score(test_type_true, test_type_pred, average='macro')\n    test_recall_season = recall_score(test_season_true, test_season_pred, average='macro')\n    test_recall_gender = recall_score(test_gender_true, test_gender_pred, average='macro')\n    test_accuracy_color = accuracy_score(test_color_true, test_color_pred)\n    test_accuracy_type = accuracy_score(test_type_true, test_type_pred)\n    test_accuracy_season = accuracy_score(test_season_true, test_season_pred)\n    test_accuracy_gender = accuracy_score(test_gender_true, test_gender_pred)\n    \n    # Print test metrics\n    print(f\"\\nTest Loss: {avg_test_loss:.4f}\")\n    print(f\"Test F1-Scores (Macro) - Color: {test_f1_color:.4f}, Type: {test_f1_type:.4f}, Season: {test_f1_season:.4f}, Gender: {test_f1_gender:.4f}\")\n    print(f\"Test Precision (Macro) - Color: {test_precision_color:.4f}, Type: {test_precision_type:.4f}, Season: {test_precision_season:.4f}, Gender: {test_precision_gender:.4f}\")\n    print(f\"Test Recall (Macro) - Color: {test_recall_color:.4f}, Type: {test_recall_type:.4f}, Season: {test_recall_season:.4f}, Gender: {test_recall_gender:.4f}\")\n    print(f\"Test Accuracy - Color: {test_accuracy_color:.4f}, Type: {test_accuracy_type:.4f}, Season: {test_accuracy_season:.4f}, Gender: {test_accuracy_gender:.4f}\")\n    \n\n    # Plot confusion matrices for each task\n    plt.figure(figsize=(12, 10))\n    for i, (task, true, pred) in enumerate([\n        ('color', test_color_true, test_color_pred),\n        ('type', test_type_true, test_type_pred),\n        ('season', test_season_true, test_season_pred),\n        ('gender', test_gender_true, test_gender_pred)\n    ]):\n        cm = confusion_matrix(true, pred)\n        plt.subplot(2, 2, i+1)\n        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n        plt.title(f'Test Confusion Matrix - {task.capitalize()}')\n        plt.xlabel('Predicted')\n        plt.ylabel('True')\n    plt.tight_layout()\n    plt.savefig('/kaggle/working/test_confusion_matrices.png')\n    plt.close()\n\n    # Plot class-wise F1-scores for each task\n    for task, true, pred in [\n        ('color', test_color_true, test_color_pred),\n        ('type', test_type_true, test_type_pred),\n        ('season', test_season_true, test_season_pred),\n        ('gender', test_gender_true, test_gender_pred)\n    ]:\n        class_f1_scores = f1_score(true, pred, average=None)\n        plt.figure(figsize=(10, 6))\n        plt.bar(range(len(class_f1_scores)), class_f1_scores, color='#1f77b4')\n        plt.title(f'Test Class-wise F1-Scores - {task.capitalize()}')\n        plt.xlabel('Class Index')\n        plt.ylabel('F1-Score')\n        plt.savefig(f'/kaggle/working/test_class_f1_scores_{task}.png')\n        plt.close()\nelse:\n    # Handle case where best model file is missing\n    print(f\"Error: Best model file {best_model_path} not found. No test evaluation performed.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T14:39:06.610060Z","iopub.execute_input":"2025-07-20T14:39:06.610844Z","iopub.status.idle":"2025-07-20T14:41:55.811044Z","shell.execute_reply.started":"2025-07-20T14:39:06.610817Z","shell.execute_reply":"2025-07-20T14:41:55.810300Z"}},"outputs":[{"name":"stdout","text":"Skipped ID 39410: Image file /kaggle/input/fashion-product-images-dataset/fashion-dataset/images/39410.jpg not found\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"},{"name":"stdout","text":"\nTest Loss: 17.0247\nTest F1-Scores (Macro) - Color: 0.0597, Type: 0.0231, Season: 0.6192, Gender: 0.6782\nTest Precision (Macro) - Color: 0.0721, Type: 0.0260, Season: 0.5958, Gender: 0.6198\nTest Recall (Macro) - Color: 0.0648, Type: 0.0222, Season: 0.6959, Gender: 0.7955\nTest Accuracy - Color: 0.2310, Type: 0.0203, Season: 0.5943, Gender: 0.8427\n","output_type":"stream"}],"execution_count":30},{"cell_type":"markdown","source":"# Further Enhancement Needed:","metadata":{}},{"cell_type":"markdown","source":"To improve the performance of the 'MultiTaskModel' for predicting fashion attributes (gender, article type, season, color), several enhancements can be considered to address the challenges observed, particularly due to the dataset's class imbalance.\n\n### Key Observations and Proposed Improvements:\n\n***Class Imbalance and High Cardinality:*** \nThe model was trained to predict four attributes: gender, article type (143 classes), season, and color (46 classes), as per the assignment requirements. However, the dataset's imbalance, especially for article type (143 classes) and color (46 classes), led to low macro-averaged F1-scores. The large number of classes in article type significantly impacted accuracy.\n\n***Solution:*** Reduce the number of classes for article type and color:\n\n - **Article Type:** Instead of predicting 143 article types, cluster similar products to create fewer, more balanced classes. Alternatively, predict higher-level categories like 'MasterCategory' or 'SubCategory' in place of 'articleType', which have fewer classes and less imbalance, potentially improving model performance.\n\n- **Color:** Group the 46 colors into color families (e.g., reds, blues, neutrals) to reduce the number of classes and improve generalization. This also accommodates future products with new colors not present in the dataset.\n\n\n**Scalability for Colors:** The dataset currently includes 46 colors, but new products may introduce additional colors, increasing color classes  over time.\n\n- **Solution:** Categorize colors into predefined color families (e.g., warm, cool, neutral tones) to create a fixed, manageable number of classes. This approach ensures the model remains robust as the dataset grows, avoiding the need to retrain for every new color.\n\n\n**Model Performance:** The macro-averaged F1-score, highlights the model’s struggle with minority classes. Clustering or reducing classes for article type and color would improve F1-scores by balancing class distributions.\n\n**Future Steps:**\n\n- Implement clustering for article types by making cluster of similar classes to reduce the number of classes.\n\n- Explore predicting MasterCategory or SubCategory instead of article type for better performance.\n\n- Define color families based on hue, saturation, or perceptual similarity to simplify color classification.\n\n- Re-evaluate the model with these changes, focusing on macro-averaged F1-scores to ensure balanced performance across all classes.\n\nThese enhancements would address the dataset’s challenges, improve model accuracy and generalization, and align with practical applications in fashion product classification.","metadata":{}},{"cell_type":"markdown","source":"## Thank You","metadata":{}}]}